{"meta":{"title":"希尔的博客","subtitle":"兰之猗猗，扬扬其香。不采而佩，于兰何伤？","description":null,"author":"zshellzhang","url":"http://zshell.cc"},"pages":[{"title":"tags","date":"2016-07-05T13:58:26.000Z","updated":"2018-01-27T14:53:07.593Z","comments":true,"path":"tags/index.html","permalink":"http://zshell.cc/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2016-08-01T11:40:08.000Z","updated":"2018-01-27T14:53:07.585Z","comments":false,"path":"categories/index.html","permalink":"http://zshell.cc/categories/index.html","excerpt":"","text":""},{"title":"about me","date":"2016-07-05T13:11:04.000Z","updated":"2019-01-20T06:24:52.723Z","comments":true,"path":"about/index.html","permalink":"http://zshell.cc/about/index.html","excerpt":"","text":"日月忽其不淹兮，春与秋其代序。路漫漫其修远兮，吾将上下而求索。乘骐骥以驰骋兮，来吾道夫先路! 建站的初心前辈的指引Donald Knuth记得上大学的时候，我的数据结构课老师曾对我们讲过一个故事：斯坦福大学计算机教授 Donald Knuth 年轻时曾立下一个豪迈的目标，要将计算机世界的一切知识全部写进书里。今天，我们欣慰得看到，《The Art of Computer Programming》总共规划了七卷，如今已正式出版了前三卷，第四卷也将很快面世。尽管年轻时的豪言定不能完全实现，但 1968 年至今，50 载岁月里，Donald 一步一个脚印，坚定得行走在自己的理想之路上，以书为媒，虔诚布道。 阮一峰我初识阮一峰老师也是在上大学的时候。最开始我只阅读阮老师的技术文章，以解决专业学习中的困惑与难点。相比 CSDN，博客园等技术网站，我能明显得感受到阮老师别具一格的为文态度：以自身的好奇与求知欲为写作文章的驱动力，而非单纯的工作内容经验总结或为求读者阅读而写作，他的刨根问底精神，使其通过浅显易懂的大白话讲清楚抽象深奥的概念。在网上看够了太多的转载，抄袭文章，回过头来与阮老师的文章对比，能强烈得感受到其作文的用心与认真。 后来工作后，我继续深入了解，进而发现阮老师是一个对各行各业、各个领域都保持探索精神与独立思考的博学者：有的文章表达自己对社会发展的隐忧，如《未来世界的幸存者》；有的文章以一颗单纯的工匠之心还原细节，如《日本刀的制造过程》；有的文章虔诚得记录着自己的成长与人生思考，如《前方的路》。阮老师面对社会与生活的态度，不卑亦不亢，澄明而平和。最近，阮老师则推出了一个新的专栏：阮一峰的每周分享，在文中，阮老师坦言希望自己在社会上能够多发声，希望让自己的声音传播出去，让尽可能多的人听到，团结志同道合的人，也许将来可以在一起做一些有意义的事情。古人云，人生要立德，立功，立言。阮老师这是用实际行动在践行 “立言” 之道。 时间方法论一位曾在阿里巴巴任职过的同事对我说：去了阿里之后，一个人的心态需要调整，曾经可能是核心系统的核心开发者，而在阿里，会发现这里的技术生态很成熟以致于并不会有太多机会做完整的大项目，从而变成了一颗螺丝钉，触碰到职业瓶颈。 我阐述观点：阿里的基础架构与中间件做的很完善，对业务线来说不需要关注底层实现细节，只需使用其对外暴露的接口便能接入强大的功能，这是很多业务线开发者觉得自己只是在写业务代码而得不到技术提升的理由。但是既然已经身处阿里这种级别的公司，也意味着能够接触到公司内部大量的优质技术文档，能够从代码仓库中拉取到很多内部开源的中间件源码，就算再不济也可以从公司构件管理私服中下载这些基础组件客户端二方包的源码构件，并反向揣摩其服务端的实现。总之无论如何，只要你想，就一定能学到东西。 同事补充道：是的，但大部分人的学习模式都是项目驱动型的，没有了可靠的项目作支撑，很多人就失去了学习的主动力。 我不再反驳，我明白在这一点上我是有所不同的，我并不需要外界的强制力量推动自己向前，我对未知事物的好奇心与探索欲足以驱动我不断前进。我没有过人的天赋，像天才那样在极短的时间内达到惊人的成就，所以我不会特别在意当下我的绝对速度。我只在意我是否仍在持续向前，我只与时间赛跑，赛一场长跑，比拼持久力，而很多所谓的天才，最终都输给了时间。 在我来杭之前，北京的一位朋友曾极力劝阻我不要过早得离开北京，说这会让我过早得碰到职业天花板，而如果在北京熬足了经历，再去杭州拿 P7、P8 的 package 会顺利很多。不过最终我还是没有采纳他的建议：道路有顺畅亦有曲折，如同股市有涨也有跌，真正的价值投资绝不会在意眼下暂时的亏损，充实丰富的人生更不用懊恼一时多走的弯路。我从未将工作职级作为人生的追求，毕竟从时间尺度来衡量，所有的运气与投机，功名与利禄都是微不足道，唯有在时间长河里能够彰显价值，才是真正值得我追求的东西。 职业的延展电影《超体》中有一个超脱情感的观点：生命的终极目的，在于争取时间与传递知识，除此之外再无更高阶的意义。 然而，为了实现这一目的，人类却没有明显的优势。十年树木，百年树人，这句话在道明人才培育的重要性之外，也暗含了人类文明的弱点：一个人从出生、成长、上学，到踏入社会并逐渐成为领域内的专家，几近耗费半生的精力。如果说文明是一场接力赛，那么人类则将一半的时间浪费在了交接棒上。 不过付出这一承重代价的人类文明，却获得了非凡的智慧、自由而富于创新的思想，这些给予了生命个体以无限的潜能，足以在其生命后半程开创文明的先河，引领突破性的文明进展。 我作为一个普通的人类个体，对传递人类文明的贡献恐怕不值一提，但也能在领域内尽自己的一份绵薄之力。我认为，作为一个程序员，计算机科学只是一个入口，一个观察世界的独特视角。你可以选择与世界无关，专心耕耘只与行业相关的内容，而我要选择以这个视角为基点，重新认识甚至改变这个世界。我带着无限的求知欲与好奇心来到这个世界，带着自然赋予我的智慧与思想, 又认识了查理·芒格这样的精神导师，以及阮一峰这样的实践榜样。我希望不要辜负了这份潜力，这份机会，我期待跨领域的交叉与融合为世界带来一阵别样的清风。 人生之路德国作家 赫尔曼·黑塞 在其著作《德米安：彷徨少年时》中写到： 每个人的生命都是通向自我的征途，是对一条路道的尝试，是一条小径的悄然召唤。对每个人而言，真正的职责只有一个：找到自我。无论他的归宿是诗人还是疯子，是先知还是罪犯 —— 这些其实和他无关，毫不重要。他的职责只是找到自己的命运而不是他人的命运 —— 然后在心中坚守其一生，全心全意，永不停息。所有其它的路都是不完整的，是人的逃避方式，是对大众理想的懦弱回归，是随波逐流，是对内心的恐惧。 如果说每个人的一生都是独一无二的，倘若每个人都来写一写自己的博客，想必也应当都是些与众不同的篇什吧：马云会写尽年轻时成天捣鼓着的那些奇怪想法；孙宏斌会把自己身陷囹圄后的大彻大悟娓娓道来；豪迈的人泼墨于当年的人生得意时；内向的人着笔于其眼中细腻的生活图景。 可惜大部分人并没有写博客的想法，故而我们只能在别人的文章中了解别人眼中的马云，别人眼中的孙宏斌······而他们自己到底是谁，他们自己眼中的自己，我们却无从得知。要进入一个人的心灵，他的文字是比他的语言更加深刻的入口。你说出来的话，就像内存里的信息，处于一种易失且易变的状态；你写下来的文字，则像磁盘上的数据，持久、稳固，并可以期待时间的检验。 其实，写不写博客都不重要，关键是我们是否仍在独立思考。我们之所以会变得平庸，是因为我们不再思考。当我们不去阅读，不去思考，我们就会被迫在行为上与普罗大众越来越趋同，从而掩盖了我们生来的独一无二性。只能说，我们每个人都有独一无二的潜力，但并非每个人都能真正意识到它，即便意识到了也并非都能真正做到。 而我决定做一些事情，来见证我生命的独一无二，也就是这里，维护这么一个博客，去写作，诚实得记录自己的想法与心路历程。我不期待将来的某一天，我的故事会广为人知，我只希望多少年之后，当我回过头，能够确认，这些点点滴滴，的的确确是我走过的路，身体的路以及心灵的路，而其他任何人都不可能跨入同我一模一样的河流。 我也希望在多少年之后，我能够真正领悟，同马云这样叱咤风云的人相比，我的人生，他的人生，谁都不比谁更高阶，在 “自我” 这条道路的实践上，我们都可以交上质量优秀的人生作业。 &nbsp;愿吾回首来路，不忘初心！ 我的联系方式微信 : &nbsp;XaaService 手机 : 18513585440 邮箱 : zhangzhi@weidian.com&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;xaaservice@gmail.com&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;service_impl@163.com 我的职业状态 2016.06: 大学毕业如何以一个偏文科院校计算机学院本科毕业生的身份，去挑战 985 工科院校的计算机硕士？唯有加倍努力！时间会证明一切。 2016.07 - 2018.06: 去哪儿网 dev应届生就像一张白纸，毕业后入职的第一家公司会在纸上留下比之后任何一家公司都要深刻的印记。感谢 qunar 和她的子公司 11bee，为我的职业生涯打下了一个良好的开端：代码规范、开发模式、运维保障、devops 精神，去哪儿网告诉了我什么是业界领先以及如何做到业界领先。即使我已离开了，在今后的工作中我会依然保持 qunar 的专业精神。 2018.07 - 至今: 微店 dev终于，我还是来杭州了。面对网易 “可口食堂，三餐全免，全年二十薪” 的福利诱惑，我曾犹豫再三。然凡事有舍才有得，既然想接触一下焕然一新的技术环境，既然不想屈服于略显保守的业务特征，我就得放弃过于优渥的条件。可以少挣点钱，可以多吃点苦，暂时远离舒适，适度拥抱压力与焦虑。来到微店最好的技术部门，我祝福自己：希望以后回过头看，这是我做出的一项正确决定！"}],"posts":[{"title":"家与房子","slug":"life-thought--家与房子","date":"2019-01-12T03:41:15.000Z","updated":"2019-01-24T01:41:15.730Z","comments":true,"path":"2019/01/12/life-thought--家与房子/","link":"","permalink":"http://zshell.cc/2019/01/12/life-thought--家与房子/","excerpt":"每颗心上某一个地方，总有个记忆挥不散；每个深夜某一处微亮，总藏着最切的思量。小时候，家是一叶温暖的襁褓，我在里面，父母在外面，包裹着它，我浸润在爱的海洋；长大后，家是一根思念的脐带，父母在上头，我在下头，剪断了它，我变成了独立的模样；而现在，家是一层薄薄的纸儿，我在左侧，她在右侧，揭开了它，我踏上了幸福的远航。","text":"每颗心上某一个地方，总有个记忆挥不散；每个深夜某一处微亮，总藏着最切的思量。小时候，家是一叶温暖的襁褓，我在里面，父母在外面，包裹着它，我浸润在爱的海洋；长大后，家是一根思念的脐带，父母在上头，我在下头，剪断了它，我变成了独立的模样；而现在，家是一层薄薄的纸儿，我在左侧，她在右侧，揭开了它，我踏上了幸福的远航。 离家的梦“我想问一下，这户口簿上，你的出生地是你的老家吧？” “不是的哦，我的籍贯才是我的老家呀！”空气似乎凝固在了下一刻，还好对面的人儿反应足够 “机敏”，才不至于酿成进一步的尴尬：“哦哦，我了解了。” 这似乎只是一段微不足道的对话，本应该迅速被双方遗忘。可我敏锐得捕捉到了一个微妙的信号，令我不由自主心生感慨！这是我三年来一直囿于内心的一段情愫，以往它仅仅于幽微之处暗自左右我的言行，不算深刻，只如文火慢炖。它期待与我对话的人能够体察到某些措辞的细节，但绝不会展示更进一步的暗示。它潜藏在其他诸如哀伤、思念、惆怅等情感之下，几乎没有存在感，却又为这些纷繁复杂的内心诉求提供了一片良田沃土，令其生生不息，滚滚东逝。 这种情愫，将千言万语化作了一个字：家。 我仔细打量着对面的他，岁月在其脸上留下的手笔，透出了一股沧桑，并散发着阅世经年的气息。一下子，我意识到了刚才对话的 “分歧” 所在：我发现他在提及 “家” 这个字眼的时候，是在说自己的家，他早已成家立业，家中妻儿，与他共同围绕在天伦之乐下，那是他的幸福之家，而当他提及 “老家” 这个词，其实指的是他父母的家。那我呢？我有家吗？有，但这三年来，不常住，恐怕一共也不过几十个日夜。想必谁都能猜的到，无非就是春节、国庆之类的法定节假日。那是我父母的家，也是我的家，我是他们的孩子，这是一个三口之家。所以当他问我户口簿上的出生地是不是我的老家时，我不假思索得说了不：我的出生地当然就是我的家啊，我的老家？那是我爷爷奶奶的家呀。 可是，不常回家的我，离家远去的我，究竟又住在何处呢？于我而言，无论是在北京还是杭州，我的栖息之处不过是从房东那儿租来的十尺地儿。故而独自站在异乡的土地上，我总于内心深处，释放出对口舌的羁绊： 我难以将 “家” 这个词随意得说出口。下班之后，我只是说：“我回去了。” 和别人聊到某件商品，我仅会道：“之前买过，放在我的房间里了。”我小心翼翼得在意着这件小事，生怕越 “雷池” 一步。倘若某天我不小心开错了口，我心里面会感到莫名的失落与难受。同我说话的人或许不会察觉到这般细微的情绪波动，而我也无意惊扰他们，只是在自己心中，尝一把它的酸辛，抿一口它的苦涩，并再一次告诉自己，我是这座城市里的一名漂泊之客。是啊，那只是我租的房子，甚至只能说是我租的房间，安能以家自居？ 不过，家与否的问题，真的只和房子的产权有关系吗？若我亲自买下一套房子而不去租住别人的，就可以找到家的感觉吗？曾经有一个故事：一名警察送一位喝得酩酊大醉的富翁回家。警察说：“先生，我送您回家吧。”富翁却摇了摇头：“家？我没有家。” “那前面这栋别墅是怎么回事呢？”“那只是我的房子而已。”所以我心里明白，问题的本质并不在于房子，而在于内心的认同感。说到底这是个幸福与否的问题，找到幸福的归属，才是真正找到了回家的路。离家的人儿，踏出家门的第一步，便也是迈出回家的第一步。然回家之路千般荒凉，吾将何以为梦？回家之路万里蹀躞，吾又何以为归？ 你站在马路边等车，我站在窗前望着你。这昏暗的房间里，静谧得只能容纳下我指尖落在键盘的嗒嗒声响。平淡的内心下暗流涌动，我迫切得想证明这世上除了我之外还有其他人的存在。于是凭栏伫立，我贪婪得吮吸着窗外的一切。低头玩手机的你，为司机师傅的两声喇叭所提醒，悠然得登上了车。车影远去，载着乘车的女孩，也载着我的梦，去了你那未知的地方。我虽不曾认识你，但你，却装饰了我的梦。 这梦悬在空中，不愿意轻易降临在我的房间，我的身边。几个月来，我一直在努力寻找着那个 “她”，怎奈命运为我准备的回家之路，却是坐落在一场迷宫之内。路漫漫其修远兮，吾将上下而求索，只望不道别离，惟愿不问归期。 回家的醒每个周末，我在同父母打电话时，我爸爸总是会问我：“在‘宿舍’干什么呐？”宿舍？愣神之余，我竟发觉这个词使用得着实恰当。何谓宿舍？宿，睡觉也，舍，房屋也，宿舍，一个提供睡觉场所的房屋。定义相当之精准，我现在住的地方的确有柔软的席梦思，以及温暖舒适的被褥。这不就是我租住这个房子最主要的用途吗？ 但我还是想问，为什么是 “宿舍” 呢？看来，“家” 这个词带着它与生俱来的敏感与多愁，若心中有个结，不管有意还是无意，料都令人难以启齿。“宿舍” 这个词，让我终于听懂了：我所租住的这个房子，不光我自己不愿意承认它是家，我的父母亦不愿意承认它是家。 七年之前我刚上大学的时候，我和爸妈拎着大包小包，走向了我的寝室。进门的那一刻，正是宿舍的模样。我们一起整理好了我的书桌床铺，在这有限的空间里，收拾出了一个五脏俱全的小天地。那一天，我即将告别父母，开启我的大学生活；那一天，我也告别了我的家，告别曾今那个装满了童年幻想的乐园。不得不承认，从 “家” 的角度看，我的身份角色已然发生了转换：我从一个以家为 “根据地” 的稚嫩学生，变成了一个需要在外地闯荡、独立自主的热血青年。在此之后的每一天，我都可能遇上一个什么人，并在更加之后的某一天，与她组成新的家庭。回想二十多年前，我的父母不也经历过这样的事情吗？这是一个轮回，而轮回的起点，正是上大学的那一天。 三年之前我毕业了，父母再一次来帮忙收拾行李：“我们也和你一起毕业！”告别母校，走出寝室大门，回眸的那一刻，还是宿舍的模样。这番印象，早已镌刻在我心上，如今也同样刻在了我父母的心上：“这就是我的孩子曾住过四年的宿舍！” 毕业后的这三年，我从学校走向社会，从一名学生变成了职场人士。纵然社会身份已经完成转变，但我的住所不过是从校内搬到了校外，除了价格翻了几番、环境稍许改善之外，似也没有其他什么区别了。于我父母而言，宿舍的轮廓似已无法在心中磨灭，或许孩子在身边就是家，只要在外，即是宿舍。上学的时候，心中总有个刻度，一年就是一座年级，四年就是一场大学。我渴望升级，父母亦盼望我成长；而现在上班的时候，刻度仍在，却变了味，变成了多久跳槽一次，变成了何时才能找到女朋友。预期在被不断拉长，变成了被多普勒擀出的时间旋涡，惶惶不知尽头何在。不在他们身边的日子里，父母会否盼望我早日回家，“离开” 社会，重新 “变回” 他们的孩子？不在他们身边的日子里，我立于床前，假装俯首揩去地上的白霜。我，有些想家了······ 家是用来回的吗？是，也不是，到不了的都叫做远方，回不去的名字叫家乡；家是用来想的吗？是，也不是，雕栏玉砌应犹在，只是朱颜改。告别父母，置身异乡，现实生活的一大意义，不正是将我们从梦的幻想中拖拽出来吗？逼着我们告别任性的自己，告别彷徨的自己，告别懦弱的自己。回不去的不过曾经的傲娇与玩闹，想不起的只是过去的稚嫩与无知。对未来的憧憬与希望，将灵魂中那片柔弱的芳草地，化作了烈日下舞动的长鞭，令汗水掺和着肿胀，撕裂交织着疼痛，敦促着自己向前迈步，一步一步，找到归宿，找到她，找到心中真正的 “家”！ 在这念想之间，我突然明白了，我所身处的，不仅是一场轮回，更是一场接力赛。从大学第一天开始，父母就向我们伸出了手，手中握着交接棒。整个交接过程，短则数十月，长则数十载。我们会犹豫，会徘徊，会在父母的家与自己的家之间抉择不定。生活与爱情的挫折，令我们颤抖了双手而接棒不稳，但父母只会在背后耐心得追随着我们，永不放手。我们还是回去吧？可我们还是回来了！一次又一次退缩的企图，却让我们一次又一次，明晰了自己的位置与处境。时不我待，只争朝夕，下一次与她的相遇，或许就将记录下我们成功接棒的瞬间，记录下我们蜕变的瞬间！ ······ 我常将我住的房间打扫的井井有条，但我从未有意去装点它。它那么朴实无华得存在着，像柔和的日出日落，像稳健转动的钟表，像磨白无光的铜镜。而一天夜里我真的做了一个梦：一个女孩走进了我的生活，降临在了我的房间里。“家徒四壁” 的外表下，我激动得对她说：“之前我一个人的时候，这里仅仅是我租的房子。而现在你的出现，意味着这里已经是一个家了。我觉得，我们有必要好好装点一下我们的家呢！” 梦醒时分，我微笑着抹去了眼角幸福的眼泪。","categories":[{"name":"life","slug":"life","permalink":"http://zshell.cc/categories/life/"},{"name":"thought","slug":"life/thought","permalink":"http://zshell.cc/categories/life/thought/"}],"tags":[{"name":"思考","slug":"思考","permalink":"http://zshell.cc/tags/思考/"},{"name":"亲情","slug":"亲情","permalink":"http://zshell.cc/tags/亲情/"},{"name":"感情","slug":"感情","permalink":"http://zshell.cc/tags/感情/"}]},{"title":"“一个人” 的社交","slug":"life-thought--一个人的社交","date":"2019-01-01T08:08:40.000Z","updated":"2019-01-23T03:48:18.277Z","comments":true,"path":"2019/01/01/life-thought--一个人的社交/","link":"","permalink":"http://zshell.cc/2019/01/01/life-thought--一个人的社交/","excerpt":"开年第一天，我想写篇文章纪念一下我与我的博客之间的故事。这个博客，它为何而来？它正在表达什么？它将向何处去？这些问题的答案，于我而言，是认真而虔诚的。社交，并非总是在固定时间维度下的空间活动。常言道，读一本书便是在与作者对话，无论是如雨果这样的文豪大家，还是如我一般渺小的普通作者，阅读他们的文字，即是倾听对方的声音，即是探入对方的心灵。这何尝不是另一种形式的社交呢？这样的社交，虽不曾面对面把酒当歌，却能剥离所有的外在，坦诚相待；这样的社交，即使对方的肉身早已灰飞烟灭，却仍然能够化解时间的束缚，在精神层面上，实现纯粹的碰撞与交融。","text":"开年第一天，我想写篇文章纪念一下我与我的博客之间的故事。这个博客，它为何而来？它正在表达什么？它将向何处去？这些问题的答案，于我而言，是认真而虔诚的。社交，并非总是在固定时间维度下的空间活动。常言道，读一本书便是在与作者对话，无论是如雨果这样的文豪大家，还是如我一般渺小的普通作者，阅读他们的文字，即是倾听对方的声音，即是探入对方的心灵。这何尝不是另一种形式的社交呢？这样的社交，虽不曾面对面把酒当歌，却能剥离所有的外在，坦诚相待；这样的社交，即使对方的肉身早已灰飞烟灭，却仍然能够化解时间的束缚，在精神层面上，实现纯粹的碰撞与交融。 起舞弄清影，何似在人间？ 其实，在本博客的 about me 栏目中，我已经详细介绍过了我创建博客的初心以及愿景，那么这篇文章又寓意何在？ 我想这大概是理性与感性的关系吧。在那篇 about me 中，我所表达的是一种理性的思考：确认社会角色，探索行为模式，以及树立人生信念，是主观意识的体现；而这篇文章中，我所表达的是一种感性的认知：重现审美倾向，释放内心渴望，以及追寻浪漫的共鸣，是潜意识暗流的涌动。 两篇文章，相辅相成，共同构成了希尔完整的 “博客人格”。 我为何选择博客今天是 2019 年的第一天。站在此刻，往前看是曲折而难以忘怀的 2018，往后看是充满抉择、机遇与挑战的 2019。昨晚在我的微信朋友圈里，各式各样的人儿都晒出了自己的 2019 年度目标，也有少部分人自豪得展示着 2018 年的目标完成情况。我作为一名特殊的人类成员，当然也会有自己特殊的表达方式，比如现在正写着的这篇文章。 新加我微信的人总是好奇地问我：“你好像不发朋友圈动态，一条都没有哇？”其实这个问题我已经问过自己千百遍了，可以说这个博客的存在本身就是这个问题的答案。或许，我六年前的遭遇也在其中掺杂了一些似有似无的影响，但时至今日，经过不断的思考与经历，我已经完全明白自己到底在做什么，而不是被一些悲伤的情绪所左右。 朋友圈是人们社交的出入口，人们通过展示自己的生活片段与别人交流，互相了解，增进感情。同微博类似，当我们点开朋友圈下拉刷新，我们的视线将被各式各样的信息占有，有想看到的，也有不想看到的，统统进入我们的眼帘。这是一个被动的过程，我们事先并不能预测将获取谁的信息，这些全靠系统投喂给我们。 而我所做的，只是找回快被人们遗忘在从前的另一种表达方式：博客。与微博，朋友圈不同，访问博客是一个主动的过程，我们很确定我们在接受谁传达出来的信息，既然我们愿意进入他的博客，这本身就意味着对他的期待，意味着对他往日博文的肯定。而每次刷朋友圈，有时的确会收获一些惊喜与价值，但它来自于谁，来自于哪个时刻，都是不确定的事情。“朋友”们的动态此消彼长，只要信息的总量保持稳定，没有人会刻意关心谁的动态少了，而谁的动态又多了。久而久之，刷朋友圈变成了一种猎奇，一种感官刺激，真正的人际关系反而模糊了。 微博、朋友圈是为移动端设计的表达渠道，其特点是短小，简单，字数限制，换句话说可能便是浮于浅层，难以深入。这固然降低了使用者的门槛，圈揽了大量用户，但也导致信息生产的质量问题。于是，我们经常看到各种转发的公众号文章，这些公众号在一定程度上弥补了朋友圈信息的质量问题，但是公众号，本质上讲不就是另一种形式的博客吗？在微信的流量生态下，知识分子为了事业上取得更好得发展，不得不转换战场，以跟上目标读者的脚步。于我而言，博客并非我谋生的渠道，所以我并不需要适应移动互联网时代下的新环境。 像我这样另辟蹊径使用传统模式表达自我，其实还有另外一点好处。在没有屏蔽拉黑的假设前提下，我们发表的朋友圈动态会推送到每一位联系人的手机上。我无法预知自己即将发布的内容会不会受到大家的欢迎，我只知道如果有人不喜欢看到我的信息，我的动态也会被推送到他的手机上，接着他很有可能就会把我拉黑。反观写博客，我就不需要承受如此的心理压力，没有人知道我在思考什么，没有人知道我在感慨什么，除非你主动访问我的博客。另外，互联网是连接世界的，访问我的博客根本就不需要认识我，你喜欢便会驻留，不喜欢便会离开，于我而言没有任何区别。 孑然而立的博客当然，我的博客是我内心深处的秘密，我从不轻易公开博客地址，这里是我肆意想象，恣情意淫的天地。而这博客维护了这么长时间，我能察觉到，唯一一名对我保持长期关注的访客，是 google 的爬虫引擎：在 google 上检索相关关键词便会出现我的博客文章。与之相对应的是，百度从来都没有 “感知” 到我的存在，当然这也在情理之中，我使用 “敏感网站” github page 发布博客，使用境外的顶级域名，没做过 SEO，也不作 ICP 备案，政治正确的百度对此一定讳莫如深。 一般而言，人们总是倾向于表达并推广自我，以获得别人的接纳，满足被认同的心理需求，实现内心的价值归属。而我却不希望将我的博客曝光于世界之下，更不打算在微信朋友圈展现自己的面貌，这可能是属于我个人的审美倾向。在我的其它文章中，也会表达出类似的观念：我一直在追求的，是一种缺憾，一种惋叹，心花怒放，而孤芳自赏，红杏含苞，却伏于墙隅，只待世人“蓦然回首，那人却在，灯火阑珊处。” 既然我已决定不轻易公开博客地址，百度也不打算帮我推广介绍，我自然就不用指望会有人关注我了。如此一说，我这个博客的意义，怕是离“社交”的定位有点远了，我对世界唯一打开的一扇门，在实质上却等效于是关闭的。在现代社交网络的世界里，离群索居的我，谁怜一片影，相失万重云？ 皎皎明月，皓然当空，她的美令众人侧目，她的美引嘉赞无数；一颗寒星，孤悬天际，遗世乎凡宇间的热闹，独立于红尘中的来往。众人赏月之际，会不会有一位走心的少年，裹挟着探索与好奇之心，向深邃的夜空一瞥，令那株隐隐若现，那抹微乎缥缈，在其双眸之内留下属于自己的一粒像素？ 对于可能存在的 “黯淡结局”，我其实自打建站之初就已做好了心理准备。“兰之猗猗，扬扬其香。不采而佩，于兰何伤？”我节选韩愈《猗兰操》中的片段作为自己博客的副标题，影射自己的志向：就算没有人欣赏我，于我而言又有何可悲？只需做自己便好，哪怕世间万事万物都背对着我，我和我自己也永远面对着面！ 好在，生活中有一样东西在万物中最为珍贵：希望。希望是一种可能性，就算发生的概率再低，只要不是零，它就配得上叫做希望。墨菲定律说，只要事情存在可能性，那么给足了时间，就总有它发生的一天。我在这里写博客不正是这样的一件事吗？看起来似乎已没什么通达之径指向我的世界，可实际上这个网站一直在与互联网保持着连接！谁又敢说将来的某一天，一定不会有人误打误撞在浏览器里输入了我的博客地址，踏进我为 ta 打开的这扇门呢？ 历史召唤的博客华夏民族的历史是一部苦难之作。落第、贬谪、离亲、亡国，令愤懑、忧郁、悲恸、疾首在文人骚客的心中冲撞回荡。而转身之念，挥斥方遒，激扬文字，脍炙人口的篇章顷然奔泄。文人本也萎靡柔弱，但在自己的文字面前，却显万丈长情。晋出陶渊明“问君何能尔？心远地自偏”，南现李煜“一江春水向东流”；唐成刘禹锡“斯是陋室，惟吾德馨”，宋就文天祥“留取丹心照汗青”。即便命运再残败不堪，即使世道再腐朽不治，一腔情潮，只要找着了文字，便拥有了寄托之处。何谓寄托？于古人言，那是将自己人生的价值追求全数倾注，以不朽的文字为载体，向世人宣告：“零落成泥碾作尘，只有香如故。”他们深信不疑，就算“众人皆醉我独醒”，冥冥之中，也定有真命知己，在未来注定的某一刻，为自己的文字潸然落泪。幸运的是，前辈们的菁华之作已悉数为后世所珍，并至此处为吾感念，遂谨以告慰各在天之灵。 于是从小学，中学，到大学，我们品读诗书，向灵魂深处注入了中华文化的基因。在文学大家的感召下，潜移默化之中，我亦对文字产生了一种深深的依恋，一种模仿前辈的冲动本能般在心中酝酿。一个人如果有千言万语无处诉说，文字将成为其最好的发泄口。就在这一瞬间，前辈的指引，内心的悸动，诉说的渴望，各种复杂的情愫糅杂在一块，一个属于我自己的博客诞生了。 今时不比往日，黯淡了刀光剑影，远去了鼓角争鸣。和平时代的我，在互联网的熏陶之下，没有了壮士断腕的悲烈，多出来的则是宁静的思考，婉转的歌啼，以及，细腻的想象。我想象着，一位读者，于不经意之间闯进了这片田地，柔和的屏幕前，ta 规律得眨着眼儿，一行一行在文字间扫动、跳跃，时而停留在某一段落反复咀嚼，时而又蹙眉思考，有着共鸣之音，亦有着质疑之声；我想象着，在时间的某个角落，历史的必然性教我在这里结识朋友，遇见知己，有没有可能收获爱情呢？ 我愿意等着那个 ta。在那一天到来之前，每一篇文章，都将是庄严的仪式，都将是虔诚的呼唤。一个人能做的事情实在有限，然而一个人能做的事情有时却可以超越时间的界限。“一个人”的社交，其实从来都不是一个人，而是你，我，以及历史星空中的点点繁星，共同筑起的，珍贵的情感纽带，深切的情感寄托。","categories":[{"name":"life","slug":"life","permalink":"http://zshell.cc/categories/life/"},{"name":"thought","slug":"life/thought","permalink":"http://zshell.cc/categories/life/thought/"}],"tags":[{"name":"思考","slug":"思考","permalink":"http://zshell.cc/tags/思考/"},{"name":"生活","slug":"生活","permalink":"http://zshell.cc/tags/生活/"}]},{"title":"fedora 折腾经验备忘录","slug":"life-pc--fedora_折腾经验备忘录","date":"2018-12-15T15:13:49.000Z","updated":"2019-01-22T15:19:30.390Z","comments":true,"path":"2018/12/15/life-pc--fedora_折腾经验备忘录/","link":"","permalink":"http://zshell.cc/2018/12/15/life-pc--fedora_折腾经验备忘录/","excerpt":"当我试图注销重新登陆时, 惊悚的一幕发生了: 黑屏! 近乎绝望般得按下电源键强制重启, 等来的居然是字符登陆界面, 讽刺的是我输入账号密码后, 还登陆成功了……字符界面下, 所有的命令都能正常执行, 可是进不了 tty7, 这系统实质上就是废的呀! 我猜测 gnome 的核心组件大概是被我误删了…… 无奈, 思忖着崩溃前我到底做了什么, 也只能重头再来;","text":"当我试图注销重新登陆时, 惊悚的一幕发生了: 黑屏! 近乎绝望般得按下电源键强制重启, 等来的居然是字符登陆界面, 讽刺的是我输入账号密码后, 还登陆成功了……字符界面下, 所有的命令都能正常执行, 可是进不了 tty7, 这系统实质上就是废的呀! 我猜测 gnome 的核心组件大概是被我误删了…… 无奈, 思忖着崩溃前我到底做了什么, 也只能重头再来; 2018 年 10 月 30 日, fedora 发布了新版本: feodra 29, 令无数 linux 忠实拥趸跃跃欲试;历经各种曲折, 耗费几近半年时间, 我终于赶在 2019 年前折腾出了一个有着勉强模样的 fedora, 装在了我的笔记本上, 甚为欣慰; 这半年间, 我试过了 fedora 26, 27, 28, 以及最新的 29, 一次又一次得蹂躏着我入手没多久的 ssd, 遭遇了各种有厘头, 无厘头的 bug, 缺陷, 宕机, 在 “几乎打算放弃” 的边缘上游走了数月; 可是我心里面总是咽不下这口气, 不把 fedora 搞定我浑身不自在, 就是特想做成这件事, 说是为了装逼也好, 学习也罢, 反正我整个人都豁出去了, 不达目的坚决不罢休, 死不瞑目!于是, 今天终于有了这篇文章, 好好总结一下, 也好好纪念一下; 关键软件安装重要软件源添加添加 rpm fusion 与 FZUG 源 (以 fedora 29 为例):1sudo dnf install https://mirrors.tuna.tsinghua.edu.cn/fzug/free/29/x86_64/fzug-release-29-0.1.noarch.rpm 如果是其他 fedora 版本, 直接参考 官方文档 即可; sogoupinyin 输入法输入法是万物之源, 没有中文输入法, 一个中国人如何正常使用 fedora?搜狗公司也算是个有情怀的公司, 为我们广大 linux 用户开发了 linux 版本的 sogoupinyin; 但是美中不足的是, 它只提供了 debian 系列才能使用的 deb 包, 而没有提供 redhat 系列的 rpm 包; 为了将其移植到 fedora, 我作了一些尝试与努力, 并专门总结了一篇文章: fedora 安装 sogoupinyin 输入法; vimfedora 自带的 vim 是功能简化的 vim, 或者说是功能增强型的 vi:12&gt; sudo rpm -qa | grep vimvim-minimal-8.1.450-1.fc29.x86_64 而在日常脚本编写中, 一个 minimal 的 vim 是不够用的, 我们需要完整版的 vim:1sudo dnf install vim-enhanced jdkpostmanshadowsocks client一般装 shadowsocks client 不会使用 yum / dnf / apt-get 之类的工具, python-pip 直接上:1sudo pip install shadowsocks 其运行命令的选项也是十分的简洁:12345678910# -c CONFIG path to config file# -s SERVER_ADDR server address# -p SERVER_PORT server port, default: 8388# -b LOCAL_ADDR local binding address, default: 127.0.0.1# -l LOCAL_PORT local port, default: 1080# -k PASSWORD password# -m METHOD encryption method, default: aes-256-cfb# -t TIMEOUT timeout in seconds, default: 300 sslocal -s xxx.xxx.xxx.xxx -p 8388 -k \"*************\" -b 127.0.0.1 -l 1080 &amp; 1&gt;/var/log/shadowsocks.log 2&gt;&amp;1 重定向一下命令的标准输出流与标准错误流, 方便故障时排查问题; 不过, 还是不建议直接在命令的选项里配置参数, 更好的方式是加载配置文件, 方便管理也不容易遗忘:1234567891011# /usr/local/etc/shadowsocks.json&#123; \"server\": \"xxx.xxx.xxx.xxx\", \"server_port\": 8388, \"local_address\": \"127.0.0.1\", \"local_port\": 1080, \"password\": \"*************\", \"timeout\": 3000, \"method\": \"aes-256-cfb\", \"fast_open\": false&#125; 1sslocal -c /usr/local/etc/shadowsocks.json 1&gt;/var/log/shadowsocks.log 2&gt;&amp;1 另外, 这里只是 shadowsocks client, 要真正翻出去还需要 server 端的配合, 我在另一篇文章里有具体介绍: 在裸镜像上搭建 shadowsocks server; atombcloud 客户端虚拟化netease-cloud-music网易云音乐客户端虽然谈不上是必装的关键软件, 但是毕竟人家是个有情怀的公司, 专门为 linux 用户出了客户端, 而我之前也拿到过云音乐部门的 offer, 无论如何我对 netease-cloud-music 都是有感情的;同 sogoupinyin 输入法一样, netease-cloud-music 客户端美中不足的是它只提供了 deb 包, 故而我就需要做一些移植工作了, 总结文章链接如下: fedora 安装 netease-cloud-music; 桌面主题设置无论是 fedora, 还是如今高版本的 ubuntu (18.04 及以上), 默认使用的桌面环境都是 gnome 这一通用主流的标准了, 而管理 gnome 的最佳工具是 gnome-tweak-tool:1sudo dnf install gnome-tweak-tool gnome-shell-extension桌面主题个性化的精髓就在于 shell 拓展, 各种方便的工具可以帮助我们展示个性, 优化交互等;之前折腾 fedora 28 时, 我下载收集了一些实用的拓展工具, 并统一整理到百度网盘上; 而现在 fedora 29 将 gnome 的版本升级到了 3.30, 这些插件对于 gnome 的版本要求很高, 连中版本都要对上号, 3.28 的插件在 3.30 的 gnome 环境下竟然不能兼容;12&gt; gnome-shell --versionGNOME Shell 3.30.1 现在我打算放弃这种思路, 毕竟以后 fedora 还会继续升级, 就算我现在将百度网盘上的插件都更新为最新的, 也难保以后能兼容更高版本的 fedora; 所以更好的思路是寻找一个稳定的代理, 去帮助自己实时获取最适配的各种插件;这个理想的代理就是 chrome, 让浏览器帮忙下载, 这需要两样东西: 首先是对应的 chrome 插件: GNOME Shell integration; 与 chrome 插件交互的本地 agent:1sudo dnf install chrome-gnome-shell 这两样东西准备好后, 就可以去 gnome-shell-extension 官方网站 下载插件了; 除了默认带有的, 目前我又安装了如下几个插件: Dash to Dock, 类似于 ubuntu 启动器, 方便用于放置常用的应用程序, 快速启动; Hide Top Bar, 隐藏最上方的管理栏 top bar, 主要用于没有外接显示器情况下的笔记本, 最大化利用屏幕尺寸; 窗口按钮设置fedora 默认情况下的窗口只展示关闭按钮, 而我们需要同时将 关闭, 最小化, 最大化 三个按钮都展示出来才符合使用习惯; 这个设置十分简单, gnome 的一条命令搞定:1gsettings set org.gnome.desktop.wm.preferences button-layout 'close,minimize,maximize:appmenu' 以上配置会让 关闭, 最小化, 最大 三个按钮从前到后分别出现在窗口的左上角, 十分符合 linux 用户 (以及 Mac 用户) 的使用习惯; 系统配置重要的 daemon service(1) fcitx输入法守护进程肯定是要在开机时就启动的, 毕竟打字的场景无处不在; 为了让 fcitx 顺利开机启动, 我竟然费了好些波折:fcitx 是一个 XWindow 程序, 使用 dbus 通信; 而 dbus 是一个仅限于普通用户 session 的进程; 我们配置开机启动, 传统的思路都是使用 systemd 生成对应的 service (早期的系统使用 system V init), 但这种方式仅适用于使用 root 用户启动的非 XWindow 程序, 如果碰到一个带图形界面的程序, 例如 fcitx, 会报类似如下的错误:12(WARN-31472 dbusstuff.c:197) Connection Error (/usr/bin/dbus-launch terminated abnormally with the following error: No protocol specifiedAutolaunch error: X11 initialization failed. 没法启动 X 进程, 和 dbus 无法通信, connection error; 查了一下, 对于这种用户级别的 XWindow 程序, fedora 有非常友好的解决方案: 将需要开机启动的应用的 .desktop 启动配置文件复制到如下目录中:1cp -a /usr/share/applications/fcitx.desktop ~/.config/autostart/ fedora 会在开机后某一个合适的时间点, 回调 ~/.config/autostart/ 下面的所有应用, 从而做到开机启动; (2) shadowsocks client 快捷键设置字体设置定制终端的命令行提示符fedora 终端的命令行提示符默认是和标准输出一样的普通白色, 没有任何区分, 这会导致一个问题: 当屏幕上有上一条命令的输出时, 无法明显得区分本条命令输出的起始位置, 看起来都是白花花的一片, 很费眼睛, 所以我们需要个性化, 酷炫而显眼的命令行提示符;linux 命令行提示符的样式是通过一个叫 PS1 的环境变量控制的, 默认情况下, 它在 /etc/bashrc 中被初始化; linux 不建议使用者直接修改 /etc/bashrc, 而是建议将定制逻辑放在 /etc/profile.d 目录下, /etc/bashrc 会回调该目录下的脚本;所以这里需要创建一个类似于 /etc/profile.d/PS1_reset.sh:12# 重新定义命令行提示符的展示样式export PS1=\"[\\e[m\\e[1;32m\\u\\e[m\\e[1;33m@\\e[m\\e[1;35m\\h\\e[m \\e[1;36m\\w\\e[m\\e[1;36m\\e[m] \\$\" 重新定义 PS1 即可;我上面给出了一个具体的样式案例, 关于它的详细含义就不多说了 (这个相比正则表达式有过之而无不及之处), 我就上一个效果图吧: terminal_new_PS1 ssh / git站内相关文章 fedora 安装 sogoupinyin 输入法 fedora 安装 netease-cloud-music 在裸镜像上搭建 shadowsocks server 参考链接 Announcing the release of Fedora 29 如何使用 GNOME Shell 扩展 修改linux终端命令行颜色 fcitx在 sudo 无法输入的问题 Fedora 28 - startup application","categories":[{"name":"life","slug":"life","permalink":"http://zshell.cc/categories/life/"},{"name":"pc","slug":"life/pc","permalink":"http://zshell.cc/categories/life/pc/"}],"tags":[{"name":"life:pc","slug":"life-pc","permalink":"http://zshell.cc/tags/life-pc/"}]},{"title":"情感安全绳","slug":"life-thought--情感安全绳","date":"2018-12-02T08:21:12.000Z","updated":"2019-01-13T08:35:10.194Z","comments":true,"path":"2018/12/02/life-thought--情感安全绳/","link":"","permalink":"http://zshell.cc/2018/12/02/life-thought--情感安全绳/","excerpt":"最近我的思路有一点悲观，在大量思考着那些 “最坏的打算”。可能是宏观形势所迫吧，在经济周期末期，中美对弈的大背景下，保值，落袋，避险等逐渐走向了聚光灯下，这样的外部语境，再结合我个人经历的内部语境，我心中逐渐酝酿出“情感安全绳”的概念来。如果要用一个词语概括一下它的含义，我想应该是：“对冲”。没错，我觉得非常恰当，就是这两个字。","text":"最近我的思路有一点悲观，在大量思考着那些 “最坏的打算”。可能是宏观形势所迫吧，在经济周期末期，中美对弈的大背景下，保值，落袋，避险等逐渐走向了聚光灯下，这样的外部语境，再结合我个人经历的内部语境，我心中逐渐酝酿出“情感安全绳”的概念来。如果要用一个词语概括一下它的含义，我想应该是：“对冲”。没错，我觉得非常恰当，就是这两个字。 安全与保险风筝因为有了线，我们才敢放之于天空翱翔；车儿因为有了刹，我们才敢驾驶其于路面奔驰； 蹦极时我们并不会真正感到害怕，因为身上有一根绳在拉着；跳伞时我们也不会感到恐慌，因为肩上的装备将为自己撑起一个有力的面； 断了线的风筝将随风远去，最终坠落在无名之地；坏了刹的车儿将失去控制，最终车毁人亡； 没有了安全绳或者降落伞的保护，大家定然不敢从极高之处纵身一跃，因为那意味着死亡； 当我们在渴望一件事情的同时，却同时需要与我们的渴望相反的力量，只有接受这种力量的制约与归束，我们才能有效得控制住自己，才能在追求的道路上不断得持久得走下去。我想这个道理适用于生活中的很多场景。 偶然之间，我开始思考这个规则是否能够同样迁移到情感关系中去：当我们在努力追求幸福，当我们在认真经营感情时，如果突然遭遇不测，在我们即将坠入旋涡无法自拔之刻，可不可以有一根绳子出现在手边，将我们从深渊中拉上岸？ 我想，在感情上受过伤的人或许非常渴望能拥有这样一根绳子：我们都不希望将痛苦重新复制一次，但却也十分渴望爱情，渴望真正遇到一个值得相伴一生的人，全心投入，与其共同结出丰收的硕果。如果能有这样一根绳子，无异于为爱情上了一份保险，令幸福多了一份保障，使我们得以敞开心扉，大胆得追求，不必担心，也无需犹豫。 保险的意义，不就是以一个微小而可控的代价，为我们这充满各种不确定的生活，换来一份安定与缓冲吗？我相信，乘坐飞机，买一份航空意外险，没有人会认为你是怕死鬼，认为你在诅咒飞机坠亡；健康的你，为家人买一份重疾险，并不会因此遭来亲人的不满，认为你在期望他们患病倒下。这些不幸的事情，没有人希望它们发生，但我们又没有绝对的实力，完全阻止它们可能的存在。如果没有准备，当噩耗真正传来时，我们的生活将被无情地摧毁，谁也无法回避。 为生命，为健康，为财富附上保障，已经成为了我们的共识。但是如果被保障的对象是一段感情，很多人在心态上却全然无法接受，一个典型的例子就是：婚前财产公证，这成为很多情侣踏入婚姻殿堂前最后一块羁绊。“难道你以为我和你在一起是为了你的钱吗？”这是一个很容易令对方哑口无言的问题：你确实感觉的到，两人的感情很好，你们是因为爱而走到了一起，钱算什么？所以你也开始怀疑，难道真的有必要去作婚前财产公证吗？这岂不是对这段婚姻的侮辱？可是你转念又想，感情好的是现在的你们，但不一定是将来的你们，人是可以变的。“所以你根本就对我们的爱情没有信心，那我们又何必要结婚呢？”是的，谁也不希望大家婚后不幸福，只是那么多活生生的悲剧摆在面前，你又有何特别之处，敢说这种事情绝不可能降临在你们身上呢？ 可是，如果没在感情上经历过挫折，捧着一尊无暇的爱情理想，将很难接受这种事情，婚前财产公证，有时竟成为一段缘分的死亡陷阱。不过，我接下来所设想的“感情保险”，与有形的事物没有任何关系，它可以是只存在于自己心里的秘密，所以相比于婚前财产公证，“风险”要低很多。 情感安全绳我是一个近视度数比较高的人，左眼五百，右眼三百。不过，在前往世纪佳缘与约好的女孩见面时，我从来不带眼镜，这样我将只能看见女孩模糊的面庞，而看不清她的真实容貌。我故意这么做，因为我不想因为相貌因素而扰乱我对女孩的判断，在模糊的视线下，我可以更加集中精神与她交流，以获取我真正想了解的信息。 于是我遇到了现在这位女孩，从性格、职业、爱好等来看，感觉都挺合适，我们加了微信。在进入她的微信朋友圈之前，我对她的映像可以说是相当好的，但是等我看到她发的朋友圈动态，等到她清晰的照片毫无遮拦地进入我的视线，我产生了一点小小的失落感。 没错，我之所以不带眼镜，就是为了应对这种情况，为了避免偏见，避免以貌取人。虽然道理我们都明白，但是内心却依旧很“诚实”，所以我才使用这种强制的方式来促使我“服从”道理。现在无论她是何等容貌，我都必须承认，抛开所有外在的东西，她确实是个不错的女孩。或者从另一个角度想，如果我是一个盲人，那我现在一定会发自内心得对她感到满意（当然，如果我是盲人，她可能就不愿意同我交往了）。 这个时候，我须要静下心来思考，我想追求的，到底是怎样的另一半？ 显然不是为了一个外在的艳丽。人总有老去的时候，不消二十年，我们都将褪去当前的年轻模样，剩下的是见识，视野，灵魂和思想。人生七八十载，从情窦初开到步入中年，属于外表的荷尔蒙时代终究是短暂的。所以，摘下眼镜，当视线朦胧的那一刻，心里面反而更加清晰，更加坚定了：外貌的缺憾，无足一顾，内心的契合，才是真的可贵。 想要遇见完美无缺的人实在是太难，更何况在完美无缺者的眼中，我们却反而是一个各种缺点的集成者。所以，欣赏对方的优点，同时也需要包容对方的缺点，求同而存异，抓住大美而放下小丑，唯有如此，才能与人携手向时间纵深处前行。当恋人的缺点攥在自己手里时，愚钝的人控制不住得将其放大，满腹牢骚，抱怨连天；睿智的人则理智对待，甚至循循善诱，将对方的不足加以引导，领向另一番别致的天地，化腐朽为神奇。 而我想说的是，攥在自己手里的，不仅仅是恋人的缺点，也是为自己订制的一份“保险”，它无形却有踪，它的存在与否完全取决于自己，它是一种平衡，我将其定义为：情感安全绳，一条由自我把控，可以在心中变魔术的绳。在感情上升期以及感情稳定期，恋人的缺点是唯美风景中的一层雾霭，当我们用手轻轻拨开，秀色风光尽收眼底；当感情发生变故，遭遇抛弃或打击之时，这样的缺点就化身为结实稳固的绳，曾经我们包容它是因为爱，而现在爱已落空，它便成为我们宽慰自我，放下感情的手段，抓紧它，向上爬，我们得以顺利得从跌落的歧路中重回正道。 “我把我整个的灵魂都给你，连同它的怪癖，耍小脾气，忽明忽暗，一千八百种坏毛病，它真讨厌。只有一点好，爱你。”可是，如果没有了最后那一点好，就如王小波前面一句总结的一般：它真讨厌！讨厌到我需要立刻远离你，接着长长地舒一口气。 这样的描述或许夸张了些，但这并不是在刻意黑化前任，而是当心态跌入了极左之境，顺势以一股反向朝右的力量将其拉向平衡。这些话当然没有必要通过外在的途径宣泄出来，就让心中的摆钟自己去校准吧。当内心重新回归，若是没有背叛和伤害，就将这段关系当作美好的回忆珍藏在心中吧；若是因为不懂得珍惜而辜负了真心，这样的人也必定是无法配得上为之倾注心血的。总之无论如何，要相信，下一次，我们将遇见更好的人。 再回到我自己身上，尽管曾经心有余悸，六年不敢再爱，然今非昔比，我已在心里为自己编织好了一根绳，从而可以大胆放手迎接任何可能性。我会做一个睿智的人，当彼此互相拥有时，就尽心用爱去包容，若失去她，则双手握紧这情感的安全绳。 另一种形式作为一个在南京走完自己快乐学生时代的人，如今身在杭州，当如“别是一番滋味在心头”：我刚来杭之时，还有几位北京认识的老同事在杭州。不消半年，各位皆已离杭回北，只留我一人独守“空城”，孑然一身。另外，在我毕业之前，我最好的朋友，熟悉的同学，关系不错的老师，以及我的亲戚，基本都在南京发展。在我的人脉关系结构中，杭州是一座孤岛，而我却身陷其中。正因此，独处的时间多了，我便沉浸于思考之中，并不厌其烦得堆砌着这些个文字。也正因此，我开始寻觅被我搁置已久的爱情。 我何尝不想回南京？互联网巨头已经开始着力布局南京，金陵古城已然不是当年的互联网沙漠，这些变化就在这短短的一两年内发生了。想去年我会选择杭州，是因为时机不成熟，在南京没有找到合适我的职位。今非昔比，我现在完全可以在南京找到理想的职位，而不会比杭州逊色。 于是我和自己约定了一份协议：截至明年六月，在我来杭满一周年之际，如果仍未找到值得相伴一生的人，我就离开杭州，打道回宁。然而只要在此期限之前遇见了合适的人并确定了彼此，除非关系破裂，否则不考虑回南京。 这是一个平衡代价与收益的博弈。首先，我肯定是需要一个 deadline 的，绝不可能无止境得等待与寻找，这样做的机会成本无法控制。一年对于我来说是一个关键的时间：从个人职业发展的角度看，互联网行业，在一个公司任职一年时间，虽不算长，但也不能说短，这是行业特征，如果选择明年年中离职，我的简历不会因此而给下一位东家的 HR 留下不好的印象；从个人情感的角度看，如果经历了一年仍未找到那个她，确实可以考虑换一下大环境，毕竟继续当前状态下的边际效益已经大大降低了。不过，一旦找到了真正合适的人，我绝对不能因为我的地域情结而错过她：我在杭州已经苦苦不得缘分而如此挣扎，我又有何等胆量敢说自己回南京之后一定会比杭州更加顺利呢？机会难得，稍纵即逝，一旦错过，或许后悔一生。 更进一步说，南京就是我最后的阵地了，无论是现实生活中，还是我的内心里。什么叫最后的阵地？就是坚守到最后一兵一卒，直至全部阵亡，全军覆没，因为再往后，根本退无可退了。此时的我对南京依然充满了无限的向往（怀念），换句话说这叫生活的希望，无论我在杭州有多么不顺心不如意，只要想起南京，我就依然对未来保留着信心，假想着自己衣锦还乡，与朋友重逢相聚的场面。可一旦真的回去了，一个大大的陷阱或许就横亘在我面前，就像很多美好的事物，在得到其之前，总是令人怦然心动，而待到真正拥有时，却又失望满盈。我从北京来到杭州后的经历，不就是一个活生生的例证吗？我从北京来到杭州尚且有南京这一条退路，倘若我再从杭州回到南京，就是孤注一掷，最后一搏了，赌输了，就是命了。如此说来，有些话只有烂在肚子里才有它的意义，有些憧憬只有不去实现才能体现它的价值。 如此一看，这般的憧憬，这般的希望，这般的怀念，还是节约着使用为妙。不到万不得已，不到大限将至，不可随意挥霍。当在某些极端事件的冲击下，比如为情所伤，悲楚欲绝之际，我们才有充分的理由祭出这一手底牌。《乱世佳人》的女主角，在小说结尾男主角执意放下她抽身而去后，并没有绝望得了此一生，而是满怀希望得鼓励自己：“我要回塔拉庄园，那里才是我的家，明天又是新的一天了。”所以说，当我们心中有这么一片土地，这么一座城市，它是否也可以类似地，成为我们心中的情感安全绳？它曾经带给我们快乐，它构成了我们美好的青春回忆，遭受情感挫折的我们，如果有机会回去那里重整旗鼓，兴许会感慨：另外一座城市的她像是鱼，而这座城市就是熊掌，二者不可得兼，如今放下了鱼，才有机会重新拾起熊掌。 这样的情结是否可以算得上是对憧憬价值的兑现？不管其最终是否被证实为一个陷阱，真到了那一刻，我想这一着棋当值得一走吧。相较于失恋的痛苦，那些北漂，沪漂，深漂，杭漂的人儿，改变一下环境真如举手之劳：不过是举起手抓住身旁的情感安全绳而已，又何苦在深坳中自寻烦恼呢？ 当然话说回来，针对我目前的情况，我必将严格执行协议的内容，理智需要排在第一位，不可以被情绪所左右。半年后我究竟会不会回到南京，拭目以待吧。","categories":[{"name":"life","slug":"life","permalink":"http://zshell.cc/categories/life/"},{"name":"thought","slug":"life/thought","permalink":"http://zshell.cc/categories/life/thought/"}],"tags":[{"name":"思考","slug":"思考","permalink":"http://zshell.cc/tags/思考/"},{"name":"情感","slug":"情感","permalink":"http://zshell.cc/tags/情感/"}]},{"title":"fedora 安装 sogoupinyin 输入法","slug":"life-pc--fedora_安装_sogoupinyin_输入法","date":"2018-11-29T15:00:24.000Z","updated":"2019-01-22T15:16:07.902Z","comments":true,"path":"2018/11/29/life-pc--fedora_安装_sogoupinyin_输入法/","link":"","permalink":"http://zshell.cc/2018/11/29/life-pc--fedora_安装_sogoupinyin_输入法/","excerpt":"搜狗公司也是一个有情怀的公司, 不过除了情怀之外, 我觉得还有责任在里面; 试想: 如果 sogoupinyin 不推出 linux 版本, 那 linux workstation 在中国的发展会增添多少阻力? 连输入法这一最频繁使用的工具都搞不定, 纵使我们这些拥趸再忠诚, 也只能算是痛苦郁闷的拥趸, 而不是真心诚意, 心甘情愿得使用 linux, 享受 linux;所以, 我觉得搜狗公司的程序员一定会认为, 开发 linux 版本的 sogoupinyin 是一项神圣而伟大的光荣事迹!","text":"搜狗公司也是一个有情怀的公司, 不过除了情怀之外, 我觉得还有责任在里面; 试想: 如果 sogoupinyin 不推出 linux 版本, 那 linux workstation 在中国的发展会增添多少阻力? 连输入法这一最频繁使用的工具都搞不定, 纵使我们这些拥趸再忠诚, 也只能算是痛苦郁闷的拥趸, 而不是真心诚意, 心甘情愿得使用 linux, 享受 linux;所以, 我觉得搜狗公司的程序员一定会认为, 开发 linux 版本的 sogoupinyin 是一项神圣而伟大的光荣事迹! 与之前在 fedora 上安装 netease-cloud-music 类似, sogoupinyin 输入法官方也是只提供了 ubuntu 版本, 而没有 fedora 版本; 民间一些 fedora 爱好者打包了 fedora 环境下的 sogoupinyin rpm 版本, 但是存在严重的 bug (怀疑内存泄露), 当输入字符达到一定量时, 便卡死无法继续输入, 只能重启 sogoupinyin 进程;很明显使用民间的版本是无法高效而专注得工作的, 所以我只能模仿之前 netease-cloud-music 的路数, 下载 ubuntu 下的 deb 包, 解压提取里面的关键内容自己安装了; 安装步骤(1) 停止 ibus 守护进程ibus 与 fcitx 这两个 linux 输入法架构同时只能有一个运行, 而 sogoupinyin 使用的是 fcitx 架构, 所以必须停止 fedora 默认的 ibus-daemon 进程;1ibus exit (2) 安装 fcitx1sudo yum install fcitx 同时配置 fcitx 的启动环境:1234# .bashrc 添加如下变量export GTK_IM_MODULE=fcitx export QT_IM_MODULE=fcitx export XMODIFIERS=\"@im=fcitx\" (3) 下载 sogoupinyin 软件包:我这里已经收集了搜狗最新发布的版本 (2018.4.24): 下载地址, 可以选择 2.2 或者 2.1 版本, 都不会有内存泄露的 bug 存在;然后就是和 netease-cloud-music 差不多的步骤了:1234# 解压 deb 包ar vx sogoupinyin_2.2.0.0108_amd64.deb# 将最核心的 data.tar.xz 复制到系统目录中sudo tar -Jxvf data.tar.xz -C / 下一步比较重要: 将 sogoupinyin 库导入 fcitx 中, 以使 fcitx 识别并统一管理;123sudo cp /usr/lib/x86_64-linux-gnu/fcitx/fcitx-sogoupinyin.so /usr/lib64/fcitx/fcitx-sogoupinyin.so# 检查一下是否具有执行权限sudo chmod +x /usr/lib64/fcitx/fcitx-sogoupinyin.so (4) 安装 fcitx-configtool (5) 启动输入法1234# 启动输入法核心驱动fcitx# 启动 sogoupinyin 面板sogou-qimpanel 下载关键依赖在以上安装过程中, 可能会遇到一些依赖问题需要解决 (主要是启动 sogou-qimpanel 时), 我已经将这些依赖都收集起来了: 下载地址;依次安装即可:12sudo yum localinstall lib64qtwebkit4-4.8.2-2-mdv2012.0.x86_64.rpmsudo yum localinstall libidn1.34-1.34-1.fc29.x86_64.rpm 遇到的坑在本次安装过程的探索中, 还遇到了一些比较深的坑, 这里也一并总结一下: ibus 与 gnome 存在一些依赖关系 (依赖了 gnome-shell, gnome-session 等, 但是又没有真正去使用), 所以刚我开始不是停止 ibus-daemon 进程, 而是试图去删除 ibus 时, 把 gnome 的关键组件也一并删除了, 结果等我下次再进入系统时, 登陆 tty7 直接黑屏, 图形界面用不了了;相关的文章说应该使用 yum erase ibus 而不是 yum remove ibus 便可以避免, 我之前在 fedora 27/28 上测试好像是没问题的, 但是在最新的 fedora 29 上 erase 和 remove 没有区别, 命令执行完桌面系统就崩了; 我查了一下 manual 文档, fedora 29 直接将 yum 重定向到 dnf, 并在其中说明 erase 被 deprecate 了, 请使用 remove;所以我只能将 ibus-daemon 进程停止而不能删除它了; 站内相关文章 fedora 安装 netease-cloud-music 参考链接 fedora20 安装搜狗输入法及各种问题的解决","categories":[{"name":"life","slug":"life","permalink":"http://zshell.cc/categories/life/"},{"name":"pc","slug":"life/pc","permalink":"http://zshell.cc/categories/life/pc/"}],"tags":[{"name":"life:pc","slug":"life-pc","permalink":"http://zshell.cc/tags/life-pc/"}]},{"title":"孩之生日，母之难日","slug":"life-thought--孩之生日，母之难日","date":"2018-11-19T13:40:56.000Z","updated":"2019-01-22T15:31:38.098Z","comments":true,"path":"2018/11/19/life-thought--孩之生日，母之难日/","link":"","permalink":"http://zshell.cc/2018/11/19/life-thought--孩之生日，母之难日/","excerpt":"生日，纪念着生命的诞生，度量着生命的年岁。生日是快乐的，蛋糕前许愿的人儿又长大了一岁；生日是严肃的，静坐闭目冥想中反思着又一年的收获；生日是痛苦的，产房中撕裂的叫喊化作了人类文明延续的沉重代价。","text":"生日，纪念着生命的诞生，度量着生命的年岁。生日是快乐的，蛋糕前许愿的人儿又长大了一岁；生日是严肃的，静坐闭目冥想中反思着又一年的收获；生日是痛苦的，产房中撕裂的叫喊化作了人类文明延续的沉重代价。 往日之态从早到晚，我今日收到生日祝福的顺序如下：妈妈，招商银行，中国联通，东吴证券，爸爸，支付宝，google。 我已经有十五年没有为一年中这“特殊”的日子在心中产生丝毫的波澜了，上一次高兴得过生日还是 2003 年我十岁的时候。后继的时日里我如一尊入定的石佛，不喜不悲，平和而淡定得踏过了十五座春秋，似一本书将十五页纸轻轻翻过。这几年在步入社会之后，我稍稍令其变得与其他日子有些不同：每当这一天来临，我便以闭目冥想的方式反思自己走过的又一年，而今天，下班后回到家，我正在写着这篇文章。 早几年前 QQ 还没有销声匿迹的时候，我记得当一个人的生日临近了，QQ 便会向这个人的所有联系人推送，告诉大家这位朋友的生日快到了，快去送上祝福吧。可惜了一旦填写了生日，QQ 就不允许取消设置，只能修改。为了避免 QQ 引导别人向我送祝福，我只好在我生日前差不多一个月的时候，把我填写的出生日期给改到半年后去，等到我生日过了差不多一个月，再给它改回来，这样我就成功令大家“遗忘”了我。此中乐趣，不足为外人道也。 我曾仔细得思考过我这种奇怪心理的动机：说白了，我之所以会如此平静，是因为我不觉得，在这一天之前，与这一天之后，我的生活会有什么变化。该付出的努力一丝不能松懈，该承受的压力一毫不会减少，每一天都在迎接新的生活挑战。如果这一天的心情激昂而上，第二天难免又回落至常态，到头来只是徒添怅惘。 我发现，与我这种心境类似，却又形成鲜明对比的是处于耄耋之年的老人：他们也不需要在乎生日了，来自晚辈长寿云云的祝福，于当事人不过虚言罢了。年岁至此，于夕阳之下拄杖前行，每一天都可能是最后的绝唱，只有当清晨沐浴在新的日光之下，才是从心底生发出的由衷感谢。 在我的微信朋友圈里，时不时得有人晒出自己生日聚会上的美照，幸福的表情洋溢在脸上。对于她们来说，那应该是发自内心的快乐吧。想必大部分人都不会如我一般，竭尽全力得让自己消失于众人的视野之下，竭尽全力得将自己的心境保持为长久的低谷，深涧的细流。每个人的认识，期待，追求都不一样，我们需要尊重自己的感受，更要尊重他人的感受，每个人都有属于自己的仪式，去迎接自己生命中的特殊之刻。所以，如果今后有一个人可以和我一起生活，在她的生日那天，我一定会用心策划，给她惊喜，满足她的期待，而在我生日的那天，我只希望能和她如平日里一样，自然而充实得度过这一天。 新的理解是的，纪念生日，每个人的方式千姿百态。而在这万态之间，有一种最为特殊，自古以来穿越了整个人类文明：我们向世界问候的第一声啼哭。生命在其中酝酿，母亲在倚头微笑，怀中的婴儿可知这微笑背后的辛酸泪？ 2018 年 11 月 9 日，刘强东的妹妹刘强茹，在临床生产时因羊水栓塞不幸去世。她是一个高龄产妇，43 岁怀孕，这或许是其发生意外最致命的因素之一，不过在此之上，还意味着另一个事实：即便再有钱，在生育这件事上，也和普通人面临着同样的危险，同样也有医生回天乏术的时候。 我们每个人活着来到这个世界，并非理所当然，这是我们的母亲冒着生命危险换来的。在几百年前，黑暗的中世纪，当女孩得知自己怀孕，要做的第一件事情是：立遗嘱。即便医学技术高度发达的今天，我们的分娩死亡率也没有低到令大家觉得可以忽略不计。就算母子平安无恙，但分娩的痛苦，现代的女性同几百年前的女性也没有什么差异。我的一位同事，其夫人几乎被折磨了两天后才终于分娩成功，他激动得说道：要爱妻子一辈子，恨这个小男人一万年！ 故曰：孩之生日，母之难日。如果我们正在为自己庆生，又或者我们正在闭目回顾，我们都不能够忘记，很久之前的今天，我们伟大的母亲，冒着生命的危险，熬过了巨大的痛苦，诞下我们，并赐予了我们生命。而妈妈又总是第一个为我们送上生日祝福的人，不是因为她们忘不了当年的痛苦，想让我们也一同记住，而是因为她们看到自己的孩子又长大了一岁而真心感到高兴，这就是母爱！ 感谢妈妈！ 参考链接 “羊水栓塞”，何以如此凶险？","categories":[{"name":"life","slug":"life","permalink":"http://zshell.cc/categories/life/"},{"name":"thought","slug":"life/thought","permalink":"http://zshell.cc/categories/life/thought/"}],"tags":[{"name":"思考","slug":"思考","permalink":"http://zshell.cc/tags/思考/"},{"name":"亲情","slug":"亲情","permalink":"http://zshell.cc/tags/亲情/"}]},{"title":"一位爱情初级玩家的偏见式独白","slug":"life-thought--一位爱情初级玩家的偏见式独白","date":"2018-11-11T06:48:44.000Z","updated":"2019-01-20T08:39:33.397Z","comments":true,"path":"2018/11/11/life-thought--一位爱情初级玩家的偏见式独白/","link":"","permalink":"http://zshell.cc/2018/11/11/life-thought--一位爱情初级玩家的偏见式独白/","excerpt":"2018.10.27 ~ 2018.11.05，一周多一点儿的时间，却如同历经了一岁枯荣。在爱情这场人生游戏里，我刚迈出第一步，却又将脚缩了回来。技能的缺失，经验的空白，让我这么一位初来乍到者感到了前所未有的迷茫。但我没有选择，逝者如斯夫，犹豫不前将导向不可逆转的败局。我只能不断摸索，凭借着本能的反应，以及单身这么多年来建立的固有认知，以自己 “独特” 的方式闯入 “这场游戏的主战场”，开启 “战斗 - 挫败 - 总结 - 提升” 的玩家晋级之路。","text":"2018.10.27 ~ 2018.11.05，一周多一点儿的时间，却如同历经了一岁枯荣。在爱情这场人生游戏里，我刚迈出第一步，却又将脚缩了回来。技能的缺失，经验的空白，让我这么一位初来乍到者感到了前所未有的迷茫。但我没有选择，逝者如斯夫，犹豫不前将导向不可逆转的败局。我只能不断摸索，凭借着本能的反应，以及单身这么多年来建立的固有认知，以自己 “独特” 的方式闯入 “这场游戏的主战场”，开启 “战斗 - 挫败 - 总结 - 提升” 的玩家晋级之路。 释然感谢这一周的时间，有你从我的生活中走过。 这一周仿佛很漫长，有紧张和期待，有兴奋和快乐，也有焦虑，以及，最后的惆怅，如同上帝赠予我的一本小小恋爱指导手册。酸甜苦辣，别样滋味，悉数为我品尝，不啻一段动人的爱情故事。 说实话，我竟真有种恋爱的感觉，这感觉在我身体里如小鹿乱撞，令我心神不宁，令我寤寐无眠。现在结束了，一切终归平静，多情应笑我，早生华发。 人海茫茫，一缘难求。相遇如同分手埋下的伏笔，甜蜜似是哀伤垂下的鱼钩。生活无常，聚散流沙，前路漫漫，蹀躞万里。但我相信，只要真诚不减，挫折不过谈笑间的樯橹；只要信念不折，困难只是霓虹中的蜃楼。 生活暂告一段落，而来路方长。愿你我都能易装换马，再度出发！ 滋味失去女朋友是什么感受？大概就是现在傍晚时分，秋雨微停，空气清爽，男男女女走出办公楼，享受下班后的惬意，而我却再也不能联系她，与她共同分享这等美妙的时光。 我为何会有失恋般的惆怅？六年前，我的第一段感情持续了两个月。之后的哀思如一江春水滚滚东逝，尽管岁月的洗刷冲淡了愁情，但时至我来到杭州，依旧细若游丝，挥斩不断。而这一次，仅仅是一周之缘，她并不算我的女朋友，我们甚至也只有过一面之谋，当是萍水相逢而已，可固执的我还是没能摆脱多愁善感的毛病，身陷过往的覆辙之中。 在我的理解里，一段关系中的男女，只有双方都尽心尽力，才能将关系维系下去。倘若一方走了心，很快便能被另一方所察觉。有人曾对我说，初次见面是互换一个初始印象，并决定是否可以尝试交往；第二次见面应该察言观色，考察互相的修养与品味；第三次见面可以深入的交流，探究对方的理想与追求。三次见面后如果互相都感觉不错，双方就可以专注得投入到一段感情中了。可是，我认为感情并不是个有章可循的手艺活，每个人的性格迥异，所能接受的交往方式也千差万别，固化的内容未免教条。比如我就倾向于在第一次见面交流中就去了解最关键的基本面，如果我觉得没有问题，值得交往，我就会全力投入其中。琐碎的细节与瑕疵，只要没有让我感到足以影响我对她大方向上的判断，我都不会介意，求同存异是我一向的态度。 作为一个一旦点燃，便热情如火的我，所对面的交往对象可能是一个腼腆内向的女孩，但这不是什么问题，我并不期望对方一定要主动，我只希望我的主动能换来对方真诚的回应，我明白尽心尽力并不是具体到行为上的刻意要求，而是每个不同的人，在自身的性格与特质下从内心不由自主生发出的情感与反应，其是否尽心尽力，关系中的另一方是可以清晰感受到的。我会与她分享乐趣，分担烦恼，探讨真善美，感悟人生，她快乐我便快乐，她难过我也难过。总之，她会完全融入到我的生活之中，我的生活从此不可能存在没考虑到她的地方。 既然每个人所能接受的交往方式不可一概而论，那么必然会有人无法接受我这种火焰般的热情。保守的女孩将本能得排斥我，扑灭我刚刚对她升腾起的热情。没关系，感情本就是双向的，轻轻得退出就好。不过，我绝不会因为女孩的保守性格而改变我追求她的方式，事实上，我也改变不了，天性使然。能自然而然走到一起才算是缘分，没有缘分而强求缘分，何苦这般逼迫自己，扭曲了个性，到头来还不是画虎类犬，落得一个分手的狼狈结局。 固然，第一次的见面无法面面俱到，就算开始互相吸引，也总可能有那么一天，我们发现对方其实不是自己想找的那个人。失望过后，就要面对如何退出的问题。我其实直到现在也不确定，从上周五之后，她几乎就是突然地，不再认真得回复我的微信消息，这是否就是她寻求结束关系的方式，只是她不肯由她那一边主动把话挑明，她希望我能明白她的意思并好自为之？反正从那之后，我便陷入了莫名的焦虑之中，寝食难安。我的耐心被一点一点消磨，直到我主动提出结束关系前的那一刹，彻底化为乌有。 折好的纸飞机刚一掷出便栽倒在地；睁开眼的小鹿刚一迈步就失去重心；醉人的烟花刚一绽放就殒身天地；剔透的雪花刚一落地就遁于无形。我不安地发现，一对恋人的未来之路，竟是荆棘遍布：生活爱好，生活习惯，消费观，房子，车子，彩礼，婚礼，生育，教育，养儿，养老······每一关背后都安置着致命的陷阱。两个人之间的分歧就如同枝枝桠桠的树木，每一处分叉，都是一次考验，每一处分叉，都可以是分手的理由。我曾经历过的两段关系，无一不是早早夭折，上帝似乎在看我笑话，看我这存在先天缺陷的性格，如何演绎一段段滑稽的情感闹剧。要知道，每一关考验都艰难险阻，然在任何一关失足，都意味着前面闯过的关卡都前功尽弃，只能从头再来。 我现今的状态，大抵还徘徊在第一关：沟通，因为我的前两段经历，应该都没有通过这一关。第一段感情，在对方提出分手之前，我甚至都没有意识到问题出在哪里，最后还是对方隐约为我指出了一些方向。第二段经历，也就是这一次，我有了沟通的意识，但是由于自己的性格原因，最终还是酿成了遗憾。在发现微信渠道受阻的情况下，我尝试着给她打电话，没有料到电话对面传来的声音却是别样的动人，别样的真诚，让我不敢相信这和微信里的她是同一个人。果然，挂掉电话，再次回到微信中，她还是和原来一样冷落我，这大概就是理想与现实的距离吧，我最终选择了放弃。女孩的心思难以揣度，像孩童吹起的泡沫，远观无法窥见其细腻的纹理，近看又在亲昵的触碰下乍然破裂。当遭遇无法解释的行为，不着边际的猜疑开始在我心中作祟：就像上面小节中所描述的那样，我至今都无从得知她在微信里疏远我的原因，莫非是她真的很忙？莫非是信号不好？莫非她正经历每个月必定来拜访的烦恼？不猜了不猜了，恐怕误会本身都已经被我误会了。 只能说，这第一关沟通，是后续所有关卡的基础，没有沟通就无法化解矛盾，没有沟通两个人就很容易走向不同的分叉，越走越远，最后形同陌路。这段关系过后，我突然变得能接受打电话这种沟通方式了，我大概想通了，微信与电话，无非是形式的区别，不是战略与战术的关系。只要电话里能谈的来，终归是有机会拉近彼此的距离的，我必须得接受这种方式，两段关系的失败结局已经给了我足够的警示。下一段缘分的到来，我希望能真正把握好，闯过第一关，并有机会接受后续更多关卡的挑战。 但我内心还是有有所不解，一段关系中，男孩作为相对主动的一方，女孩作为相对被动的一方，我去追女孩子，我尽量使用女孩乐于接受的方式去接触她，这无可厚非。但是，如果女孩对男孩真的有好感，并渴望与他交往，难道不应该考虑一下男孩的感受？你说你对我的印象还不错，可是你如此冰冷得回应我发给你的微信消息，就算我对你爱的深沉，也无可避免被你的冷漠所伤害。我不相信一个还对我有好感的女孩子会作出这般无情的事情，所以我只能选择退出，否则每一天对我来说都是煎熬。 再继续往更深处回味，我发现了更多之前未曾察觉的事情。我把自己置身于一个假设性的场景之中：如果她没有如此良好的家境，如果她在杭州没有房子，然后把我们这一周的经历回放一遍，我能坚持到第几天？这真是一个毒辣的问题，令我突然意识到我内心的潜意识究竟在渴望什么。结论很明显：我大概在上周三，上周四的时候，就会修正我对她大方向上的判断，然后主动提出结束交往。甚至还可能更糟糕，我们第一次见面交流后，我就不会向她要来联系方式，这段关系根本没机会开始。 人是如此好吃懒做的生物。若不提及女孩的家世，如果她在杭州没房，我大概是非常笃定，自己将通过事业上的提升，通过自身的努力，自力更生，安居乐业。但是你突然告诉我有这么一条捷径可以走，我就这么着了魔，就这么满怀期待得与她开始交往。我自己在心中描绘出了一个美好的她，仿佛我们志趣相投，我们互相欣赏。但事实终归是事实，我们没法欣赏各自的兴趣爱好，我们交流话题的范围变得越来越狭窄，可我还在这里苦苦支撑，不甘放弃，是什么原因在背后指使我愿不放手，我现在算是恍然大悟了。而对于她，就没有这些无端的干扰，因为优越的条件本就是属于她自己的，我不过是一个普通的男孩，如果已经没有了共同语言，对我的兴趣自然就结束了。只是她没那么决绝，留下我一个人又挣扎了几天，最终无力地熄灭。 所以说，物质条件总是以一种不经意的方式，扰乱人们正常的感情交往，它看不见却很强大，强大到令人身不由己，甚至无法自拔。我很庆幸，我及时抽身出来了，或许是因为我不够 “坚定”，没有那种不撞南墙不回头的 “精神”？我觉得，大概是我还相信自己的经济实力，即便没有捷径可走，脚踏实地的努力也不算遥远。而想想那些嫁入豪门的女孩们，其中不乏终日以泪洗面者，但她们没有能力，也没有勇气对生活说不。 当我发现我难于放手的根本原因后，我感觉浑身轻松了许多。是的，终究我还是要靠自己的本事吃饭，其他的幻想都不要有。 深夜复盘秋雨绵延，辗转难眠。虽然之前已悟出些许道理，但是，我感觉这一周的伤心遭遇，还是有些细节没有被正视，前因后果，不明不白。我怕以后重蹈今日的覆辙，故挑灯伏案，借着夜的透彻与深邃，欲将其和盘托出，重新审视一番。 星期六下午我们第一次见面，相谈甚欢，我们交流了各自的一些状况，聊到了各自的生活乐趣，比如喜欢的电影之类。我向她简述了我对艺术的追求，以及我对于跨领域跨学科综合涉猎的推崇，等等。末了，我询问了她对于我这些生活爱好，人生观念的看法，她笑着告诉我，她觉得我很优秀。这是向我抛出了橄榄枝，我有些兴奋，感觉新生活就要来临了！ 可是我被兴奋冲昏了头脑，竟然忘了反过来问一问她的生活爱好，以及一些追求，态度之类的问题。至此，我对她性格爱好的了解仅限于见面前提前了解到的：她属于文静型的女孩，喜欢旅游。 这个草率的开头，似乎为一周后的结局埋下了伏笔。 星期日早晨九点醒来，我赶忙在微信上向其问好，并配上可爱的表情。心里想着以后要早点起床，不能等到她都起床好半天了我才和她打招呼。她以同样可爱的表情回应我的问好，这真是一个美好的开端。 白天她要参加一个专业培训，我不再打扰她。晚上等她下课了，我给她打了一个电话，我们聊了一个半小时，谈天说地，非常愉快。在电话中，我不加掩饰得表达了昨日与她见面的喜悦之情，以及对能够与她交往的期待。她似乎是半开玩笑得回复我：“我感觉你说的好像有一点点······ 哈哈！” 我知道这当然不是什么表白，所以没多想，自然也就没从她的话中读出其他的信号：她其实是一个十分保守的女孩，直到经历了后续的事情，我才回味了过来。 星期一开始要上班了，我早早地起床向其问好，并试探性得问她，应该不会对我每天早上的问好感到厌烦吧？她笑着回答说不会。同时，我和她协商，工作的时候我们就专注得工作，等晚上下班了再尽情聊天，这些我们都非常愉快得达成共识了。 等晚上我们都下班后，再次进入了二人的聊天世界中。我们聊到了李咏的去世，聊到了他最后的遗言：“没有遗憾，只有不舍”。就着这些话题，我们探讨了爱情观，家庭观，事业观等等。我感觉我说的比较多，真的是有感而发，她也跟随着我的节奏，就其中的一些内容表达自己的看法，这样的聊天节奏与聊天氛围真的让人满意。 这个晚上，我突然在思考一件事：我是一个文字爱好者，有时甚至无悔于花费我全部的节假日时间，只为倾吐内心的感慨。不久之前的国庆节，我就几乎使用了七天之间的全部空隙，完成了我最近六年来心路历程的总结，只求探究一个真实的自我。我在想，我要不要把这篇文章给她看一下，毕竟这是我最真诚的情感抒发，尽管文章里提及了前几年我生活上的挫败，但通过整篇文章，的确可以更加深入得了解我这个人的价值观与人生观。 犹豫了一下，我决定暂时还是不要让她知道，我不敢保证她读完以后的感受，所以还是先度过一些美好轻松的时光吧。 星期二白天照旧，与昨日类似，一切都显得十分顺利与和谐。 我这两天会有意识地搜集一些有趣而值得探讨的事情，这样我们彼此就能通过交流观点而加深了解。这一天我搜集到的是一个五岁小朋友的入学简历，小朋友非常优秀，简历很棒，我正好可以借机与她讨论讨论子女教育的问题。 晚上和她交流相关话题时，也聊的挺精彩的，可以说面对这些问题我们的基本理念是一致的。可就在这一晚我突然隐约发现了一个细节：她从未唤过我的名字，更准确的说，是我的姓名。我每天从早上第一句问候，到后面每一句对其生活的关心，我一定会呼唤她的名字，以表示亲切。诚然，她的姓名包含了三个字，所以当我截断姓氏后只取其名，两个字读起来显得朗朗上口。可是我的姓名就只包含两个字，如果全读出来，会显得过于正式，似有 “直呼其名” 之嫌。只取我的名字那一个字，又显得过于亲昵，倘若把这一个字念作叠音，更是不适合刚交往的对象。我不知道她是不是也这么想的，不过这里确实有难处，我能理解。 从这里其实也能引申出一个问题：三个字的姓名比两个字的姓名在社会交往中更加容易被自然得称呼，更容易从心里上被接受。所以在给自己孩子起名字的时候，尤其要注意这一点。 星期三这一天开始有一点小波折了。我如往日一样，早早得送上清晨的问候，但是她并没有及时回复我，等我已经到公司了，她终于发消息告诉我她睡过头了。刚才还隐隐有些不安的我看到她的回复之后长舒了一口气，否则我还真担心出了什么事呢。这天晚上，我们聊的话题比较发散，没有一个明确的主题，有时候谈到一些社会现象，有时候又聊到各自的爱好。于是，我终于了解到了，平日里，她很喜欢看韩剧，日剧，以及一些其他的综艺节目。我有一些发愣，因为娱乐领域我是真的不了解，也真的不感兴趣。一时间有种奇怪的感觉爬上了我的身体，我不知道这是一种什么感觉，但我又知道这是一种什么感觉。 后来没多想了，正如我在 滋味 那一篇中所描述的，我不愿意想那么多，有种力量在我身后不允许我想那么多。 星期四保持节奏，清晨准时同她问好。然而这一天开始成为整个交往过程的转折点。 首先是，她早上回复我的问好不再带上表情了，只是三个字：早上好。这也无妨，我心里一直告诉自己不要特别在意一些细节。接着是，我中午向她分享了我的午餐内容，她没有回复我。关于这一点，我其实也能够理解，这几天中午我都时不时得分享一些琐碎的东西给她，而中午大家吃饭午休的时间都很短，若天天中午都抽空与我互动，次数多了是会有些不耐烦，只要换位思考，设身处地得想象一下便能体察那种感觉，所以说只要晚上我们下班后能愉快得交流我就心满意足了，其他的不必强求。 果然，晚上我们如期开始了微信上的交流。这天晚上和星期三类似，也是没有什么突出的主题，你一句我一句的，从天上聊到地下。不知道节奏是被谁带偏了，没一会儿我们竟然又聊到了兴趣爱好上面。说真的，经历了昨晚的交流，我现在不是特别想与她聊电视剧这个话题，但是这一天她似乎有点主动，主动追着问我会看一些什么样的电视剧。这让我很尴尬，我是真的很少看电视剧。可想而知，这一轮对话后，气氛瞬时凝固起来。短时间内她没有再发送消息，我隔着屏幕似乎感觉到了她淡淡的失望。“你有没有觉得我这个人有点无趣？”我以一种自责的口吻打破了临时的僵局。“没有啦，每个人的兴趣爱好不同是很正常的事情嘛。” 是的，我们每个人出生于全然不同的环境，自然而然得塑成了不同的生活习惯与兴趣爱好。我一直追求的是一种求同存异的关系，但是何谓同，何谓异？究竟该如何拿捏同与异的分寸，我之前并未深入细致得思考过，我内心一直持有的是这样的观点：态度，态度是关键。生活中有些事情是我们的心之所向，我们愿素履以往；有些事情虽谈不上喜欢，但却理解喜欢这些事的人，并认同追求这些事给 ta 带来的价值，或许在长期的交往过程中，我们也会在潜移默化之中同样爱上这些事情；还有些是我们不太理解，也不感兴趣的事情；当然必不可少的，总也会有些事，令我们十分反感，完全不能接受。 所以，有一个非常简洁而高效的筛选方法，就是逆向筛选。比如说，我非常反感抽烟，反感饭局与酒桌文化，反感各种网络游戏，反感类似直播、抖音这种极其浪费时间的娱乐工具。讨厌与反感是一种十分强烈的态度，是每个人不可妥协的底线，底线相互冲突，泾渭分明，也就没什么好谈的了。在逆向筛选之后，剩下的选择就不可能通过如此粗暴的方法实现了，但有些还是比较好判断的。比如共同的爱好，这将为我们对其印象加分不少，所以相当一部分有缘人皆源于同行。即便没有共同的爱好，但若能互相认可各自追求的价值，也是一件十分幸运的事，我想说，这就是我所理解的 “同” 的含义。君子和而不同，在价值追求的态度与原则上保持相同，而追求的具体手段与方式，可以不尽相同，这就是 “异”。当然，其他与态度及原则无关的生活习惯，那些经过交流后很容易作出妥协与改变的东西，也都属于 “异” 的范畴之内。 我似乎是在以一种理想化的方式解释我的择偶观，是定格某个静止的时刻，然后从这一截面横切进去作观察与判断。而然人是会变的，一旦考虑加入时间这一参量，整个求解过程便瞬间复杂起来，这将引出另一个艰深的领域，那是关于如何经营感情，如何处理好两性关系的深奥学问，已经超出了我此刻正在面对的问题。 这天晚上，我执拗地想理清楚一件事情：看电视剧对我来说究竟意味着什么？首先喜欢肯定是算不上。那么它应该被归类到剩下三个中的哪一类呢？这似乎不是一个可以被独立归类的事情，而是需要将电视剧的具体内容以及观看时长一并考虑进去才能综合给出的结论。就像电影一样，我喜欢电影，但不可能全局通吃，所有都看，我也只是看我感兴趣的，觉得有价值的电影。首先要肯定，电视剧是一种影视艺术，同电影在本质上是一致的，只是它的叙事不用像电影那么紧凑，它可以使用很长的篇幅来细致得表现主题，细腻得刻画人物。我喜欢高质量的经典电影，是因为其以精炼的篇幅表现深刻的主题，或者说，我可以利用相对短暂的时间完成对一部完整作品的欣赏。但电视剧过长的篇幅，容易花费大量的时间，让人陷入其中。我很少看电视剧的一个重要原因，就是我不想陷入对某一部电视剧的无尽追逐之中，我能体会追剧的痛苦。但如果遇到了质量优秀，主题深刻的电视剧，追逐一下也无妨，比如去年的作品《人民的名义》，这是我这两年看过的唯一一部电视剧，感觉相当满意。说白了，我反感的并不是电视剧本身，而是无止尽地耗费大量时间追逐低质量的肥皂剧，这其实与把时间花费在抖音、直播等上面没有本质的区别。 可惜当天晚上我并没有将这件事像上述文字那般理得如此清楚，我只是想象了一下如果以后我们真的在一起了，在同一个房间里，她在看韩剧，我在读书或者作文的场景，用一句话形如就是：各做各的事，没有共同语言。我是如此得冲动以至于提前亮出了我的底牌：我告诉了她我国庆节写过一篇探究真实自我的文章，我希望她能看一下。是的，如果已经察觉出什么了，最直白的做法就是大声对她说出来。但我选择了如此含蓄的方式来表达自己，含蓄到其实我自己都需要好好揣摩一下我这么做的用意何在：我正在被物质条件的优越所魅惑，我做不到由我这边主动把话挑明，我希望她能给个结论，在看完这篇文章之后。周一的晚上我之所以犹豫要不要给她看这篇文章，是因为我那时还拿不准她对这篇文章的态度。而这天晚上我亮出了文章，是因为我好像猜到了她可能的表态了。 现在看来，我那天这么做的确是一个无厘头的决定，我既不知道她在看什么具体内容的日剧韩剧，也不知道她一周花费多少时间在追剧上面，我好像是直接假想出了一个天天花费大量时间追逐各种无意义肥皂剧的她，但是又不忍心向她提出结束交往，最后以一篇文章的形式把这个决定权交给了她。 “今天不早了，明天我把这篇文章的链接发给你吧。” “好的。” 星期五既然现在还没有得知最终的结论，所以我一如往常，向她问好。 中午的时候，我不再打扰她了。但是她倒是反过来主动给我发了一个新闻，讲的是前两天重庆公交车坠江案的责任认定结果，并附带了一句话：“午安”。简洁之余透着一股匆忙，似乎证明了我昨天的想法。但是她主动向我发信息，不知是不是觉得没有被我如期骚扰好像有一点反常？ 晚上下班了，我给她发了一些消息，并琢磨着在什么时间点以什么方式发给她那篇文章比较合适。想着想着，我发现好长时间了她还没回我消息，见鬼了，不会是和同事聚餐了吧？我手里把玩着手机，揣摩着她现在的状态。我还没发给她文章链接呢，难道她已经察觉出什么了？中午那句午安到底向我发出了怎样的信号？ “我不小心把手机设置成免打扰模式了，没看到你的消息。你该不会生我的气吧？”终于，我看到她的回复，又是长舒了一口气。我怎么可能会对和我交往中的女孩生气？我只会感到难过，失望，以及惆怅，我是不容易被激怒的。没有犹豫，我发送了一个愉悦而期待的表情给她。 这就是微信，充满了各种假装与粉饰，你永远无法窥探到消息背后的人究竟是以一种怎样的心情在发送，唯一不能掩饰的就是回复消息的时间，这大概是微信交流中最诚实的信号了。 如果你正和你的对象交往，在下班后本应该愉快聊天的时间，收不到对方的消息了，你接下来本能得会怎么做？我就在这里时不时得看一下她有没有回复，时不时得刷出了最新的失望。她就在那里做着自己的事情，两个小时过去了，她突然发现不小心把手机设成了免打扰模式。 我和她大概都不是善于与对方真诚交流的人。当她中午对我频繁的消息感到厌烦时，她选择了使用沉默而不是沟通来向我传递她的不满；当我对她长时间不关心对方的消息而感到心寒时，我选择了使用一个愉悦的表情来表达我的 “不在意”。看来我比她更狠，她好歹还是间接得让我知道了她的想法，而我用这样的 “一腔热情” 将我的失望封藏得滴水不漏。 可该聊的天还是得聊，她至少问了我有没有生她的气，无论如何她都关心了一下我对她的态度。我半开玩笑得问她是不是在看什么引人入胜的节目，她笑着回答我说，她现在只是在和我聊天，顺手捣鼓捣鼓其他一些零碎的事情而已。这听上去多么像是对自己刚才的走心作出的补偿，而这种方法对于我这样的人又是如此奏效，似乎一瞬间又填补上了我内心失望的空白，让我顿扫所有的阴霾，重新拾起了热情。 但与往日不同的是，在尽兴聊天之余，我还保持了一份敏锐的心思，我在观察时机，在寻找一个恰当的时间点向她展示那篇文章的链接。不管今晚聊得多么欢畅，我都不会忘记我昨天和她说过的事，她忘记了不要紧，但我不能忘，哪怕我知道促使她回忆起昨日的对话可能并不是一件让她感到高兴的事。现在我们的关系正处在一个微妙的时刻，昨日与今日的反常似已令互相心生嫌隙，而我已决定摊出底牌，执意要交由她给我一个判决结果。 “这是我的那篇文章，如果有空的话，可以看一下嘛？”我总算是迈出这一步了。这只是早或晚的问题，而不是可以回避的问题，口头语言的交流不是万能的，要进入一个人内心最深处，ta 的文字是比 ta 的语言更加深刻的入口，尤其是像我这样敏感的人。我的文字承载了我的深情，我的文字承载了我不可言说的秘密。 她不再回话，毕竟阅读需要时间，审判亦需要时间。当明日第一道阳光射入我的瞳孔，不管她的结论如何，在这段关系中，我都将成为一个全新的自己了。 星期六或许这是我最后一次向她问好，或许来日方长，那我便只管做好当下的自己，从一句清晨的问候开始。 其实我也能够猜的到，她没有回复。接下来会发生什么，我也很熟悉了，六年前的往事，历历在目，言犹在耳。我正襟危坐，只轻轻地问了一句：“可以告诉我你的决定了吗？” 无论她告诉我能理解还是不能理解，能接受还是不能接受，我都想好了该怎么回答。但是临近中午时分，她的回复竟让我哑口无言：“我还没来得及看你的文章呢。”愣神了半晌，我才吐出一句：“不着急不着急”。难道她是真的没有看吗？我有点不敢相信。如果这是真的话，这个结局简直比我预想的两种情况都要糟糕：她不愿意接受我的文字语言沟通，不愿意走进我为她打开的我内心世界的大门。但愿只是我想多了，希望她是真的没来得及看。 前几天当我还没有像现在这番纠结时，我一直在计划着周末我们两人的约会事宜。但是从周四晚上开始持续到现在的这个糟糕样子，我是怎么也说不出口了。我们的关系就像一盏明火殆尽，余烟袅袅的蜡炬，在等待着双方谁出来表个态，吹灭最后一丝火星。可我真的不忍心就这么不明不白得了结这段关系，我真想和她把事情说清楚。我习惯于使用文字表达，但文字不是万能的，就像此时此刻，如果她不愿意接受这种沟通方式，纵有千词万句，也只剩苍白无力，还不如注视着她的眼睛，用几句话传达我想表达的一切！ “我们明天可以出来一起见一见吗？”但是消息刚一发送，我就笑了：我其实第一天就知道的，她最近每周日都有一个专业培训要参加，从早到晚。所以星期日她指定是没时间出来约会的，这是上帝不给我机会。 “我原本以为我们会周六见面的，因为周日我要参加培训。但是你一直没跟我约，我以为你周六要加班呢。”事到如今已经活脱脱演成了一部悲剧，原来她心里面一直是这么认为的。我现在算是明白了，我们两个人的思路根本就没搭在一根弦上，我发现她并没有理解我这个问题的意图：“可以告诉我你的决定了吗？”当然这也怪我，我从来就没有把我的担心，我的内心想法详细得透露给她，我只是给了她一篇文章链接，只是委婉得对她说：“这篇文章中描述的我，可能会令你感到失望，但他确实是真实的我。”也许她没意识到，这篇文章对我来说有多么重要，所以否定这篇文章就是否定我，肯定了这篇文章，我才能构筑起我们共同交往的基础。可是在她眼里，这篇文章的链接和我之前给她分享过的微信公众号文章链接，似乎没有太大的区别。 当意识形态发生了冲突，悲剧就不可避免。如果和我交往中的女孩发给我一篇她写过的文章，这对她意味着什么，对我又意味着什么，简直再清楚不过了。能感受到的，一定会牢牢把握，感受不到的，只能任凭其错过。 星期日我之所以还在向她问好，是因为并没有谁站出来给这段摇摇欲坠的关系定一个结论，而我答应过每天早上都要和她问好。但我已经力不从心了，我只发送了文字，而不再带上任何表情。照旧，她也不会回复我的。我觉得文章她肯定是看了，只不过接近七千字的篇幅，她未必有耐心将其看完。 我来到理发店，准备了却伴随我两个月的长发，手起刀落，一地断首，好生痛快！但这也止不住我肆意增长的惆怅，剪不断、理还乱的，是我的自作多情。 我决心再给我自己最后一次机会：既然无法当面交流，那我就给她打一个电话吧。 我突然想起了美国那位心理学家的著名公式：“信息的总效果 = 7% 的语言 + 38% 的音调 + 55% 的面部表情”。按照这个结论，如果使用微信作纯文字交流，93% 的信息将会流失耗散，只有不到十分之一的信息能够传递给对方。姑且不论这三个百分比的准确性，透过数字本身，公式的提出者其实想要强调的是沟通中情感反馈的重要性。 “你好呀, 在忙嘛?” 收到礼物的惊喜，遭遇挑衅的愤怒，触景而生的愁哀，与人分享的快乐······我们一定会承认，林林总总的感觉，心情，反应，很多时候没法用准确的文字来形容，正所谓只可意会，不可言传。语言与表情，总是相辅相成，相生相伴，所以无论是曾经的 QQ，还是当下的微信，文字沟通之余，我们都离不开表情包的使用。“一图胜千言”，一旦没有了表情，我们将在光秃秃的文字之下，陷入揣摩对方情感的无尽挣扎之中。 “哦没有，我刚吃完晚饭，正在回去的路上。你在家吗？” 心灰意冷，过去的我曾一度避免在通信软件中使用表情，因为表情的滥用，也是一种奢侈，一种放纵。过度依赖表情的人，最终将不得不以表情才能证明自己的情感，文字反而成为了表情的附庸。六年前，在我告别了初恋之后，这漫长的岁月里我孑然一身，再未觅得一人足以让我放下束缚，去发送那个曾经令我陶醉，如今却令我心碎的可爱笑脸，直到上一周，我与她相见。 “嗯嗯我在家呢。这两天我在微信里似乎感觉到你有些不高兴，我想打个电话关心一下你的情况。” “没有啦，昨天你没有约我出来见面，下午我就找我闺蜜逛街去了。只是我不喜欢三心二意，所以和闺蜜专心逛街时我从来不看手机的，不然逛街也逛不好，和你聊天也聊不好，你说是吧。” 久违的声音，如一口刚哈出的暖气抚慰了寒窗上的霜花。我好像没认真听清楚她说的具体内容，我只是听出来了她的语气里并没有丝毫的冷漠。一对情侣之间的甜言蜜谈，内容本身已不是重点，只要两个人持续得让彼此感受到自己正在意 ta，这样的交谈就能持续下去，这个过程就是感情的培养。微信的表情包可以满足这样的需求，电话里语音的交流更能够抵达对方的内心。 “实在是不好意思，我原本在周二周三时就计划着周末和你一起出来玩的，但是这两天的事情可能引起了一些小误会，说实话我看到你一直没回话，真的心里面很焦虑很担心。” “抱歉呀，我好像觉得你的声音和之前不太一样，我感觉到你受委屈了。” 卸下了微信的马甲, 我的真情实感再也无处遁藏。之前被滤去的重要信息，此刻正毫无保留，毫无阻挡得向她传递：如果你愿意一层一层得剥开我的心，你将会感受到我对你的在意，感受到我的压抑和不能自已。当此时我若站在你面前，必是 “执手相看泪眼，竟无语凝噎！” “如果我有哪里做的不够好，你一定要帮我指出来呀，我怕你对我的不满意，我却全然不知道。” 六年前失恋的教训我怎敢忘记，曾经多少次，伸出手想抓住熟悉的背影，睁眼竟是梦醒。放下所有的面子，我只想挽回一段濒临结束的关系，哪怕无法改变最终的结局，至少我也要比六年前的自己表现得更好。付出实际的行动，不仅仅是为了她，也是为了我自己。 “不知道那天我冲动得发给你那篇文章，是否引起了你的不适？” “哦哦，那篇文章，我只看了前面几节，说实话你的语言确实让我感觉有一点点不舒服，我觉得你文中描写你的生理反应太过真实了，你可以描写你的感受，但是这个实在是有点······” 就是说，我猜中了开头，却没有猜中结尾。她确实去看那篇文章了，也确实没有看完，我猜对了。但她所吐槽的内容点与角度，我着实没有预料到。我本是如实描写，并未有夸大事实以博眼球，流露的是我的真情实感。她这般反应，也许意味着她在某一方面的拘谨态度，相关的话题讨论可能触碰到了她敏感的神经。在这一 “禁忌” 领域，她还无法接受 “激进” 的理念，还需要慢慢引导，打开心结。我相信，这是生命中最神秘且最容易引起好奇心的领域，保守的人儿，只是不经意间为自己的心坎设下了屏障，只是还未发觉屏障背后的精彩与奥妙。 “所以说，你是觉得我可能在某些方面，太过于流露自己的情感？或者说，说话的分寸把握得不是很谨慎？” “嗯嗯，差不多是这个意思吧。” 如果我在意她，又有什么是无法改变的呢？一段关系，原本就是在不断的冲突与磨砺下铸成越来越契合的彼此，世间本不存在自然成珏的一对玉佩，亦未有天生合璧的两柄宝剑。双玉成珏，必先经历千凿万刻的雕琢；双剑合璧，定要承受千锤百锻的冶炼。但只要缘分足够，无论趟过多少泥沼，无论穿越多少荆棘，天下有情人终成眷属。 ······ “嘟嘟” 几声忙音，她的手机没电了。 星期一清晨阳光灿烂，似乎没有任何征兆这天傍晚将会落下久违的甘霖。 周日晚挂断电话之后直到早上我最后一次向她问好，我始终也没能在微信联系上她，我是否需要相信她的手机一直没充上电而无法开机？ 感慨是只有我一个人的感慨，而没有别人什么事。现实与梦境的距离大抵如此，就算像昨天一样，像一周前初次见面一样，每天都能同她打一个如梦一般甜蜜的电话，但梦醒的时候我是否能够抵挡冷漠，战胜孤独与绝望？在该进入梦乡的时候我是否又能够安心合上双眼？该来的终究还是要来，至少以我的方式，这一周我没有怠慢过，我努力过，珍惜过。 恋爱毕竟是一种高级的人类活动，是一场难度极高的人生游戏，要通往幸福的彼岸，有太多的学问值得研究，有太多的曲折等待历经。作为一名程序员，我当然不会忘记排查 bug 时一次一次地调试失败，又从头开始追踪；作为一名作者，我再清楚不过当前正伏案作文的自己，是怎样将写好的词句，乃至段落，一遍一遍地删去，更重新构思酝酿。没有一次编译，完美运行的程序，没有一气呵成，字字珠玉的文章，那么也不会有：一帆风顺，波澜不惊的爱情。 百感交集，万情纵融，我将此时此刻心中之所言，汇成为一篇：《释然》。 正襟危坐，我把手指停放在微信消息发送键上方约莫半寸的位置，缓缓得转过屏幕背对着脸，撇开头，闭上眼，深吸一口气，猛然将手指贴在了屏幕上。心里蓦然一颤，一周之内的往事与回忆快速得在大脑中闪现，像一管不断抽出的胶卷，被时间曝光，被记忆塑封，被灵魂收藏。看呐，它被盛放在一隅静谧的角落，一格质朴的抽屉内，抽屉的外侧贴上了标识：《一位爱情初级玩家的偏见式独白》。 睁开眼，待我再次面对屏幕，确认早已度过了足够长的时间，这条消息已经成功发送，再也，无法撤回了。","categories":[{"name":"life","slug":"life","permalink":"http://zshell.cc/categories/life/"},{"name":"thought","slug":"life/thought","permalink":"http://zshell.cc/categories/life/thought/"}],"tags":[{"name":"思考","slug":"思考","permalink":"http://zshell.cc/tags/思考/"},{"name":"情感","slug":"情感","permalink":"http://zshell.cc/tags/情感/"}]},{"title":"一只猫与南师的邂逅","slug":"life-thought--一只猫与南师的邂逅","date":"2018-10-15T03:20:35.000Z","updated":"2019-01-22T15:28:58.450Z","comments":true,"path":"2018/10/15/life-thought--一只猫与南师的邂逅/","link":"","permalink":"http://zshell.cc/2018/10/15/life-thought--一只猫与南师的邂逅/","excerpt":"教堂内沧桑墙壁上深深刻着的 “命运” 一词，令雨果读出了人性的真善美与假恶丑；实验室中模拟地球演化的系统，一个是否包含生命的参数选项，令刘慈欣窥探到了整个宇宙的游戏规则；这一次轮到了我，当一只流浪猫与南师邂逅，当它的目光与我的目光交织在一块，我将会悟出什么？","text":"教堂内沧桑墙壁上深深刻着的 “命运” 一词，令雨果读出了人性的真善美与假恶丑；实验室中模拟地球演化的系统，一个是否包含生命的参数选项，令刘慈欣窥探到了整个宇宙的游戏规则；这一次轮到了我，当一只流浪猫与南师邂逅，当它的目光与我的目光交织在一块，我将会悟出什么？ 自序这本是一封辞职信，初写于 2012 年底。在我的百度网盘私密空间尘封六年之后，我决定让其重新曝光于这个世界。 我记得 2006 年我上初中，第一节语文课，学到的第一篇课文，是赵丽宏老师的《为你打开一扇门》。开学伊始，我定然是认真得学习，可惜我天性愚钝，又或是阅历尚且，在诵读与笔记之余，并未理解赵老师想要表达的真义，无法窥见那扇大门背后的瑰丽与宏伟。那时的我像个 “标准” 的理科生, 字迹潦草，性情执拗，无法欣赏文学的美，只知道埋头解数学题。 六年过去后，我上了大学，以一名理科生的角色来到一所偏文科的院校。这看似剑走偏锋的选择，却为我呈上了一份珍贵的人生之礼：发觉艺术与审美的能力。而这篇文章所描述的，正是母校赠与我这份礼物的全过程。从事理工相关的方向，求学与职业之路无不充满了复杂的设计与缜密的逻辑，思维的高负荷运转难免为生活带来干涩与磨损，而这份精致的礼物，可相伴我一生，舒缓不顺心之事所带来的烦恼，慰藉不如意之情所添增的苦闷。 六年之后又六年，今天的我将这篇文章搬上了我的博客。错愕于触目惊心的文字，我方才惊忆起过去的我长着如何的一张面孔。尽管文中我的行为令现在的自己感到不齿，但那的的确确是过去的我，是真实的曾经。人总是在不断的改变，我们不会因为一个人糟糕的童年而否定其往后的努力人生，尤其当这个人是自己时，甚至需要反过来感到欣慰，欣慰自己的成长与蜕变：我，已经从一个懵懂无知的少年，变成了一个渴望思考、好奇世界、憧憬美好与高尚的青年人。回想起十二年前我坐在初一 (11) 班整洁明亮的教室里，朗诵着《为你打开一扇门》，我不禁热泪盈眶。纸上得来终觉浅，绝知此事要躬行，无论如何，我已经真正悟了，相比于那些还在门外徘徊不得而入的人来说。 种一棵树的最佳时间是十年前，其次是现在。感谢扬州市梅岭中学，于十二年前在我心中播下了一粒种子；感谢南京师范大学，于六年前为种子周围的土壤浇水施肥，令新生的嫩苗破土而出；感谢现在的我，继续悉心呵护着小树，令其深深扎根，茁壮成长。我相信：终了，它定会在我心中成长为一棵枝繁叶茂的参天巨木。 以下为正文：&nbsp; 我特别喜爱南师阳光明媚的午后，尤其是在这幅精致的图景之上添置一只可爱的小猫。 迷误的心猫本是有灵性的动物，随遇而安，依境而存。于是，在我们宿舍楼，周遭总是窜着一只又一只的。它们日日生活在我们周围，睦邻相伴。每天都有阿姨给它们喂食，也有男生女生与它们嬉戏。就像青春的精灵，不管来自何方，它们都可以忘却曾经，尽情享受如今的温馨美好。 猫有记忆，它们能记住人。宿舍楼里的同学可以分辨出不同的猫，为它们起一个个可人的名字。猫也能辨别不同的人，尤其会记得某某对自己特别的好，于是静静往墙角一趴，专心地等待那位同学下课归来，几个小碎步迎上前去，懒懒的喵一声，像是在对自己的好朋友道声问候。 不过，猫也有自己的烦恼，因为它们遇上了我。我是一个理工科男生，也是这里所有安详与和睦的搅局者。在我这位理工男的眼中，动物与人是不一样的。人迹出没的地方，容不得动物的插足。但凡在我回宿舍的路上，看到猫的踪影，我的第一反应便是狠狠跺上一脚，看它们被吓得四散逃跑，仿佛在我心中，那是光明的火种驱散黑暗的阴霾，是人类为自己的权利而不懈斗争的胜利，我以为自己获得了一种不足为外人道的满足感，甚是好笑。自此，没有哪只猫会在看到我之后不慌不乱，甚至是隔得远远的时候，当感受到那一袭黑衣，斜跨黑包的身影急促地逼近时，所有在路口等待自己好朋友归来的猫们就仓皇而撤，连正面与我对视一眼的机会都不曾有过。我冷冷地微笑着。 我曾经就是这样以搅局者的身份自居：思维奇异，与众不同，追求极端，冷酷无情。仿佛一个理工科的男生，来到女儿王国的南师大，势必要挑起一场价值观的冲突。 虽是彻头彻尾的冷酷，但我依旧在外表上活成了一个 “有声有色” 的人：和其他同学一样，面试校学生会，面试赛扶，参与各种社团，过关斩将，悉数被录用。面对动物，我睁着邪恶的双眼；而面对人，我又展示着理性的思维与缜密的语言组织能力。道貌与岸然，将我的人格诠释的刚好。 于是，我加入了南师赛扶 “虎韵福鞋” 项目。在这里，我依旧走着我的风格：颠覆式的否定与创新。我无视了那些女生苦心孤诣地挖掘与丰富虎头鞋内涵的举动，我不懂她们也无心去了解。我一意孤行地设计着自己的战略：让传统的文化与现代的时尚去激情碰撞，我试图打开电商推广的渠道，我只相信现代科技的力量。而虎头鞋本身究竟是什么，我并不懂。虎头鞋的追根溯源与精神文化，我亦不屑。像我这么浮躁的人，怎会有耐心打磨绣花针？所以，分歧在所难免，隔阂日渐凸显。但是，我行我素，因为没有一种力量能打破僵局。 梦醒而惊但是却有一种无形的力量可以做到。 一个阳光明媚的午后，我独自一人往宿舍走。静谧无声，周遭的一切与往昔似没有任何不同之处，唯独别致的是，当我路过一个转角，经过开水机的一刹那，我瞥见了一只小猫。它是如此的大胆以至于竟敢在我面前装作不动声色，甚至还作出 “越界” 的举动：趴在人类的开水机上惬意地舔舐着上面的积水。我从来都没有机会近距离地观察一只猫的形态，于是突然就来了好奇。弯下腰，以一种不怀好意的目光打量着它：一身毛发黄白两色，渐变一般从头到脚柔和地过渡，尾巴翘着老高像是在保持平衡，两只前爪刚好抠住不锈钢的平台，尽情地享受着饮水的乐趣。它的肚腩如波浪般的一抖，显然是一口清澈的陶醉。或许是忘我的沉浸让它忽略了身边的危险，我一口呼气掠过它的发须，它漫不经心的一瞥，眼神正好在那刻与我对撞。 原来这只猫的眼珠竟是蓝色的，特别纯洁的那种蓝！惊讶之余，一股被挑衅的感觉莫名涌上心头，我竟不能让这只猫屈服？莫非它不畏惧我邪恶的眼神？难道相比于它我这庞大的身躯都不能对其构成一点压力？我在考虑要不要保持我在这栋楼里对猫群的 “尊严”，总不至于过往的惯例在今天就此打破？ 有一点我敢笃定，这只猫是这栋楼的新客，它没有见识过我的凶残，在它记忆里恐怕只有南师大整体的博爱情怀！ 在它蔚蓝的眼神里，似乎包涵了整个南师大的灵魂：清澈不失厚重雄浑，淡定却又锋芒敏行！没想到，从一只猫的眼里，我竟读出一种强大的气场，邪恶与正气的交锋中，我越发觉得自己已处于守势！ 如果我此刻突然爆发，使用暴力手段相威胁，它一定会在瞬间仓皇而逃。但是如果剥离所有肉体与物质层面上的东西，在两个生命的对峙中，我却无论如何也无法战胜它。曾经有个寓言：在质量的天平上，蚂蚁和大象没有可比性，然而在生命的天平上，两者却是等价的！ 我觉得我没有资格在这只猫面前滥用武力，因为我面对的不仅仅是一只猫，也是南师大，她是我尊敬的母校！ 或许这只猫曾浪迹天涯，只是最终与南师邂逅，并在生命里注入了南师的基因，从此行走在博雅与爱的路上。南师的魅力在于她不但能感召人，同时也能将物点化为自己的精魂。而很大程度上，南师感召莘莘学子，正是靠身边不计其数的师大精灵，才让混沌而迷误的灵魂走出泥沼，获得醍醐灌顶的觉悟。 我庆幸自己最终没有对那个纯洁的生命做出卑鄙残忍的行为，从而让它保持了那份对南师无暇的爱。我也后悔自己让其它无辜的生命这些天饱受恐惧与惊吓的折磨，打碎了它们对南师这个伊甸园美好纯真的映像。我担心，这些天，我从未让这些青春的精灵正面看我一眼，它们可能会误判而刻意躲避与我衣着类似的同学，这是间接剥夺了其他同学对自然生命亲密接触的权力！这一切的后果都是我造成的！我宁愿让我暴露在光天化日之下，让所有的精灵都看清我的本貌，让所有的惩罚都冲着我一个人来吧！ 就让恶贯满盈的少年发自内心地忏悔吧！就让一身污迹的浪子接受电闪雷鸣的洗礼吧！ 正是这种无形的力量。 忏悔与反思对物残忍，对人傲慢。揭开我道貌与岸然的画皮，剩下的大概就是这两句话了。曾经我被赛扶吸引，是因为 “商业” 二字。然而我却忘了全句：用商业的力量改变世界，造福社会。重点在后面，而我本末倒置。我丝毫没有忖度自己的实际素养便妄图加入，还用自己的无知拖累整个团队，用赤裸的利益动机玷污了虎头鞋博大精深的文化底蕴。曾经有团队的同事告诉我，她选择虎韵福鞋是因为自己真的非常喜欢中国传统文化，因此想在这个领域做出自己的贡献。而我怎么告诉她？我选择这个项目是因为其中有诱人的利益链条，因此想大挣一把？情何以堪？ 如今我再也不敢说我参悟了赛扶的真谛。真谛无情地照在我身上，反射出我惨白而嶙峋的瘦骨。我活了将近二十年，可能从小就会写 “公益”、“可持续” 这些个汉字。可悲的是，到如今我仍然还停留在小学的水平，我会写这几个字, 看得懂它们的字面意思，但是就是无法领悟它们的内涵！初中高中，学了六年的理工科，接触了大量的公式与定理，我每天忙碌地在试卷与作业上搬运成批成量的它们，我自以为能灵活运用，驾轻就熟。可是，我发现，学理工科最大的致命伤，就是我们过分强调了运用，却忽略了这些公式背后的探索验证，其实是一把饱含血泪的辛酸史。理性，正在扼封人性！我们踩着前人的肩膀向上攀登，却忘记了对先辈、对知识的敬畏与仰望！那一串串字符，是有血有肉的生灵；那一句句推理假设，当是为我们的明天，为我们的后代奠定了幸福的基础！ 这些, 我曾经想过吗? 一个伟大的科学家，绝不仅仅停留在对人类在科学技术上的突出贡献。他一定也是一个悲天悯人的慈善家，他热爱生命，关心人类的疾苦，这些都是促进他在科学领域开创新时代的源动力；他一定也是一个对人类，对社会负责任的公民，他参悟了公益与可持续发展的内涵与精髓，他从骨子里焕发着对社会的使命感；他一定，也是一个心思细腻，柔情似水的诗人，在一只小猫面前，他甘心拜倒，放下他所有的身段与荣耀，只为接受自然予他的馈赠。 而一个伟大的科学家，从广义上讲更是一个执着思考的文学家。文学是这个世界上最容易被忽视而又最不容忽视的巨大力量，文学，总是与世界上最感性的事物相关联。她代表的是一种信念，一种信仰。她可以在人类面临危机时爆发出不可抗拒的能量，也可以在日常中左右人们细微的行为，并以一种滴水穿石的恒念，积聚起改变未来的倾彻。 历史上很多著名的科技巨头公司，曾经都是光芒万丈的恒星，他们也秉持着改变世界，造福社会的理念，只可惜，不可一世的辉煌麻痹了他们的双眼，资本市场的催化却加速了他们的腐化，很多人变得腰缠万贯，也变得偏执傲慢，于是离自己的初衷渐行渐远，最终堕落为天际边划过的一颗流星，燃烧殆尽。 怎样才能让自己始终不变初衷，坚定不移地前进？唯有信念与信仰！我越来越相信文学的力量，相信她对人的一生所起的指导作用。信念，只有一个终点，教人始终清醒，洞悉自己，不为眼前所迷惑，善待众生。如果一个跨国公司，在一只猫面前敢于屈膝，那么它就具有了生生不息的动力。一个能扛得起惊天伟业的人或组织，一定也能在自然面前认清自己卑微的本质。一个人当认识到自己的卑微时，他的行为便开始伟大！ 所有贪图商业利益的人都是在走向终结的深渊。时间会淘尽一切，露出真金的本色。对于虎韵福鞋而言，文化即是最好的保值品。将来所有的东西都会消失，唯有文化得以生生不息。此刻，我刚好理解了为什么女生们会在加入虎韵福鞋后醉心于虎头鞋的文化内涵了。一个肤浅的人，搅浑了一捧清澈的甘露。 这些天，我突然想起来两个多月前我与杨经理第一次的电话交流。“如果将来学生会与赛扶都很忙，你必须放弃一个，你怎么选择？” “我会选择赛扶。因为我在暑假就已经规划好了我大学的目标，培养我在商业方面的职业素养。校学生会方面，我在宣传中心工作，可以理解为媒体与公关，它确实也是商业组织不可或缺的一部分，但那本质上触及不到商业的核心。”一段貌似有理的论述，现今看来，恐怕都没有一层纸的厚度。这段话暴露了我早期贪婪的本质，如果按照我 “精心设计” 的路线走下去，前方不远一定是万丈深渊。 我如今，没有能力，没有资格再在赛扶继续下去了。我向我曾经因为自己的无知而亵渎的虎韵福鞋文化，公益的精神，社会可持续的使命表示深深的歉意。在此，我也正式呈上我的辞职申请。 杨经理，请原谅我的食言。面对一个歧误的承诺，我已无力再恪守。 曾经我还抱着美好的希望，希望能在赛扶找到值得相伴一生的人。现在我只能苦笑，我的卑鄙龌龊根本就配不上那些天使般的女生，我的凑近只会反衬她们的纯洁，我不配！ 脱胎与换骨又是一个宁静的午后，我站在宿舍阳台的一隅。远处层叠的山峦，如同编织起温暖的摇篮，枕着南师所有的生命，孕育着未来。 我之于那只可爱的小猫，不就如同猫之于南师大吗？感化与洗礼，脱胎与换骨，一只猫被注入了南师的精魂，青春的精灵得以在世间飘洒。而我，又何尝不是一只猫呢？造化选择我与南师邂逅，选择在一个阳光明媚的午后，选择在一个静谧无声的楼道，选择与一只青春精灵的生命碰撞，来完成对我整个灵魂的重塑！ 我爱上了文学，爱上了读书，爱上了写作，爱上了思考。我作为一个理工科的男生，有必要去经历一个从未体验过的生活。一人静静走在随园校区的林荫小路上，凝神尽力吮吸着那古色古香的建筑所焕发出来的韵味。人生需要放空自己，解开束缚，让所有的欲念自由飞翔，能沉淀下来的才是真正的菁华。 如果说南师代表的是女性，那么我自甘情愿接受女性化的洗礼，我爱我的母校！如果有需要，我也可以成为南师万物中被点化的精魂，去拯救更多混沌而迷误的心！ 我也愿意等候下一个安详而静谧的午后，站在宿舍开水机旁，只求与那只可爱的小猫再一次邂逅······","categories":[{"name":"life","slug":"life","permalink":"http://zshell.cc/categories/life/"},{"name":"thought","slug":"life/thought","permalink":"http://zshell.cc/categories/life/thought/"}],"tags":[{"name":"思考","slug":"思考","permalink":"http://zshell.cc/tags/思考/"},{"name":"人生","slug":"人生","permalink":"http://zshell.cc/tags/人生/"}]},{"title":"六年来我与自己的斗争","slug":"life-thought--六年来我与自己的斗争","date":"2018-10-07T15:44:27.000Z","updated":"2019-01-22T15:29:14.338Z","comments":true,"path":"2018/10/07/life-thought--六年来我与自己的斗争/","link":"","permalink":"http://zshell.cc/2018/10/07/life-thought--六年来我与自己的斗争/","excerpt":"写出这篇文章，本意味着我的幼稚，但若不写这篇文章，也只不过是将幼稚藏于心底罢了。敏感脆弱的品性，使我固执了六年，而不敢拾起真实的自己，蓦然回首，却发现我苦苦寻找的光明，其实就是自己的影子。伤痛，迷惘，绝望，逃避, 再次面对，幡然醒悟······值得欣慰的是，无论这个过程多么坎坷而曲折，这么多年来，我心灵最深处却始终保留着通往真实自我的火种，在历经无数的风吹雨打后重新被我拾起，再一次燃燎起我内心的草原。","text":"写出这篇文章，本意味着我的幼稚，但若不写这篇文章，也只不过是将幼稚藏于心底罢了。敏感脆弱的品性，使我固执了六年，而不敢拾起真实的自己，蓦然回首，却发现我苦苦寻找的光明，其实就是自己的影子。伤痛，迷惘，绝望，逃避, 再次面对，幡然醒悟······值得欣慰的是，无论这个过程多么坎坷而曲折，这么多年来，我心灵最深处却始终保留着通往真实自我的火种，在历经无数的风吹雨打后重新被我拾起，再一次燃燎起我内心的草原。 不堪一击的我时间回退至 2012 年，阳光明媚的正午，我收到了你的消息：“我们俩的关系可能真的需要考虑一下了！” 开学以来的这两个月我很幸福，可惜在你眼里我最终还是令你感到失望了。这是一个无法挽回的结局，我不会赖着强留你。这是我第一次失恋，只是这终点距离起点，只有两个月的时光。我的内心一边对伤痛的洪流打开了闸门，一边又在无力地安慰自己：这只是两个月，而不是两年，但愿没有陷得太深。 可惜一语成谶，我高估了自己的情感自愈能力，接下来的一段时间内，我已经不是在开闸泄洪，而是在坠入黑洞：拂晓时分，睁开眼的一瞬，我一次又一次得被无情的现实拽开梦中我们紧拉着的手；之前极少梦遗的我，每当掀开被子，时不时会感到一片湿漉漉的下身；我在同学朋友面前故作镇定，每当控制不住时，不得不闭上眼睛，好让眼泪被瞳孔快速得吸收，末了，再假装睁开惺忪的睡眼，生怕别人看穿我内心的波澜。 在接近一个月的炼狱之旅后，我熬过了失恋的第一阶段，这一阶段属于时间短而冲击猛烈，如果我属于天生乐观的那类人，挺过这一阶段或许便能恢复到正常的生活。很遗憾我没有做到，在此期间，我的生理、心理、潜意识都不亚于经历了一场器质性的改变，造成了难以愈合的创伤，以致于我被迫进入了失恋的第二阶段。 这一阶段属于文火慢炖，学习、作息等日常活动都与此前几无二致，但性情却发生了大变，仿佛我内心的某一扇门被合上了：我关闭了 QQ 空间，排斥在任何群里说话，与单个人发送信息时也不会再轻易使用任何表情，尤其是那个可爱的笑脸，它像极了一个讽刺，曾经它令我感到多么幸福，现在就令我感到多么残酷。后来普及了微信，但于我这并不意味着一个崭新的开始，却倒像是对 QQ 的一个延续，我从未在朋友圈中分享过任何内容，也未主动加过别人好友，不认识的人一律拒绝，临时有事需要联系的，当事情结束后我便清空一切痕迹······我的学业虽不曾耽误，但把这种孤立自我的生活称作一蹶不振也不失得当吧。 喜怒哀乐乃人之常情，哀多乐少，也勉强可以当是一种生活之态，随着时间推移，此消彼长，或许于不经意之间又可以找回当初的模样。可惜我的心境没有就此打住，而是继续向更深处跌落，向着扭曲与极端方向发展，我本以为时间会为我酿制解药，慢慢稀释我的悲痛，但恰恰相反，我其实每天都在服下这剂慢性毒药，日复一日，直至病入膏肓，落下无可弥补的后遗症：我不敢再谈恋爱，不再有信心处理好两性关系，不敢再次尝试陷入别人的世界中，因为上一次的经历警示我，哪怕只有两个月，我都难保可以承受其失恋之痛。我冷漠得回应异性对自己的表白，尽管对方的真心也会让我内心悸动，但我总以 “绝对的理性” 强制扑灭心中的火苗。有时候别人的表白也会令我感到 “喜悦”，不过这份喜悦只是拒绝别人时变态而畸形的虚荣心与优越感罢了。 恰逢失恋之时，又遭遇了父母离婚，在这样的双重打击之下，我的三观彻底淹没在了汹涌的洪流之中，我无可避免得陷入了第三阶段：凡事有始必有终，既然承受不了终点的痛苦，那干脆就别给它开始的机会。这句话传递给了我一个危险的信号，我难以想象任我现在的状态发展下去会面临一个怎样的结局?庆幸的是,在这样一个节骨眼上,我遇到了我的高中同桌,他在隔壁南邮修习计算机专业，我仔细聆听他讲述他们专业的内容及特点，并感受到了强烈的召唤：计算机可能是助我摆脱当前危险处境的救命稻草，我必须竭尽全力得投入其怀抱，这是避免我生命终结的不二选择!经过半年的努力，我成功转到计算机学院，真的好希望能以此为契机，彻底告别过去！ 倒向另一种病态的追求计算机给了我一个活下去的理由，它是挽救我生命的第一张多米诺骨牌，但要真正推倒它，我得付出实际行动：我需要疯狂得爱上计算机。如若不能永恒，那就注定要毁灭，假设我对待计算机的态度只是为了逃避情感，那这种三分钟热度断不可存续太久，命运将会无可抗拒，所以我需要打造一个被信念赐予力量，抛开一切杂念的自己。 很快我就给自己找到了一个力量之源：还是我那位南邮同学。是他在我即将坠入万劫不复之际为我打开了一扇门。当我踏进门内，面对广阔无垠的新世界，他再一次成为我撷取知识的参考系。他是从大一开始学习计算机的，而我属于大二开学才半路杀入，我和他之间至少存在一年的差距，于是我的奋斗目标被冰冷得定义为：竭尽所能赶上他并超越他！我开启了自己波澜壮阔的求学之旅，每日每夜，每时每刻。图书馆、教室、宿舍、食堂窗口、路上······如果我处于一种思考的状态，那我一定在思考与计算机相关的问题，我进入了一种不可思议的魔怔。 每个周末我都要找我这位同学交流最近的学习心得，这种事情从开始的只是令我感到愉悦，发展到后来的令我极度渴望，我大概意识到了我学习计算机的动机已经发生了微妙的变化，我不是直接在为我自己学习，我是在为我这位同学而学习，我从同他的每周交流分享中获取快感，更甚的说，我从每周在他面前的装逼中体验高潮，这似乎才是我学习的原始动力。当然，我察觉到我在这方面的疯狂后，其实也在有意无意地利用这一点：如果装逼的代价是需要持续学习，那我不介意把装逼进行到底，不管学习的动机与姿态多么难看，我都是在实打实得学，最后掌握知识的人还是我自己呀！ 一旦有多巴胺在生化级别上对我的行为作出了奖励，我真的感觉要对过去说再见了。自杀？没有的事，计算机的世界还有太多太多等着我去发现，哪还有心思去考虑怎么死？ 学生会、社团、团 (党) 支部，这些字眼都与我无缘了，当我不在其上倾注感情，也就无所谓得与失。我的追求就是计算机，我对其倾注了所有的情感，它也给足了令我满意的反馈，我绝不容许自己失去它，失去即是死亡，即是毁灭。 差不多这就构成了我大学后三年的生活基调了，我认为这三年来我已经摆脱了失恋后危险的第三阶段，进入了一个有点唯心主义，并带有极端色彩的第四阶段。第四阶段与第二阶段在很多方面很类似，我还是和以前一样社交恐惧，内心离群索居，与常人的生活浅行浅远。但是第二阶段我的行为受到了主观意志的干扰，而第四阶段的我却是顺其自然，仿佛与生俱来，水到渠成。另外，第四阶段的我有强力的追求目标，让我的学习生活充满 “活力与斗志”，这几乎是塑造了一个全新的自己，但我清楚这并非一种健康的状态，就像前苏联一样高歌猛进，最后变成了跛脚的巨人。可是我能停下来吗？我敢停下来吗？ 大概每一个单纯而执着的程序员，背后都有着自己心酸的往事。茶余饭后的人们总是戏谑程序员的木讷与无趣，殊不知木讷可能并非我们天生的性格，而是后天无可奈何的选择。 裂痕渐起毕业后我去了北京工作，而我这位同学则继续留在南京读研，地理位置的隔阂让原本的一周一碰面，变成了以年为单位的见面。当然，我这辆疾速奔跑了三年的战车，已经拥有了足够的惯性，使得我不再需要以大学时代的模式来维系我生活的运转。 但这终究还是有区别的，学习与工作，校园与社会。我真心怀念学校图书馆里无忧无虑看书的日子，相比之下，在社会上，毕竟拿着公司发的工资，干活与完成任务才是第一要义。我喜欢计算机，但这和在互联网公司上班是两回事，很多人倾向于用工作的忙碌程度来评估自己的价值，把自己交给繁忙，得到了心里的踏实，但在 IT 行业，这是个死亡陷阱，是一个让人陷入原地踏步无法快速提升自己的重要原因。我不喜欢上班的感觉，可是哪有不上班的道理，不上班哪有经济来源？ 如此，自失恋以来我又陷入了另一种痛苦之中，工作使我不得开心颜。即便并非天天皆如此，但这种悲观的预期却很难摆脱，当面临一个晴朗的周末，如果想到下周一又得跟进一个很恶心坑很多的项目，这个周末还要怎么度过？一周有七天，五天很烦恼，剩下两天稍微缓一缓；一年有 365 天，358 天都是漫长的修行，最后七天回到家乡与亲人团聚见一面。假期总是一晃而过，新的修行早已在路上。一年中的时日就像结绳，绳子由痛苦构成，结点则是快乐的分身，短暂的快乐连结了一段段漫长的痛苦，使岁月得以延续，然明年复明年，明年何其多？ 淳朴的民工，辛勤劳作了一年，返回家乡时是快乐的。天生焦虑的我，只能感叹，快乐到来之前才是真正的快乐，假期来临之际其实刚好按下了快乐准备结束的倒计时，一秒一秒头也不回得流逝着，宣誓着，下一段痛苦的降临。佛曰：受身无间者永远不死，寿长乃无间地狱中之大劫，身处人间界又何尝不是如此？ 五年前我去过一次杭州，欲把西湖比西子，淡妆浓抹总相宜。这是个令人心驰神往的城市，同时也孕育着互联网的新时代。我尽力地安慰身处北京的自己，将来会有那么一天，我挥手作别北京，投入杭州的怀抱，览水光潋滟，观山色空蒙。痛苦将会消褪，幸福将会来敲门······ 苦难中的人们，热衷于编织美好的未来传说。三大宗教长盛不衰，因为它们所倡导的救赎，依托于死亡。当无法眼见为实，我们便心甘情愿以耳听为虚来慰藉满目疮痍的生活。所以，一个善意却不太高明的谎言，会给被骗之人留下通往真相的尾巴，当执着者按图索骥触及终点时，便会意识到斐然如画的词句，不过想象里缥缈的幻光，乍现即逝，正如我此刻虽已置身杭州，只是城虽换，心未易，这两个多月来却没有一天开心的日子。当然在北京的两年我也不曾度过开心的时光，可我在北京总可以安慰自己去了杭州一切便焕然一新。那么现在身处杭州的我，该怎么继续安慰（欺骗）自己，难道说等再回了南京一切才能真正好起来了吗？我内心到底在渴望怎样的一种生活？ 信念开始瓦解从我第一次接触编程到现在已经快六年了，我心无旁骛，一路披荆斩棘。我以为曾经的痛苦会被我指尖的代码所肢解，我以为程序调通的瞬间会从内心升腾起由衷的喜悦，我笃定计算机是这世界上值得我留恋的东西，却不曾想到它竟渐渐要成为我在这世上唯一值得留恋的东西。 在北京的我，无论工作压力多么大，生活多么重复单调，我都能忍受，对计算机的喜爱加上对杭州的憧憬，所有的烦恼都会烟消云散。同大学时我不顾一切得投入计算机类似，这种激励模式谈不上良性，但至少也为我在一段时间内保持了比较稳定的心态，直至我来到杭州为止。我以为换了一座城市，就能甩掉所有包袱，重新开始，如今这被证明不过是在以偏概全，换汤不换药。作为一个谎言，它的确很有魅惑力，起到了望梅止渴的效果，可惜曹孟德最后确实找到了水源，然对我来说只是延缓了精神崩溃的时间罢了。 在北京的时候，偶然间我会再次萌生出自杀的想法，只一闪而过，随即便会被理智所控制，我笑着告诉自己不值得，我走过了黑暗的岁月，在失恋后最绝望的第三阶段重新拾起了新的追求目标，我何苦再踏回原先的老路。而今在杭州的我，被自己欺骗了自己的我，美好憧憬破灭的我，当再次想起自杀这个词眼时，我竟然放下了警惕，开始认真而专注地考虑这件事情： 六年来，两千多天，我努力超度自己，一层又一层得剥离自己感性的一面，我不再购买帅气的衣裤，不再尝试原创音乐，不再和小动物玩耍，不再打网球，不再与别人进行深入灵魂的交流······我腾出大脑的所有容积，只为给计算机世界留下 “自由发展” 的空间。终于，我 “成功” 了，当我闭上眼，当我睁开眼，我在意的只是代码，其余的一切，都灰飞烟灭了。当我不再拥有它们，也就不会再失去它们。起点与终点，如果每个人都要选择用一条线来连接，那么我当下的选择则是一条直线，所以当美好的周末来临，除了继续研究另一个令我 “感兴趣” 的技术实现方案之外，我已没有任何其他的 “期待”。 如果其余都照旧，只是不再与小动物玩耍了，我的生活最多少了两声欢笑；同理，如果只是不再打网球了，我也可以很快找到另外一项消遣活动；但当所有的这些都消失了，就构成了现在的我，一个被执念牢牢束缚的自己。五彩的泡沫幻灭了，我终于要看清我的真实面目了：原来我这六年来所做的一切努力，并不是在为自己打造一个没有失去、没有痛苦的乌托邦，而是恰恰在无端地制造失去，硬生生得剥夺生活中的乐趣。我变成了一个自虐狂，扼杀人性于无形之中，最后只能依赖一个莫须有的谎言，苟延残喘，艰难度日。细细想来，谎言中描绘的图景所影射出的，不正是我一边在极尽渴望，一边却又撒手而弃的生活吗？ 猛然回神过来，我正站在窗边，凝视着十三层楼下的马路，一辆又一辆的汽车川流不息，越开越远，直至消失在视野尽头······ 这算是我失恋后历经的第五阶段吗？ 重新思考, 重新上路苦海无边，回头是岸，我既已悟了此道，便是亡羊补牢，为时未晚。失恋的创伤即便谈不上痊愈，也至少已经结痂了。偶尔的时候，我的内心固执地不愿意放下这段往事，似乎我很酷嘛？欣赏自己痛苦的状态，以为这是一种艺术行为，或是在顾影自怜？可王小波很早就说过，自己的痛苦成全不了自己，但却会成为别人的艺术源泉。所以我真得不必与自己过意不去，如果没有这场恋爱，也许我会走出另一种完全不同的人生，可能迷上了网络游戏而不能自拔，也可能错过了我这位南邮同学，却在另外一段感情中陷入绝境。这些都不是真实的我，该来的总归会来，挫折与磨炼无可回避。 偶尔和其他一些初高中同学交流，我发现他们好些人现在都过得十分 “幸福”，在老家三四线小城市里做一个公务员或国企职工，每天朝九晚五，不知加班为何物。收入高的也有七八千，进展快的已经结婚生子，开启天伦之乐。这种生活从某些角度讲可能叫做一眼望到路的尽头，遭到了很多人的不屑，但说真的如果让我选择是否向往这种生活，我恐怕会犹豫：如果说我不喜欢这种生活，那是因为我不甘心如此平庸，不希望自己一辈子只是养家糊口而无所成就；如果说我向往这种生活，那是因为它不会占用我的个人时间，除了周末外，每个工作日的晚上也归自己自由支配，我可以无干扰地做我自己想做的事。 什么是我自己想做的事？现在的我已经不是大学时那个不顾一切，舍命追求计算机的自己了。我欣慰得发现，曾经的爱好，阅读、写作、运动，其实都没有彻底泯灭，野火烧不尽，春风吹又生，它们只是躲了起来，在暗中观察我，期待着我的苏醒。只要我愿意醒过来，它们会永远追随我。我想做的事，就是找回曾经的那个自己，真实而自然的自己！ “什么是真实？真实是你看到什么，听到什么，做什么，和谁在一起，有一种从心灵深处满溢出来的，不懊恼也不羞耻的平和与喜悦。” 真实是有所成就的前提条件，不满足这一前提的所谓成就，是违心与压迫的产物，它将不会饱含激情与心血，也就注定逃不出平庸的罗网。 而当前的我就像一个标准加工的产品，计算机科班出生，毕业后进入著名互联网公司工作，两年后跳槽，薪水大幅提升。如果继续朝这个路线走下去，再过两年可以考虑去阿里巴巴，争取一个 P7 的职位。这是一个 “理想” 的职业发展轨迹，很多人都在冥冥中被如此安排了命运。我可以说不吗？这不是我想要的生活，如果这种职业攀升路线需要耗费我过多的精力在业务内容上，我根本不觉得这实现了我的人生价值，我不想被计算机的世界绑票。 其实这并不妨碍我热爱计算机，只是我的爱好十分广泛，我不允许自己囿于狭窄的一隅，却错过盎然多姿的世界！古今中外，文学大家的风骨；沧海桑田，历史车轮的磅礴；造化诡谲，基因破译的秘密；算法精妙，人工智能的潜能；股海沉浮，商业战场的博弈；宏观调控，经济运转的定律······说白了，我今生今世，发自肺腑想要做的，想探索的，想感悟的，不依赖于某个企业的环境或某个个人的意志，而是在于综合的这个世界的本身，这是我个人的价值得以实现的唯一途径。 过去与未来：愿阳光与我同在2009 年我上高中，任职班长，沉稳自信，深受同学好评； 2010 年负责学校广播台，被评为优秀学生会干事； 2010 年校园合唱比赛，任指挥，带领班级拿下年级第一名； 2011 年校元旦文艺汇演，任主持人，同时自编自谱原创音乐，穿插表演，获最佳创意奖； 2012 年我上大学，在学院迎新晚会上参与舞台剧《霸王别姬》，主演项羽，被评为晚会最佳节目； 2012 年 10 月 18 日中午 11:28，我失恋了，阳光遁入乌云深处，接着便发生了上述的一切！ 你想取代我，我就成为你。六年一个轮回，一段修行，我从绝望中来，向光明中去。挫折曾令我沮丧，命运曾强大到令我生不出改变它的念头。可是过去的我如此优秀，凭什么叫我对不堪的当下低头？我的青春也不过只有这些日子，还得抓紧时间赶路，我已经听到了未来的呼唤。 采月湖畔的浪漫回忆入学军训时你的靓影从我左肩划过，我便知道我将邂逅一段只在文学作品中才描述过的浪漫故事。我想陪你看书，也想两年后带你去上海迪士尼变成白雪公主；我想为你写诗，也想为你亲自谱一曲专属的浪漫乐章。 图书馆有我们坐在一起的背影，我认真帮你准备学生会入职后的第一份 PPT；学校餐厅有我们面对面的甜蜜，无需多贵，两杯奶茶就足以营造温馨的氛围；创行中国的答辩现场，你流畅的思路与犀利的言辞，无论对手是谁，在我心中都不及你半分；我买了你最爱吃的柚子与火龙果，你爱吃的水果当然也是我爱吃的水果。 天色渐晚，秋风宜人，你挽着我的手臂坐在了柔软的草地上。月光朦胧，如轻薄的衣纱从天而降，徐徐落在我双掌之间，你那洁白如玉的手上。微风拂过，依偎在我肩上的脸蛋，被吹乱的秀发迷离了双眼，采月湖面上波光粼粼，我心亦泛起阵阵涟漪。远处旖旎的路灯下，南师的佳人们入对出双，而你和我，只愿在这起霞坡的芳草地上，同蟋蟀为友，与蜻蜓为伴，相与枕藉，宁可不觉东方之既白。 六年恍如隔世，漫天的我在空中肆意飘洒，落在火红的枫叶上，“你” 还在想我吗？","categories":[{"name":"life","slug":"life","permalink":"http://zshell.cc/categories/life/"},{"name":"thought","slug":"life/thought","permalink":"http://zshell.cc/categories/life/thought/"}],"tags":[{"name":"思考","slug":"思考","permalink":"http://zshell.cc/tags/思考/"},{"name":"人生","slug":"人生","permalink":"http://zshell.cc/tags/人生/"}]},{"title":"linux 重度使用者拿到 MacBook 后的一系列挣扎","slug":"life-pc--linux重度使用者拿到MacBook后的一系列挣扎","date":"2018-08-26T07:46:05.000Z","updated":"2018-09-24T08:45:11.690Z","comments":true,"path":"2018/08/26/life-pc--linux重度使用者拿到MacBook后的一系列挣扎/","link":"","permalink":"http://zshell.cc/2018/08/26/life-pc--linux重度使用者拿到MacBook后的一系列挣扎/","excerpt":"新东家发的办公笔记本是 MacBook Pro, 来之前我还觉得挺高大上, 然而真正开始用的时候发现, OS X 对于 linux 用户来说实在是太难于上手了, 甚至感觉比 Windows 系统还不习惯, Windows 好歹从前还是使用过的, OS X 简直就和初学者使用 vim 一样不知所措;","text":"新东家发的办公笔记本是 MacBook Pro, 来之前我还觉得挺高大上, 然而真正开始用的时候发现, OS X 对于 linux 用户来说实在是太难于上手了, 甚至感觉比 Windows 系统还不习惯, Windows 好歹从前还是使用过的, OS X 简直就和初学者使用 vim 一样不知所措; 关于一些常规而必备的软件 (如 chrome, thunderbird, atom/sublime, jetbrains 系列, jdk 等等), 本文就不再赘述了; 搞定 sudo 权限说来蛋疼的是, 即便已使用 visudo 命令开启了用户的 sudo 权限, OS X 依然不允许修改系统级的目录, 这是 OS X 在 10.11 中引入的 System Integrity Protection (SIP) 特性; 我观察了一下, 差不多除了 /usr/local 这一原本就该属于用户自己管理的目录下之外, 其余的都无法操纵, 切到 root 也不行, 可以说算是另一个阉割版的 admin;所以拿到本子的第一件事就应该是关闭 SIP 特性, 否则后面的操作会显得束手束脚:12# 开机, command + r 进入 rescue 模式csrutil disable 这样就可以关闭 SIP 特性, 后面就可以以 sudo 权限操纵系统级的目录了; 安装 Homebrew作为 Mac 生态下主流的包管理软件, 安装 Homebrew 是使用 Mac 的程序员必做的事情之一, 否则后面想在命令行装东西可就费劲了;1curl -LsSf http://github.com/mxcl/homebrew/tarball/master | sudo tar xvz -C/usr/local –strip 1 如果遇到 Error: Unknown command: install, 则需要更新 Homebrew:1brew update 这时就体现了完整版 sudo 权限的重要性: brew update 命令需要更新 /usr/local/ 下的文件, 如果开启了 SIP 特性, 这个操作就没权限执行了; &nbsp;有了 brew 之后, 后面安装与管理各种软件就方便多了; Homebrew 的命令是比较简洁明了的:12345678# 安装与卸载brew install $packagebrew uninstall $package# 查询brew listbrew search $packagebrew info $package 安装 showsocks client借助 brew 命令, Mac 下面部署梯子的操作倒还算方便:1brew install shadowsocks-libev 自定义一个开机启动脚本, 让 mac 每次开机时自动运行 ss-local:123#!/bin/bash/usr/local/opt/shadowsocks-libev/bin/ss-local -c /etc/shadowsocks.json &amp; 使用解放鼠标的资源定位器目前我了解到的, 这种通过快捷键召唤出来并能够根据关键字定位资源的工具, 大致有三类主流的代表: spotlight, alfred 以及 devonthink; mac 本身自带 spotlight, 通过 command + space 召唤出来, 其特点是增量渐进式得搜索各种类型的资源, 可能包括 app, document, image 等, 一边搜索一边展示最新的结果, 速度稍慢; 我在我的 mac 上安装的是第二个 alfred: alfred 通过 option + space 召唤出来, 并且默认优先搜索 app, 只有当多敲一个空格或单引号时才会搜索 document 等其他类型;这个设计我觉得完全不冗余, 反而是很精妙, 因为它用极其微小的代价 (一个空格/单引号) 就将最频繁与非频繁的资源类型作了隔离, 让最频繁的资源类型以极高的效率被检索到, 而不是像 spotlight 那样全盘通吃却拉低了整体搜索的响应时间; 第三个是 devonthink: 这个工具的功能更加专注, 它就是一个搜索引擎, 当我们将需要被索引的文件放入 devonthink 作预处理, 往后就可以以极高的效率通过文档内容中的关键字检索到目标文档了;对我来说, 需要被检索的知识与文档我都用专业的云笔记去作归档与备份, 所以我并不额外需要 devonthink 这样的工具了; 安装 sougoupinyin 代替默认输入法苹果自带的中文输入法不是很好用, 中英文切换默认使用 ctrl + space 组合, 十分不方便, 具体在哪里修改设置我也懒得看了; 此时需要下载符合国人习惯的 sougoupinyin, 当然由于搜狗对 mac 的支持比较友好, 仅需一键安装即可, 此处就不用多说了;在输入法方面, 不得不承认 mac 是比 linux (至少是 fedora) 要方便不少的: fedora 上的 sougoupinyin 一直停滞更新, 目前最新版本依然有严重 bug, 我不得不去移植 ubuntu 环境下的 deb 包才能满足我在 fedora 下的使用; 配置更友好的终端环境mac 自带的 terminal 也不是很好用, 不过有第三方强大的替代品可以选择, 我这里选择的一个终端环境的组合是 iTerm2 + oh-my-zsh, 以代替原有的 terminal + bash 的默认组合;首先通过菜单栏更改 iTerm2 为 default terminal;iTerm2 支持各种个性化的配置, 包括终端颜色, 快捷键等, 我这里选择的配色方案是 solarized 中的 Solarized Dark;接下来是安装 zsh 的全能管家 oh-my-zsh:1234# by curlsh -c \"$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\"# by wgetsh -c \"$(wget https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)\" oh-my-zsh 的配置文件默认是 ~/.zshrc, 这个文件里有几个关键配置项:123# 加载 oh-my-zsh 的核心内容export ZSH=\"/Users/zshell/.oh-my-zsh\"source $ZSH/oh-my-zsh.sh 以下为个性化定制:1234567891011# 定制主题ZSH_THEME=\"ys\"# 开启语法高亮插件source /usr/local/share/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh# 定制插件plugins=( git osx docker zsh-autosuggestions) 一般比较漂亮顺眼的两款主题是 ys 和 agnoster, 在 ZSH_THEME 中可以更换, 如果使用 agnoster, 需要另外安装 Meslo 字体并在 iTerm2 中启用它;关于语法高亮插件, 可以使用 brew 安装:1brew install zsh-syntax-highlighting 然后在 .zshrc 中 source 下载的 zsh-syntax-highlighting.zsh 脚本即可;&nbsp;与 iTerm2 相关的软件资源我整理到了一个公共目录下, 以方便日后在新的 MacBook 上下载: software / iterm+; 熟悉 mac 的按键及其标识这其实是个很扯淡的事情: mac 的按键体系与其他传统的笔记本不一致, 它多了一个 command 键, 更改了 delete 键的含义, 少了一些诸如 backspace, page up/down, home/end 等按键, 如此迥异以致很多传统的快捷键在 mac 下都有很大的不同, 有些功能需要依靠按键组合来实现, 让初次接触的人很不习惯;另外 mac 的各个按键有着独特的图像标识, 在一些软件的快捷键设置面板上会频繁出现, 如果不稍作了解, 有很多标识是不太看得懂其象形含义的, 这里我对所有 MacBooK 基础按键的标识作一个整理: 按键标识 含义 ⌘ Command ⇧ Shift ⌥ Option, Alt ⌃ Control ↩ Return/Enter ⌫ Delete ⌦ 向前删除键 (Fn + Delete) ↑ / ↓ / ← / → 上下左右 箭头 ⇞ / ⇟ Page Up/Down (Fn + ↑/↓) Home / End Fn + ←/→ ⇥ 右制表符 (Tab键) ⇤ 左制表符 (Shift+Tab) ⎋ Escape (Esc) 使用总结我相信从 Windows 迁移到 mac 环境是一件阻力不大的事情, 这也是大部分人的模式, 而且这部分人群的行业分布十分广泛, 软件工程师只是其中一个子集而已; 然而对于一个长期使用 linux PC 的程序员来说, 事情就没那么富有吸引力了: mac 所能给予的生产力与效率, linux 也不遑多让, 另外对于开源软件有信仰的人来说, 这事甚至没有任何商量的余地;但其实我很清楚, 这本质上不过是一个人内心深处的偏见与执念, 长期使用 mac 的人, 让他们转投 linux 阵营也是不可能的事; 即便在 linux 业界之内, 关于 fedora, arch 与 ubuntu 的争论也是从未休止过; 关于 OS X 其实有大量的优点在本文中完全没有被提及, 可能是我觉得不值得花费时间去探索这些东西, 我在工作中所创造的价值完全依托于 linux 主机, 所以我亦使用 linux 作为我个人笔记本的操作系统, 借用这种方式以熟悉, 并更好得理解我的作品在生产环境下的工作原理: 兴许这就是我无可救药的执念……我听说阿里巴巴的办公笔记本发放的是 MacBook Pro 15’, 并且强烈不建议使用自己的笔记本办公, 非要使用的话必须安装各种安全监视与审计软件, 毕竟信息安全是上市公司的头等大事; 这么说无论如何, 我都得慢慢得去适应 mac 环境下的办公模式了, 否则将来因为强烈排斥使用公司统一发放的 MacBook Pro 而拒绝了某公司的 offer, 就有点扯淡了; 参考链接 ios brew安装记录 OS X 执行命令加了sudo还是提示Operation not permitted MAC 电脑如何启用root用户 mac sip关闭教程 苹果MAC10.11系统关闭SIP教程 Mac下终端配置(item2 + oh-my-zsh + solarized配色方案) Mac 按键标识 Alfred 3.7(938) 效率神器","categories":[{"name":"life","slug":"life","permalink":"http://zshell.cc/categories/life/"},{"name":"pc","slug":"life/pc","permalink":"http://zshell.cc/categories/life/pc/"}],"tags":[{"name":"life:pc","slug":"life-pc","permalink":"http://zshell.cc/tags/life-pc/"},{"name":"MacBook","slug":"MacBook","permalink":"http://zshell.cc/tags/MacBook/"}]},{"title":"berkeley db 7.x 压力测试报告","slug":"linux-other--berkeley_db7.x压力测试报告","date":"2018-08-12T15:10:04.000Z","updated":"2018-08-18T06:40:48.123Z","comments":true,"path":"2018/08/12/linux-other--berkeley_db7.x压力测试报告/","link":"","permalink":"http://zshell.cc/2018/08/12/linux-other--berkeley_db7.x压力测试报告/","excerpt":"之前写过一篇文章 apache benchmark 使用笔记, 介绍了 apache benchmark 的使用及注意事项, 当时我确实是使用 ab 作了一个系统的压力测试; 可惜不够重视, 我在博客里只作了关于 ab 的使用笔记, 却没有将当时压测的结果输出为一份详细报告;这次被我逮到机会了: 最近我在调研一个 KV 数据库 oracle berkeley db, 需要测试其新版本 (7.4.5) 引入堆外内存作为辅助缓存的实际性能; 我详细得记录了本次压力测试的各种细节 (已经对所有涉及公司内部的信息作了脱敏处理), 希望能以此为模板, 当以后有相关的压力测试需要时, 可以从中获得参考价值;","text":"之前写过一篇文章 apache benchmark 使用笔记, 介绍了 apache benchmark 的使用及注意事项, 当时我确实是使用 ab 作了一个系统的压力测试; 可惜不够重视, 我在博客里只作了关于 ab 的使用笔记, 却没有将当时压测的结果输出为一份详细报告;这次被我逮到机会了: 最近我在调研一个 KV 数据库 oracle berkeley db, 需要测试其新版本 (7.4.5) 引入堆外内存作为辅助缓存的实际性能; 我详细得记录了本次压力测试的各种细节 (已经对所有涉及公司内部的信息作了脱敏处理), 希望能以此为模板, 当以后有相关的压力测试需要时, 可以从中获得参考价值; 测试环境测试机器的物理配置如下:12324C64G2.7T 测试内容为了构造大量的随机数据以模拟服务的真实场景, mock 了三个接口如下:123456# 随机写, key 在 (0, xxx] 范围内随机生成, valueSize 指定 key 的大小http://$&#123;remote_url&#125;/random_set?keyRange=xxx&amp;valueSize=xxx# 随机读, key 在 (0, xxx] 范围内随机生成http://$&#123;remote_url&#125;/random_get?keyRange=xxx# 随机批量读, key 在 (0, xxx] 范围内随机生成, keyNum 指定批量个数http://$&#123;remote_url&#125;/random_mget?keyRange=xxx&amp;keyNum=yyy 在各接口中使用当前时间作为随机数发生的 seed, 确保真实随机, 然后使用 apache benchmark 作压力测试:12# 100 万次总请求, 250 并发, 5s timeoutab -n 1000000 -c 250 -s 5 http://$&#123;remote_url&#125;/random_get 基础指标分析使用 ab 收集基础数据:123456# rtmin, mean, median, P90, P99, max# 标准差/乖离率stdev# failure staterror/exception/timeout jvm 指标分析使用 jstat 采样 jvm gc 状态:12345&gt; sudo -u www jstat -gcutil -h 10 $&#123;vmid&#125; 1000 | tee /tmp/jstat_collect/xxx# sampleS0 S1 E O M CCS YGC YGCT FGC FGCT GCT5.67 0.00 48.74 70.68 98.24 - 15588 1199.695 20 2.865 1202.561 12# 收集关键 gc 状态指标YGC, YGCT, FGC, FGCT 堆外内存分析堆外内存无法使用 jmap / jstat 观察, 只能用 top 观察;1top -b -n 100 -H -p $&#123;vmid&#125; 控制变量测试计划除了计划 E 是专门对比收集器效果的, 其余的测试计划内均使用 ParNew + CMS 的收集器组合, 配置如下:123456789-XX:ParallelGCThreads=$&#123;CPU_COUNT&#125;-XX:+UseConcMarkSweepGC-XX:+UseCMSCompactAtFullCollection-XX:CMSMaxAbortablePrecleanTime=5000-XX:+CMSClassUnloadingEnabled-XX:CMSInitiatingOccupancyFraction=80-XX:+UseCMSInitiatingOccupancyOnly-XX:+CMSScavengeBeforeRemark 计划 A: in-heap 缓存大小控制测试环境:12345-Xms=25g-Xmx=25g-Xmn=10g-XX:MaxDirectMemorySize=10g-Dje.maxOffHeapMemory=10g A-1: 测试 set测试命令:123# 100 万次请求, 250 个并发ab -n 1000000 -c 250 -s 5 \"http://$&#123;remote_url&#125;/random_set?keyRange=9999999&amp;valueSize=5000\"sudo -u www jstat -gcutil -h 10 $&#123;vmid&#125; 1000 | tee /tmp/jstat_collect/A-1_X 测试结果: metrics \\ je.maxMemoryPercent 5% 10% 20% 30% RT (min/P90/P99/max) (ms) 6/122/316/1461 6/128/352/1708 6/125/365/3354 ab timeout RT (mean/median) (ms) 85/73 87/75 88/75 / error/timeout 0 0 0 / stdev/bias 68.2 72.0 77.0 / YGC/YGCT (s) 14/2.998 14/4.397 16/6.278 / FGC/FGCT (s) 0/0 0/0 2/0.589 / A-2: 测试 get测试命令:123# 100 万次请求, 250 个并发ab -n 1000000 -c 250 -s 5 \"http://$&#123;remote_url&#125;/random_get?keyRange=9999999\"sudo -u www jstat -gcutil -h 10 $&#123;vmid&#125; 1000 | tee /tmp/jstat_collect/A-2_X 测试结果: metrics \\ je.maxMemoryPercent 5% 10% 20% 30% RT (min/P90/P99/max) (ms) 9/32/29/1030 8/26/29/1038 8/27/29/1218 / RT (mean/median) (ms) 24/24 23/24 22/21 / error/timeout 2 2 5 / stdev/bias 15.8 17.8 27.8 / YGC/YGCT (s) 7/1.442 6/0.963 6/0.907 / FGC/FGCT (s) 0/0 0/0 0/0 / A-3: 测试 mget测试命令:123# 100 万次请求, 250 个并发ab -n 1000000 -c 250 -s 5 \"http://$&#123;remote_url&#125;/random_mget?keyRange=9999999&amp;keyNum=20\"sudo -u www jstat -gcutil -h 10 $&#123;vmid&#125; 1000 | tee /tmp/jstat_collect/A-3_X 测试结果: metrics \\ je.maxMemoryPercent 5% 10% 20% 30% RT (min/P90/P99/max) (ms) 8/28/34/4529 6/28/31/4804 6/27/33/1073 / RT (mean/median) (ms) 34/26 32/25 25/23 / error/timeout 2006 10907 14300 / stdev/bias 139.5 29.8 24.3 / YGC/YGCT (s) 26/31.157 23/22.947 24/4.687 / FGC/FGCT (s) 0/0 2/1.689 1/4.243 / 测试小结在当前的测试机器上, 共有 30g 的存量数据; 根据现有的状况, 在计划 A 中选取的几个测试条件, 分别代表了: 5%: 占用较少的 jvm 堆内存资源; 10%: 比较充分得使用 jvm 堆内存资源; 20%: 比较拥挤得争用 jvm 堆内存资源; 30%: 十分拥挤得争用 jvm 堆内存资源; 当然, 根据不同机器上的不同数据分布情况, 相应的测试条件也需要调整;从以上测试结果中可以得知: 当各分片 bdb 实例的 in-heap 大小控制在比较高的水平 (20%) 时, 由于数据的 overflow, 将会对整体请求的稳定性造成影响, 产生比较大的乖离率, timeout/error 概率也相应增大; 而当 in-heap 大小控制到更高水平 (30%) 时, 甚至在 250 并发强度下无法正常提供服务, 发生大量 timeout 以及 connection error;综合来说, 这里建议比较充分得使用 jvm 堆内存, 对应测试中的第二项条件 10%; 计划 B: off-heap 缓存大小控制测试环境:1234-Xms=25g-Xmx=25g-Xmn=10g-Dje.maxMemoryPercent=10 B-1: 测试 set测试命令:123# 100 万次请求, 250 个并发 ab -n 1000000 -c 250 -s 5 \"http://$&#123;remote_url&#125;/random_set?keyRange=9999999&amp;valueSize=5000\"sudo -u www jstat -gcutil -h 10 $&#123;vmid&#125; 1000 | tee /tmp/jstat_collect/B-1_X 测试结果: metrics \\ je.maxMemoryPercent 5% 10% 20% 30% RT (min/P90/P99/max) (ms) 6/122/339/3173 7/117/318/1714 6/128/352/1708 6/131/153/3074 RT (mean/median) (ms) 85/73 83/72 87/75 89/76 error/timeout 0 0 0 2 stdev/bias 71.6 69.0 78.0 75.3 YGC/YGCT (s) 14/4.398 15/5.051 14/4.397 15/4.954 FGC/FGCT (s) 0/0 0/0 1/4.243 0/0 B-2: 测试 get测试命令:123# 100 万次请求, 250 个并发ab -n 1000000 -c 250 -s 5 \"http://$&#123;remote_url&#125;/random_get?keyRange=9999999\"sudo -u www jstat -gcutil -h 10 $&#123;vmid&#125; 1000 | tee /tmp/jstat_collect/B-2_X 测试结果: metrics \\ je.maxMemoryPercent 5% 10% 20% 30% RT (min/P90/P99/max) (ms) 9/25/29/1030 8/25/28/1225 8/26/29/1038 823/28/29/441 RT (mean/median) (ms) 23/22 23/22 23/24 23/26 error/timeout 11 5 2 371 stdev/bias 22.5 25.8 17.8 11.6 YGC/YGCT (s) 8/1.222 7/1.214 6/0.963 8/1.602 FGC/FGCT (s) 0/0 0/0 0/0 0/0 B-3: 测试 mget测试命令:123# 100 万次请求, 250 个并发ab -n 1000000 -c 250 -s 5 \"http://$&#123;remote_url&#125;/random_mget?keyRange=9999999&amp;keyNum=20\"sudo -u www jstat -gcutil -h 10 $&#123;vmid&#125; 1000 | tee /tmp/jstat_collect/B-3_X 测试结果: metrics \\ je.maxMemoryPercent 5% 10% 20% 30% RT (min/P90/P99/max) (ms) 6/28/162/1029 6/27/145/1342 6/28/31/4804 6/27/67/1431 RT (mean/median) (ms) 26/24 26/24 32/25 26/23 error/timeout 9011 9467 10907 10875 stdev/bias 29.1 35.5 29.8 36.8 YGC/YGCT (s) 27/3.758 26/3.535 23/22.947 23/3.05 FGC/FGCT (s) 2/0.236 2/0.236 2/1.689 2/0.245 测试小结berkeley db 使用堆外内存作为堆内存 overflow 后 spill to disk 之间的缓冲区; 计划 B 分别选取了四个差异较大的测试条件; 从测试结果中可以得知:分配相对充分的 off-heap 比例作为 disk 缓冲区是有一定的效果的, 在 get 测试和 mget 测试中, 10g 与 20g 的测试组都在 gc 次数与 gc 时间上比 512m 和 1g 的测试组占有优势; 在乖离率方面, 10g 与 20g 的测试组也较 512m 和 1g 测试组较低, 稳定性更加;综合来说, 这里建议分配相对充分的堆外内存 (10g ~ 20g) 作为 disk buffer; 计划 C: -Xmx / -Xms 大小控制一般控制 -Xmx 与 -Xms 相同, 同时这里设置 -XX:NewRatio=2;需要注意的是, 在 64 位机器上, 当 jvm 内存超过 32g, 指针压缩 (CompressedOops) 功能将无法生效, 内存使用效率将会降低; 所以无论机器的物理内存有多大, 每个 jvm 实例的 Xmx 都不建议超过 31g;测试环境:123-Dje.maxMemoryPercent=10-XX:MaxDirectMemorySize=10g-Dje.maxOffHeapMemory=10g C-1: 测试 set测试命令:123# 100 万次请求, 250 个并发ab -n 1000000 -c 250 -s 5 \"http://$&#123;remote_url&#125;/random_set?keyRange=9999999&amp;valueSize=5000\"sudo -u www jstat -gcutil -h 10 $&#123;vmid&#125; 1000 | tee /tmp/jstat_collect/C-1_X 测试结果: metrics \\ je.maxMemoryPercent 5% 10% 20% 30% RT (min/P90/P99/max) (ms) 6/123/324/3092 6/123/343/3140 6/128/352/1708 6/138/324/3101 RT (mean/median) (ms) 83/70 86/74 87/75 94/80 error/timeout 0 0 0 26 stdev/bias 69.0 76.1 72.0 82.3 YGC/YGCT (s) 38/4.035 19/11.268 6/0.963 12/6.99 FGC/FGCT (s) 2/0.202 0/0 0/0 0/0 C-2: 测试 get测试命令:123# 100 万次请求, 250 个并发ab -n 1000000 -c 250 -s 5 \"http://$&#123;remote_url&#125;/random_get?keyRange=9999999\"sudo -u www jstat -gcutil -h 10 $&#123;vmid&#125; 1000 | tee /tmp/jstat_collect/C-2_X 测试结果: metrics \\ je.maxMemoryPercent 5% 10% 20% 30% RT (min/P90/P99/max) (ms) 9/25/28/2819 8/25/28/1077 8/26/29/1038 10/25/28/1429 RT (mean/median) (ms) 22/22 22/22 23/24 22/22 error/timeout 368 539 112 86 stdev/bias 45.1 17.7 17.8 18.8 YGC/YGCT (s) 17/1.912 12/1.154 14/4.397 5/1.206 FGC/FGCT (s) 1/1.934 0/0 0/0 0/0 C-3: 测试 mget测试命令:123# 100 万次请求, 250 个并发ab -n 1000000 -c 250 -s 5 \"http://$&#123;remote_url&#125;/random_mget?keyRange=9999999&amp;keyNum=20\"sudo -u www jstat -gcutil -h 10 $&#123;vmid&#125; 1000 | tee /tmp/jstat_collect/C-3_X 测试结果: metrics \\ je.maxMemoryPercent 5% 10% 20% 30% RT (min/P90/P99/max) (ms) 6/28/102/1195 6/29/140/1264 6/28/31/4804 6/28/159/1344 RT (mean/median) (ms) 27/25 27/25 32/25 28/25 error/timeout 6125 9410 1090 7670 stdev/bias 28.8 28.7 29.8 38.1 YGC/YGCT (s) 66/4.818 32/3.579 23/22.947 20/5.442 FGC/FGCT (s) 4/0.197 2/0.202 2/1.689 2/0.469 测试小结此次升级 bdb 版本的重要目的就是使用堆外内存, 降低堆内存, 从而降低 gc 的压力; 在计划 C 中选取了不同的 Xmx, 从测试结果中可以得知:较高的堆内存 (30g) 虽然没有明显的 gc 压力, 但是在乖离率, max rt 等方面相比中等内存 (20g, 25g) 有增加; 另外, 较低的堆内存 (10g) 由于可用内存太少, 可以看出存在频繁的 gc, 无论是 young gc 还是 old gc, 都明显高于其他测试组;综合来说, 这里建议分配适当的堆内存空间 (20g ~ 25g) 作为 Xmx; 计划 D: bdb 版本对比选取对比的两个目标版本为: 6.4.25 vs 7.4.5;测试环境:123456-Xms=25g-Xmx=25g-Xmn=10g-Dje.maxMemoryPercent=10-XX:MaxDirectMemorySize=30g-Dje.maxOffHeapMemory=10g 注意: 当 bdb 版本降为 6.4.25 时, 其性能已支撑不了前面三个测试计划中的 250 并发量, 频繁超时, 无法收集到有效数据; 经过多次调节, 确定将并发数降低到 50 方可收集到有效数据; D-1: 测试 set测试命令:123# 50 万次请求, 50 个并发ab -n 1000000 -c 50 -s 5 \"http://$&#123;remote_url&#125;/random_set?keyRange=9999999&amp;valueSize=5000\"sudo -u www jstat -gcutil -h 10 $&#123;vmid&#125; 1000 | tee /tmp/jstat_collect/D-1_X 测试结果: metrics \\ version 6.4.25 7.4.5 RT (min/P90/P99/max) (ms) 6/24/40/755 6/24/40/1015 RT (mean/median) (ms) 17/15 17/15 error/timeout 0 0 stdev/bias 13.5 13.4 YGC/YGCT (s) 7/2.739 7/2.621 FGC/FGCT (s) 0/0 0/0 D-2: 测试 get测试命令:123# 50 万次请求, 50 个并发ab -n 500000 -c 50 -s 5 \"http://$&#123;remote_url&#125;/random_get?keyRange=9999999\"sudo -u www jstat -gcutil -h 10 $&#123;vmid&#125; 1000 | tee /tmp/jstat_collect/D-2_X 测试结果: metrics \\ version 6.4.25 7.4.5 RT (min/P90/P99/max) (ms) 6/8/8/1077 6/8/8/1130 RT (mean/median) (ms) 7/7 7/7 error/timeout 2 2 stdev/bias 12.6 10.9 YGC/YGCT (s) 3/0.604 4/0.849 FGC/FGCT (s) 0/0 0/0 D-3: 测试 mget测试命令:123# 50 万次请求, 50 个并发ab -n 500000 -c 50 -s 5 \"http://$&#123;remote_url&#125;/random_mget?keyRange=9999999&amp;keyNum=20\"sudo -u www jstat -gcutil -h 10 $&#123;vmid&#125; 1000 | tee /tmp/jstat_collect/D-3_X 测试结果: metrics \\ version 6.4.25 7.4.5 RT (min/P90/P99/max) (ms) 6/8/9/510 6/8/9/1068 RT (mean/median) (ms) 8/7 8/7 error/timeout 8 2 stdev/bias 9.2 12.0 YGC/YGCT (s) 8/1.561 8/1.049 FGC/FGCT (s) 0/0 0/0 测试小结从测试结果来看, 50 并发量的请求压力下, 6.4.25 与 7.4.5 版本没有存在明显的差距; 但是在更高的并发量下, 6.4.25 版本的 berkeley db 根本扛不住;所以这里毫无疑问, 7.4.5 版本的 berkeley db 是优于 6.4.25 版本的; 计划 E: 收集器对比最后是关于收集器的对比; 考虑到 G1 对于大内存 (大于 16g) 的延时管理较其他收集器有优势, 这里也需要就收集器作一些对比测试;两个收集器的选项对比如下:ParNew + CMS:12345678-XX:ParallelGCThreads=$&#123;CPU_COUNT&#125;-XX:+UseConcMarkSweepGC-XX:+UseCMSCompactAtFullCollection-XX:+CMSClassUnloadingEnabled-XX:CMSInitiatingOccupancyFraction=80-XX:+UseCMSInitiatingOccupancyOnly-XX:+CMSScavengeBeforeRemark G1:123-XX:+UnlockDiagnosticVMOptions-XX:+UseG1GC-XX:+G1SummarizeConcMark 测试环境:123456-Xms=25g-Xmx=25g-Xmn=10g-Dje.maxMemoryPercent=10-XX:MaxDirectMemorySize=30g-Dje.maxOffHeapMemory=10g E-1: 测试 set测试命令:123# 100 万次请求, 250 个并发ab -n 1000000 -c 250 -s 5 \"http://$&#123;remote_url&#125;/random_set?keyRange=9999999&amp;valueSize=5000\"sudo -u www jstat -gcutil -h 10 $&#123;vmid&#125; 1000 | tee /tmp/jstat_collect/E-1_X 测试结果: metrics \\ collector CMS G1 RT (min/P90/P99/max) (ms) 6/128/352/1708 ab timeout RT (mean/median) (ms) 87/75 / error/timeout 0 / stdev/bias 72.0 / YGC/YGCT (s) 14/4.397 / FGC/FGCT (s) 0/0 / E-2: 测试 get测试命令:123# 100 万次请求, 250 个并发ab -n 1000000 -c 250 -s 5 \"http://$&#123;remote_url&#125;/random_get?keyRange=9999999\"sudo -u www jstat -gcutil -h 10 $&#123;vmid&#125; 1000 | tee /tmp/jstat_collect/E-2_X 测试结果: metrics \\ collector CMS G1 RT (min/P90/P99/max) (ms) 8/26/29/1038 / RT (mean/median) (ms) 23/24 / error/timeout 2 / stdev/bias 17.8 / YGC/YGCT (s) 6/0.963 / FGC/FGCT (s) 0/0 / E-3: 测试 mget测试命令:123# 100 万次请求, 250 个并发ab -n 1000000 -c 250 -s 5 \"http://$&#123;remote_url&#125;/random_mget?keyRange=9999999&amp;keyNum=20\"sudo -u www jstat -gcutil -h 10 $&#123;vmid&#125; 1000 | tee /tmp/jstat_collect/E-3_X 测试结果: metrics \\ collector CMS G1 RT (min/P90/P99/max) (ms) 6/28/31/4804 / RT (mean/median) (ms) 32/25 8/7 error/timeout 10907 / stdev/bias 29.8 / YGC/YGCT (s) 23/22.947 / FGC/FGCT (s) 2/1.689 / 测试小结可惜了, 我 retry 了几次, 使用 G1 gc, ab 都在途中 timeout 了; jstat 显示 G1 的 young gc 经历了一个非常长的时间:12345S0 S1 E O M CCS YGC YGCT FGC FGCT GCT 0.00 100.00 94.87 47.44 98.45 96.54 12 6.923 0 0.000 6.9230.00 100.00 94.87 47.44 98.45 96.54 12 6.923 0 0.000 6.9230.00 100.00 2.89 50.92 98.46 96.54 12 14.315 0 0.000 14.3150.00 100.00 2.97 50.92 98.46 96.54 12 14.315 0 0.000 14.315 12345S0 S1 E O M CCS YGC YGCT FGC FGCT GCT 0.00 100.00 94.87 50.92 98.46 96.54 13 14.315 0 0.000 14.3150.00 100.00 94.87 50.92 98.46 96.54 13 14.315 0 0.000 14.3150.00 100.00 2.14 55.58 98.29 96.54 13 25.692 0 0.000 25.6920.00 100.00 2.21 55.58 98.29 96.54 13 25.692 0 0.000 25.692 我对 G1 的了解还是不够深入, 可能当前的场景比较特殊, 需要作定制化的调参, 之前使用 G1 都是只加 -XX:+UseG1GC 和 -XX:+G1SummarizeConcMark 两个参数, 其余的优化都交给 jvm 了, 然而对于今天的场景这可能不够用了, 这个需要另行研究了; 测试总结本次测试采用 ab + jstat 组合的方式同时采集测试数据, ab 用于反映系统表面的性能指标, jstat 用于反映系统的 gc 状态, 并进而反映隐藏在表面之下的系统性能问题或者服务潜力;本次测试并没有作极限测量 (不断增大并发直至压挂为止), 而是根据当前的调用状况取了一个留有适当 buffer 的并发量, 从测试结果中可以间接得计算当前服务能承载的 TPS;根据测试的结果, 7.4.5 版本的 berkeley db 优于 6.4.25 版本的 berkeley db, 其在并发承受能力上存在明显优势;在收集器选择上, 暂时还是使用 CMS 比较稳妥, G1 可能遇到了特殊的情况, 需要后续研究调优的方法;在使用 7.4.5 版本的 berkeley db 时, 建议作如下内存配置组合, 以达到较好的使用效果:123456-Xms= 20g ~ 30g-Xmx= 20g ~ 30g-Dje.maxMemoryPercent= $&#123;Xmx&#125; * 80% / $&#123;bdb_shard_number&#125;-XX:MaxDirectMemorySize= ($&#123;machine_total_memory&#125; - $&#123;Xmx&#125;) * 80%-Dje.maxOffHeapMemory= $&#123;MaxDirectMemorySize&#125; / $&#123;bdb_shard_number&#125;","categories":[{"name":"linux","slug":"linux","permalink":"http://zshell.cc/categories/linux/"},{"name":"other","slug":"linux/other","permalink":"http://zshell.cc/categories/linux/other/"}],"tags":[{"name":"linux:perf","slug":"linux-perf","permalink":"http://zshell.cc/tags/linux-perf/"},{"name":"jvm:gc","slug":"jvm-gc","permalink":"http://zshell.cc/tags/jvm-gc/"},{"name":"linux:other","slug":"linux-other","permalink":"http://zshell.cc/tags/linux-other/"}]},{"title":"ThreadLocal 相关知识全梳理","slug":"jdk--ThreadLocal相关知识全梳理","date":"2018-08-03T09:30:03.000Z","updated":"2018-08-05T09:32:13.208Z","comments":true,"path":"2018/08/03/jdk--ThreadLocal相关知识全梳理/","link":"","permalink":"http://zshell.cc/2018/08/03/jdk--ThreadLocal相关知识全梳理/","excerpt":"两年前在老东家, 我于 InheritableThreadLocal 上踩过一次坑, 可惜当时坑不算深, 就没有把相关的知识点总结下来; 结果两年后的今天我在新东家又遇到了类似问题, 似曾相识却又记不太清楚具体的情况了; 所以这一次一定要认真总结一下 (本文代码基于 jdk 1.8);","text":"两年前在老东家, 我于 InheritableThreadLocal 上踩过一次坑, 可惜当时坑不算深, 就没有把相关的知识点总结下来; 结果两年后的今天我在新东家又遇到了类似问题, 似曾相识却又记不太清楚具体的情况了; 所以这一次一定要认真总结一下 (本文代码基于 jdk 1.8); 原生 ThreadLocal 的使用注意点线程关联的原理ThreadLocal 并不是一个独立的存在, 它与 Thread 类是存在耦合的, java.lang.Thread 类针对 ThreadLocal 提供了如下支持:123/* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ThreadLocal.ThreadLocalMap threadLocals = null; 每个线程都将自己维护一个 ThreadLocal.ThreadLocalMap 类在上下文中; 所以, ThreadLocal 的 set 方法其实是将 target value 放到当前线程的 ThreadLocalMap 中, 而 ThreadLocal 类自己仅仅作为该 target value 所对应的 key:12345678public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125; 123ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; 123void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125; get 方法也是类似的道理, 从线程的 ThreadLocalMap 中获取以当前 ThreadLocal 为 key 对应的 value:12345678910111213public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(\"unchecked\") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125; 需要注意的是, 如果没有 set 过 value, 此处 get() 将返回 null, 不过 initialValue() 方法是一个 protected 方法, 所以子类可以重写逻辑实现自定义的初始默认值;12345678910private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;&#125; 123protected T initialValue() &#123; return null;&#125; 综上所述: ThreadLocal 实现线程关联的原理是与 Thread 类绑定, 将数据存储在对应 Thread 的上下文中; 使用中的注意点ThreadLocal 中主要有两个使用中需要注意的地方; (1) 谨防 ThreadLocal 导致的内存泄露和 OOM讨论这个问题之前, 需要先介绍一下 ThreadLocal.ThreadLocalMap 类中维护了的一个自定义数据结构 Entry, 其定义如下:123456789static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125; 这里要注意的是, Entry 类继承了弱引用 WeakReference, 更具体的说, Entry 中的 key (ThreadLocal 类型) 使用弱引用, value 依旧使用强引用; To help deal with very large and long-lived usages, the hash table entries use WeakReferences for keys. 这其实是一个令初学者感到困惑的设计:假设 Entry 不继承 WeakReference, 令 key 也使用强引用, 那么结合上一节的内容, 只要该 thread 不退出, 通过 Thread -&gt; ThreadLocal.ThreadLocalMap -&gt; key 这条引用链, 该 key 就可以一直与 gc root 保持连通; 这时即便在外部这个 key 对应的 threadLocal 已经没有有效引用链了, 但只要该 thread 不退出, jvm 依旧会判定该 threadlocal 不可回收;于是尴尬的事情发生了: 由于 ThreadLocal.ThreadLocalMap 这个内部类没有对外暴露 public 方法, 在 Thread 类里面 ThreadLocal.ThreadLocalMap 也是 package accessible 的, 这意味着我们已经没有任何方法访问到该 key 对应的 value 了, 可它就是无法被回收, 这便是一个典型的内存泄露;而如果使用 WeakReference 这个问题就解决了: 当该 key 对应的 threadlocal 在外部已经失效后, 便仅存在 thread 里的 weak reference 指向它, 下次 gc 时这个 key 就会被回收掉;针对这一特性, ThreadLocal.ThreadLocalMap 也配套了与之相适应的内部清理方法:12345678910111213141516171819202122232425262728293031private int expungeStaleEntry(int staleSlot) &#123; Entry[] tab = table; int len = tab.length; // expunge entry at staleSlot tab[staleSlot].value = null; tab[staleSlot] = null; size--; // Rehash until we encounter null Entry e; int i; for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; e.value = null; tab[i] = null; size--; &#125; else &#123; int h = k.threadLocalHashCode &amp; (len - 1); if (h != i) &#123; tab[i] = null; // Unlike Knuth 6.4 Algorithm R, we must scan until null because multiple entries could have been stale. while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; &#125; &#125; &#125; return i;&#125; 在该方法里, 除了清理指定下标 staleSlot 的 entry 外, 还会遍历整个 entry table, 当发现有 key 为 null 时, 就会触发 rehash 压缩整个 table, 以达到清理的作用;下面就要提到这里的一个隐藏的坑, ThreadLocal 并没有配合使用 ReferenceQueue 来监听已经回收的 key 以实现自动回调 expungeStaleEntry 方法清理空间的功能; 所以 threadlocal 实例是回收了, 但是引用本身还在, 其所对应的 value 也就还在: However, since reference queues are not used, stale entries are guaranteed to be removed only when the table starts running out of space. 实际上, expungeStaleEntry 方法是被安插到了 ThreadLocal.ThreadLocalMap 中的 get, set, remove 等方法中, 并被 ThreadLocal 的 get, set, remove 方法间接调用, 必须显式得调用这些方法, 才能主动式地清理空间;在某些极端场景下, 如果某些 threadlocal 设置的 value 是大对象, 而所涉及的 thread 却没来得及在 threadlocal 被 gc 前作 remove, 再加上之后也没有什么其他 threadlocal 去作 get / set 操作, 那这些大对象是没机会被回收的, 这将造成严重的内存泄露甚至是 OOM; 所以使用 ThreadLocal 要谨记一点: 用完主动 remove, 主动释放内存, 而且是放在 finally 块里面 remove, 以确保执行;在很多系统中, 我们会定义一个 static final 的全局 ThreadLocal, 这样其实就不存在 threadlocal 被回收的情况了, 上面说的 WeakReference 机制也将效用有限, 这种环境下我们就更加需要用完后主动作 remove 了; (2) 谨防线程复用组件下的 value 串位在下一节中我还会继续讲到 value 串位的问题; 这一节所讲的串位与下一节相比, 有相似之处也有不同的问题场景; 与此同时, 这一节的串位与上一小节的内容也有一丝关联;通常而言, 我们的代码总是跑在应用容器里, 如 tomcat, jetty, 或者是 dubbo 这样的服务框架内; 这些基础组件都有一个共性: 线程池化复用; 在这种场景下, 线程被线程池托管, 在整个应用的生命周期中, 这些 worker 线程往往是不会轻易退出的;试想一种极端场景: 在一个处理线程内, 我们条件性得 (并非每次都会) 使用 ThreadLocal.set 方法设置一个 value, 然后在后续逻辑中又使用 ThreadLocal.get 方法获取该值; 一个处理线程在上一个任务执行结束之前未作 ThreadLocal.remove 清理 value, 刚巧这个线程在接手下一个任务时未满足条件, 没有调用 ThreadLocal.set 方法设置 value, 此时它所绑定的是上一个任务的 value, 在后面调用 ThreadLocal.get 时, 拿到的就是串位的数据了;这也再一次提醒我们: 使用 ThreadLocal, 在逻辑处理完后, 一定要作 remove; InheritableThreadLocal 的特点及其使用问题首先要说的是, 上文所讲的 ThreadLocal 的问题与注意点, 对 InheritableThreadLocal 都是成立的, 这里便不再赘述;与 ThreadLocal 类似, InheritableThreadLocal 类也不是独立存在的, Thread 类针对 InheritableThreadLocal 作了如下支持:12345/* * InheritableThreadLocal values pertaining to this thread. This map is * maintained by the InheritableThreadLocal class. */ThreadLocal.ThreadLocalMap inheritableThreadLocals = null; 只是, InheritableThreadLocal 要额外实现子线程传递 threadlocal 的任务, 所以 Thread 类在构造方法中还提供了额外的支持以将父线程的 ThreadLocalMap 传递给子线程:123public Thread() &#123; init(null, null, \"Thread-\" + nextThreadNum(), 0);&#125; 12345678910111213private void init(ThreadGroup g, Runnable target, String name, long stackSize) &#123; init(g, target, name, stackSize, null, true);&#125;/* * @param inheritThreadLocals if &#123;@code true&#125;, inherit initial values for inheritable thread-locals from the constructing thread */private void init(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc, boolean inheritThreadLocals) &#123; ...... if (inheritThreadLocals &amp;&amp; parent.inheritableThreadLocals != null) this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals);&#125; 下面要说的是 InheritableThreadLocal 在线程复用组件下的串位问题;上一小节所讲的 ThreadLocal 的 value 串位问题, 对于 InheritableThreadLocal 来说也是存在的, 这点自不必说; 然对于 InheritableThreadLocal 所提供的额外功能 父子线程传递 value 来说, 还有一种线程复用场景, 会遇到类似的坑;在 jdk 1.5 之前我们没有线程池的时候, 子线程的创建都是手工及时完成的, 那种场景下父子线程的关系是唯一绑定的, 绝对不会出现 value 串位的问题; 然而 Doug Lea 大神开发了 ThreadPoolExecutor, 这彻底改变了我们使用多线程的习惯, 它不仅仅在各种容器中出现, 我们的日常代码中凡涉及多线程的地方, 大多也会采用线程池的方式实现;那么问题来了: 在线程池中, worker 线程是被复用的, worker 线程的父线程是谁并没有人关心, 反正 worker 线程的父线程大多数都比 worker 线程本身要短命许多; 而线程的初始化只发生在其创建的时候, 根据上面的内容, InheritableThreadLocal 传递 value 只发生在子线程初始化的时候, 也就是线程刚创建的时候; 所以, 往线程池中提交任务的时候, 除非是线程池刚好创建了一个新线程, 才能顺利得将 value 传递下去, 否则大多数时候都只是复用已经存在的线程, 那线程中的 value 早已不是当前线程想要传递的值; 改进 InheritableThreadLocal 的方案InheritableThreadLocal value 串位问题的根本原因在于它依赖 Thread 类本身的机制传递 value, 而 Thread 类由于其于线程池内 “复用存在” 的形式而导致 InheritableThreadLocal 的机制失效; 所以针对 InheritableThreadLocal 的改进, 突破点就在于如何摆脱对 Thread 类的依赖;现在业界内比较好的解决思路是将对 Thread 类的依赖转移为对 Runnable / Callable 的依赖, 因为提交任务时 Runnable / Callable 是实时构造出来的, 父线程可以在其构造之时将 value 植入其中; 下面以阿里为例, 介绍一种典型的实现; 阿里巴巴开源了其对 InheritableThreadLocal 的改进方案: alibaba/transmittable-thread-local;纵观其源码, TransmittableThreadLocal 的核心设计之一在于其自己维护了一个静态全局的 holder, 存储了所有的 TransmittableThreadLocal 实例:123456static ThreadLocal&lt;Map&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt;&gt; holder = new ThreadLocal&lt;Map&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt;&gt;() &#123; @Override protected Map&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt; initialValue() &#123; return new WeakHashMap&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt;(); &#125;&#125;; 这里的一个设计细节是, 其使用 WeakHashMap 作为存储 TransmittableThreadLocal 实例的容器; 这里与上文所讲的 ThreadLocal.ThreadLocalMap.Entry 使用 WeakReference 作为 key 的原理是类似的, 可以便捷得发现已经无效的 threadlocal, 而且 WeakHashMap 使用了 ReferenceQueue 去监听 key 的 gc 情况, 不用像 ThreadLocal 那样每次需要遍历全表以寻找 stale entries;同时, TransmittableThreadLocal 提供一个 copy() 方法实时复制所有 TransmittableThreadLocal 实例及其在当前线程的 value:1234567static Map&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt; copy() &#123; Map&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt; copy = new HashMap&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt;(); for (TransmittableThreadLocal&lt;?&gt; threadLocal : holder.get().keySet()) &#123; copy.put(threadLocal, threadLocal.copyValue()); &#125; return copy;&#125; TransmittableThreadLocal 的另一个核心设计是它封装了自己的 Runnable 和 Callable; 以其封装的 TtlRunnable 为例, 其提供了一个 private 类型的构造器:12345private TtlRunnable(Runnable runnable, boolean releaseTtlValueReferenceAfterRun) &#123; this.copiedRef = new AtomicReference&lt;Map&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt;&gt;(TransmittableThreadLocal.copy()); this.runnable = runnable; this.releaseTtlValueReferenceAfterRun = releaseTtlValueReferenceAfterRun;&#125; 可以发现, 在 TtlRunnable 构造之初, 除了包装原始的 Runnable 之外, 其复制了当前线程下所有的 TransmittableThreadLocal 实例及其对应的 value, 放到了一个 AtomicReference 包装的 map 之中, 这样就完成了由父线程向 Runnable 的 value 传递;下面是最关键的 run() 方法的处理:1234567891011public void run() &#123; Map&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt; copied = copiedRef.get(); // 非核心逻辑已省略 ...... Map&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt; backup = TransmittableThreadLocal.backupAndSetToCopied(copied); try &#123; runnable.run(); &#125; finally &#123; TransmittableThreadLocal.restoreBackup(backup); &#125; &#125; 拿到父线程所有的 threadlocal -&gt; value 键值对后, 需要将其一一设置到自己的 ThreadLocal 中:123456789101112131415161718192021static Map&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt; backupAndSetToCopied(Map&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt; copied) &#123; Map&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt; backup = new HashMap&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt;(); for (Iterator&lt;? extends Map.Entry&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt;&gt; iterator = holder.get().entrySet().iterator(); iterator.hasNext(); ) &#123; Map.Entry&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt; next = iterator.next(); TransmittableThreadLocal&lt;?&gt; threadLocal = next.getKey(); backup.put(threadLocal, threadLocal.get()); if (!copied.containsKey(threadLocal)) &#123; iterator.remove(); threadLocal.superRemove(); &#125; &#125; // 将 runnable 携带的父线程 threadlocal -&gt; value 键值对, 真正用 ThreadLocal.set 将 value 设置到子线程中去 for (Map.Entry&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt; entry : copied.entrySet()) &#123; @SuppressWarnings(\"unchecked\") TransmittableThreadLocal&lt;Object&gt; threadLocal = (TransmittableThreadLocal&lt;Object&gt;) entry.getKey(); threadLocal.set(entry.getValue()); &#125; doExecuteCallback(true); return backup;&#125; 接下来在调用原始 Runnable 的 run() 方法时, 便能够顺利 get 到父线程的 value 了; 参考链接 ThreadLocal WeakReference和内存泄漏的思考 话说ReferenceQueue","categories":[{"name":"jdk","slug":"jdk","permalink":"http://zshell.cc/categories/jdk/"}],"tags":[{"name":"jdk","slug":"jdk","permalink":"http://zshell.cc/tags/jdk/"},{"name":"面试考点","slug":"面试考点","permalink":"http://zshell.cc/tags/面试考点/"}]},{"title":"在裸镜像上搭建 shadowsocks server","slug":"life-pc--在裸镜像上搭建shadowsocks_server","date":"2018-07-21T14:29:35.000Z","updated":"2019-01-22T15:03:33.829Z","comments":true,"path":"2018/07/21/life-pc--在裸镜像上搭建shadowsocks_server/","link":"","permalink":"http://zshell.cc/2018/07/21/life-pc--在裸镜像上搭建shadowsocks_server/","excerpt":"什么废话都不用多说, 就一句话: 搭梯子, 程序员的基本功!最近在折腾 fedora, 想着不能老是蹭公司的 “绿色通道”, 遂自己兑了点美刀, 自力更生干了起来, 顺手在这里总结一下;","text":"什么废话都不用多说, 就一句话: 搭梯子, 程序员的基本功!最近在折腾 fedora, 想着不能老是蹭公司的 “绿色通道”, 遂自己兑了点美刀, 自力更生干了起来, 顺手在这里总结一下; 国外云主机搭梯子的痛点要搭梯子, 得买个国外的云主机服务; 以 DigitalOcean 为例, 选择 centos 系统的 elastic compute service, 如果不使用定制的 cloud-init, DigitalOcean 创建的虚机将配置默认的 yum 源 (附带一个 digitalocean 自己的源):123456789CentOS-Base.repoCentOS-CR.repoCentOS-Debuginfo.repoCentOS-fasttrack.repoCentOS-Media.repoCentOS-Sources.repoCentOS-Vault.repo# digitalocean 附带的自己的源digitalocean-agent.repo 默认的源里面是没有 shadowsocks 相关的软件包的, 这意味着我们无法使用 yum 安装 shadowsocks server; 解决问题: shadowsocks github 仓库在 shadowsocks 的 官方 github 上, 有多种 shadowsocks 版本: python, go, rust, R, nodejs 等; 以 shadowsocks-go 为例, 其 release 页面 提供各种版本的二进制包供下载; 而 GFW 迫于中国 IT 界的压力暂不能封锁 github, 这样我们就可以从 shadowsocks github 官方页面上下载 shadowsocks 了; 更加便捷的一站式工具在 github 有个好心人做了一个更加便捷的 shadowsocks 一站式安装工具 teddysun/shadowsocks_install 方便广大网民 “一键部署”; 以安装 shadowsocks-go 为例, 其提供了 shadowsocks-go.sh 脚本, 其中安装 shadowsocks 的主函数内容如下:12345678910install_shadowsocks_go() &#123; disable_selinux pre_install download_files config_shadowsocks if check_sys packageManager yum; then firewall_set fi install&#125; 其中: pre_install 方法通过 read 关键字从 stdin 中读取 password, port 与加密方式 cipher, 完成用户自定义行为; download_files 方法:(1) 从远程 url 下载 shadowsocks-server 的二进制文件, 放入 /usr/bin/ 目录;(2) 从远程 url 下载 shadowsocks-server 的 daemon 启动脚本 shadowsocks, 放入 /etc/init.d/ 目录; config_shadowsocks 方法将 pre_install 方法获取的 password, port, cipher 写入配置文件 /etc/shadowsocks/config.json; firewall_set 方法对 iptables filter 表加入了一条规则, 开放用户设置的 port 端口; install 方法就是使用 chkconfig 设置 shadowsocks-server 在 sysvinit 的启停级别, 并读取 启动服务, 交付给使用者; 可以发现, 在 centos 裸镜像中, 使用以上工具部署 shadowsocks-server 的过程总结如下:(1) 安装 wget1yum -y install wget (2) 下载安装脚本12wget --no-check-certificate -O shadowsocks-go.sh https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks-go.shsudo chmod +x shadowsocks-go.sh (3) 执行脚本1bash shadowsocks-go.sh 2&gt;&amp;1 | tee shadowsocks-server-install.log 可以说是相当方便, 为国外云主机上安装 shadowsocks-server 的首选方案; 参考链接 SS_Server的搭建及加速","categories":[{"name":"life","slug":"life","permalink":"http://zshell.cc/categories/life/"},{"name":"pc","slug":"life/pc","permalink":"http://zshell.cc/categories/life/pc/"}],"tags":[{"name":"life:pc","slug":"life-pc","permalink":"http://zshell.cc/tags/life-pc/"}]},{"title":"openssh-client 相关内容梳理","slug":"linux-ssh--openssh-client相关内容梳理","date":"2018-07-17T05:13:43.000Z","updated":"2018-08-05T11:58:39.542Z","comments":true,"path":"2018/07/17/linux-ssh--openssh-client相关内容梳理/","link":"","permalink":"http://zshell.cc/2018/07/17/linux-ssh--openssh-client相关内容梳理/","excerpt":"ssh 相关的命令是日常开发中基础中的基础, 乃是登陆机器操作必不可少的过程; 但是越是寻常, 可能越容易疏于整理总结; 本文就从 openssh-client 着手, 总结一下 .ssh 目录, ssh 相关命令, 以及相关配置文件的使用;","text":"ssh 相关的命令是日常开发中基础中的基础, 乃是登陆机器操作必不可少的过程; 但是越是寻常, 可能越容易疏于整理总结; 本文就从 openssh-client 着手, 总结一下 .ssh 目录, ssh 相关命令, 以及相关配置文件的使用; .ssh 目录.ssh 目录对权限的要求是比较苛刻的, 毕竟涉及到了私密信息的安全问题; 一般来说, .ssh 下各目录的权限要求如下 (这里只考虑使用 rsa 算法而不考虑 dsa, ecdsa 等其他非主流的加密算法): .ssh 目录自己的权限是 700; id_rsa 的目录权限是 600 (强制要求); id_rsa.pub 的目录权限一般为 644 (这个没有特殊要求); authorized_keys 的目录权限是 600 (强制要求); known_hosts 的目录权限一般为 644 (这个没有特殊要求); 以下是一个直观的例子:1234567&gt; ls -al .ssh/drwx------ 2 zshell.zhang qunarops 76 Dec 25 13:27 .drwx------ 4 zshell.zhang qunarops 94 Dec 25 14:50 ..-rw------- 1 zshell.zhang qunarops 12997 Dec 25 15:38 authorized_keys-rw------- 1 zshell.zhang qunarops 1679 Dec 25 11:55 id_rsa-rw-r--r-- 1 zshell.zhang qunarops 407 Dec 25 11:55 id_rsa.pub-rw-r--r-- 1 zshell.zhang qunarops 7931 Dec 25 14:02 known_hosts 一般来说, id_rsa 是私钥, id_rsa.pub 是公钥, 公钥与私钥的命名只是约定俗成, 没有强制规定, 可以自定义; 但自定义之后要使用特定的私钥登陆就需要在命令中使用参数指定, 具体请见下一小节;还有一点需要说明的是, 这四类文件虽然都默认存在于用户家目录下的 .ssh/ 目录中, 但对于同一台主机上的同一个用户, 这四个文件并不都会同时出现, 如果真的同时出现了, authorized_keys 与 id_rsa, known_hosts 中的内容也不会有什么关联; 关于 authorized_keys 和 known_hosts 的具体说明, 请见下文; authorized_keysauthorized_keys 记录了允许以当前用户登陆该主机的所有公钥, 但凡一个登陆请求的私钥与 authorized_keys 中的公钥相匹配, 则此次登陆成功; 所以, authorized_keys 并非用于 openssh-client, 而是 server 端的 sshd, 这也是上文所说的: 即便 authorized_keys 与 id_rsa 共存于一个 .ssh 目录下, 两者在内容上也是独立的, 前者是校验别人登陆到本机器的, 而后者是用于从本机器登陆其他主机的;在日常运维值班中, 有一个比较频繁的事情便是机器权限申请的审核与开通, 这里面的操作就涉及到 authorized_keys 的更新; 通常我们会使用自动化运维工具 (例如 saltstack, ansible) 在目标主机上执行相关的逻辑:12345# 创建用户useradd -g $&#123;user_group&#125; -d $&#123;user_dir&#125;/$&#123;user_name&#125; $user_name# 将公钥写入目标主机对应用户的 authorized_keys 文件wget -O $&#123;user_dir&#125;/$&#123;user_name&#125;/.ssh/authorized_keys http://user_query_service_url/$&#123;user_name&#125;/id_rsa.pub... known_hosts对于最后一个 known_hosts, 其主要用于 openssh-client 对每次登陆的主机的 host key 作校验; 主机 host key 的构成在 man sshd 中有如下介绍: Each line in these files contains the following fields: hostnames, bits, exponent, modulus, comment. The fields are separated by spaces. host key 中存储了 hostname, ip 等内容, 并作了哈希编码; 当 openssh-client 试图连接一个主机时: 如果在 known_hosts 中不存在该主机的 host key 信息, 则会告知使用者从未连接过该主机, 并确认是否要连接: 1234The authenticity of host '10.64.0.11 (10.64.0.11)' can't be established.RSA key fingerprint is SHA256:3O+bKYBXKHcYLBbltbuzu8dJbWaX42QHvkKeyABTyqU.RSA key fingerprint is MD5:ff:3f:57:5c:54:39:8c:71:50:71:aa:bf:1a:6e:a1:0f.Are you sure you want to continue connecting (yes/no)? 如果在 known_hosts 中存在该主机, 并且 ip 等信息并未发生变化, 则校验通过; 如果在 known_hosts 中存在该主机, 但是 ip 等信息发生了变化, 则会打印类似如下的 中间人攻击 告警信息: 123456789101112131415@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!Someone could be eavesdropping on you right now (man-in-the-middle attack)!It is also possible that the RSA host key has just been changed.The fingerprint for the RSA key sent by the remote host isad:12:0a:af:77:09:af:b0:65:16:9a:0a:04:57:2e:f1.Please contact your system administrator.Add correct host key in /home/zshell.zhang/.ssh/known_hosts to get rid of this message.Offending key in /home/zshell.zhang/.ssh/known_hosts:96Password authentication is disabled to avoid man-in-the-middle attacks.Keyboard-interactive authentication is disabled to avoid man-in-the-middle attacks.Agent forwarding is disabled to avoid man-in-the-middle attacks.X11 forwarding is disabled to avoid man-in-the-middle attacks. 其实, 在公司的内网环境中, 大可不必考虑中间人攻击的可能, 倒是日常运维操作致使主机 ip 地址改变的情况时有发生, 所以对于这种提示, 只需要更新 known_hosts 文件, 删除对应的 host key 即可:1ssh-keygen -f \"/home/zshell.zhang/.ssh/known_hosts\" -R l-xx1.ops.cn1 重新 ssh 连接, 经过询问与确认之后, 新的 host key 便会写入 known_hosts 文件; 最后回过头来总结一下:像 id_rsa 以及 authorized_keys 这类涉及到私人信息安全的文件一定是要对其余用户不可访问的: 如果私钥文件对其余用户可读, openssh-client 会直接拒绝并提示文件权限设置过宽, 如果 authorized_keys 对其余用户可读, 则用户无法登陆, 会提示需要输入密码; 而类似 id_rsa.pub 公钥这种原本设计就是要公开的信息, 设置成 644, 对其余用户只读即可; ssh 相关命令ssh 命令常用的选项如下:1234# -i: identity, 指定私钥文件, 适用于文件名自定义的私钥文件# -p: port, 指定连接 openssh-server 的端口号# -X: 开启 openssh 的 Forwarding X11 图形界面功能ssh -p 22 -i .ssh/id_rsa_xxx zshell.zhang@l-xx1.ops.cn1 scp 命令常用的选项如下:12345# -r: recursive, 传输整个目录下的子文件# -l: limit, 限制传输带宽, 单位是 kb/s# -i: identity, 指定私钥文件# -P: port, 指定端口scp -r zshell.zhang@l-xx1.ops.cn2:/tmp/xxx ~/Downloads 与 openssh-client 相关的命令, 还有一个 sftp, 在本文中不作详细讨论, 本站另一篇文章中单独讨论了 sftp 相关的内容: sftp 相关知识梳理; openssh-client 配置文件openssh-client 的配置文件主要有两方面, 全局配置和个人家目录下的私有配置; 在可配置的内容选项上, 全局配置与私有配置其实没有差别, 只不过习惯上会将一些比较通用的配置放在全局配置里; 全局配置文件openssh 的全局配置文件的路径: /etc/ssh/ssh_config;123456789101112131415161718Host * # 对所有的 host 适用的配置ForwardAgent noForwardX11 no # 允许开启图形界面支持RhostsAuthentication noRhostsRSAAuthentication noRSAAuthentication yesPasswordAuthentication yesFallBackToRsh noUseRsh noBatchMode noCheckHostIP yesStrictHostKeyChecking no# 默认的私钥文件, 按先后顺序依次获取IdentityFile ~/.ssh/identityIdentityFile ~/.ssh/id_rsaPort 22Cipher 3desEscapeChar ~ 私有配置文件openssh 的私有配置文件的路径: $HOME/.ssh/config;12345678910111213141516Host * # 对所有的 host 适用的配置ServerAliveInterval 30ControlPersist yesControlMaster autoControlPath ~/tmp/ssh/master-%r@%h:%pConnectTimeout 30TCPKeepAlive yesStrictHostKeyChecking no# 对所有匹配到 *.cn0 的主机, 均使用以下配置连接Host *.cn0Port 22User zshell.zhang # 使用 zshell.zhang 用户登陆目标主机IdentityFile ~/.ssh/id_rsa # 使用指定的私钥文件ProxyCommand ssh zshell.zhang@l-rtools1. -W %h:%p # 具体的 ssh 命令 站内相关文章 sftp 相关知识梳理 参考链接 ssh配置authorized_keys后仍然需要输入密码的问题","categories":[{"name":"linux","slug":"linux","permalink":"http://zshell.cc/categories/linux/"},{"name":"ssh","slug":"linux/ssh","permalink":"http://zshell.cc/categories/linux/ssh/"}],"tags":[{"name":"linux:ssh","slug":"linux-ssh","permalink":"http://zshell.cc/tags/linux-ssh/"},{"name":"security","slug":"security","permalink":"http://zshell.cc/tags/security/"}]},{"title":"fedora 安装 netease cloud music","slug":"life-pc--fedora_安装_netease-cloud-music","date":"2018-07-11T14:38:12.000Z","updated":"2019-01-22T15:03:20.157Z","comments":true,"path":"2018/07/11/life-pc--fedora_安装_netease-cloud-music/","link":"","permalink":"http://zshell.cc/2018/07/11/life-pc--fedora_安装_netease-cloud-music/","excerpt":"网易是个有情怀的公司, 云音乐客户端推出了 linux 版本, 虽然是个 deb 包, 那也值得尊敬!我现在要做的, 就是把它移植到 fedora 环境中, 以造福更多的 linux 爱好者!","text":"网易是个有情怀的公司, 云音乐客户端推出了 linux 版本, 虽然是个 deb 包, 那也值得尊敬!我现在要做的, 就是把它移植到 fedora 环境中, 以造福更多的 linux 爱好者! 安装思路网上流传着某些 netease-cloud-music 的 rpm 包, 但是经测试发现这些 rpm 包无法正常使用;所以现在一个经测试验证可行的方案是下载官方的 deb 包, 然后提取关键内容手动移到 fedora 上: 无论是 ubuntu 还是 fedora, 都以同样的本质运行 linux 进程, 软件包只是打包方式而已, 不影响程序的执行过程; 提取关键内容以 netease-cloud-music_1.1.0_amd64_ubuntu.deb 为例, 将其解压后得到如下文件:123control.tar.gzdata.tar.xzdebian-binary 其中, data.tar.xz 是核心的内容, 其余的都可以删除; data.tar.xz 是 xz 压缩包, 解压后得到如下目录结构:12345678&gt; xz -d data.tar.xz&gt; tree -L 2 datadata└── usr ├── bin ├── lib └── share 它是对应到 /usr/ 目录的, 所以需要将其全部拷贝到对应目录:1sudo cp -a usr / 至此, netease-cloud-music 的核心内容已经全部提取并放置到正确路径下了; 其余可能还有一些制作 desktop 图标放到 dock 启动器中等小动作, 本文不再详述; 下载关键依赖fedora 安装 netease-cloud-music 所需要的依赖 (安装命令) 列举如下:123456su -c 'dnf install http://download1.rpmfusion.org/free/fedora/rpmfusion-free-release-$(rpm -E %fedora).noarch.rpm http://download1.rpmfusion.org/nonfree/fedora/rpmfusion-nonfree-release-$(rpm -E %fedora).noarch.rpm'sudo dnf install gstreamer1-libav gstreamer1-plugins-ugly gstreamer1-plugins-bad-free gstreamer1-plugins-bad-freeworld gstreamer1-vaapisudo dnf install libmadsudo dnf install vlc # fedora 26 上需要安装, 在我的笔记本上亲测sudo dnf install qt5-qtx11extrassudo dnf install qt5-qtmultimedia &nbsp; 以上便是 fedora 安装 netease-cloud-music 的过程记录, fedora 26 上亲测有效; 参考链接 Fedora 全系列安装网易云音乐","categories":[{"name":"life","slug":"life","permalink":"http://zshell.cc/categories/life/"},{"name":"pc","slug":"life/pc","permalink":"http://zshell.cc/categories/life/pc/"}],"tags":[{"name":"life:pc","slug":"life-pc","permalink":"http://zshell.cc/tags/life-pc/"}]},{"title":"nginx module 使用总结: ngx_http_geo_module","slug":"nginx-module--nginx_module_使用总结_ngx_http_geo_module","date":"2018-05-13T07:45:02.000Z","updated":"2018-05-13T08:05:13.962Z","comments":true,"path":"2018/05/13/nginx-module--nginx_module_使用总结_ngx_http_geo_module/","link":"","permalink":"http://zshell.cc/2018/05/13/nginx-module--nginx_module_使用总结_ngx_http_geo_module/","excerpt":"在处理与 ip 地址相关的 nginx 逻辑上, ngx_http_geo_module 往往能发挥一些有力的作用; 其封装了大量与 ip 地址相关的匹配逻辑, 使得处理问题更加便捷高效;","text":"在处理与 ip 地址相关的 nginx 逻辑上, ngx_http_geo_module 往往能发挥一些有力的作用; 其封装了大量与 ip 地址相关的匹配逻辑, 使得处理问题更加便捷高效; ngx_http_geo_module 最主要的事情是作了一个 ip 地址到其他变量的映射; 一说到映射, 我们便会想起另一个模块: ngx_http_map_module; 从抽象上讲, geo 模块确实像是 map 模块在 ip (geography) 细分领域内的针对性功能实现; geo 模块的安装ngx_http_geo_module 编译默认安装, 无需额外操作; geo 模块的配置geo 模块的配置只能在 nginx.conf 中的 http 指令下, 这与 ngx_http_map_module 模块是一致的:1234567891011static ngx_command_t ngx_http_geo_commands[] = &#123; &#123; ngx_string(\"geo\"), NGX_HTTP_MAIN_CONF|NGX_CONF_BLOCK|NGX_CONF_TAKE12, ngx_http_geo_block, NGX_HTTP_MAIN_CONF_OFFSET, 0, NULL &#125;, ngx_null_command&#125;; geo 模块的配置模式如下:1234geo [$address] $variable &#123; default 0; 127.0.0.1 1;&#125; 其中, \\$address 可选, 默认从 $remote_addr 变量中获取目标 client ip address; 如果使用其他变量作为 ip 地址, 该变量须要是一个合法的 ip 地址, 否则将以 “255.255.255.255” 作为代替;以下是一个典型的 geo 模块配置, \\$address 已缺省默认为 $remote_addr:123456789101112131415161718geo $flag &#123; # 以下是一些设置项 # 定义可信地址, 若 $remote_addr 匹配了其中之一, 将从 request header X-Forwarded-For 获得目标 client ip address proxy 192.168.100.0/24; delete 127.0.0.0/16; # 默认兜底逻辑 default -1; # 定义外部的映射内容 include conf/geo.conf; # 以下是具体的映射内容 # 可以使用 CIDR 匹配 192.168.1.0/24 0; # 精确匹配 10.64.0.5 1;&#125; 除了以上的典型用法之外, geo 模块还有一种地址段范围的匹配模式:1234567geo $flag &#123; # 需放在第一行 ranges; 192.168.1.0-192.168.1.100 0; 192.168.1.100-192.168.1.200 1; 192.168.1.201-192.168.1.255 2;&#125; 参考链接 Module ngx_http_geo_module nginx geo 使用方法","categories":[{"name":"nginx","slug":"nginx","permalink":"http://zshell.cc/categories/nginx/"},{"name":"module","slug":"nginx/module","permalink":"http://zshell.cc/categories/nginx/module/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://zshell.cc/tags/nginx/"},{"name":"nginx:module","slug":"nginx-module","permalink":"http://zshell.cc/tags/nginx-module/"}]},{"title":"chattr / lsattr 使用总结","slug":"linux-disk--chattr_lsattr使用总结","date":"2018-04-06T13:23:22.000Z","updated":"2018-04-07T10:08:56.222Z","comments":true,"path":"2018/04/06/linux-disk--chattr_lsattr使用总结/","link":"","permalink":"http://zshell.cc/2018/04/06/linux-disk--chattr_lsattr使用总结/","excerpt":"对于在机器上操作的人来说, 如果有 sudo 权限, 那 chattr 根本就不是事, 这也不是 chattr 的意义所在;对 chattr 来说, 其所要阻止的, 是那些有意无意想要修改机器上重要文件的程序, 从而保证机器上重要的文件不会因非人为因素而遭到非预期的操作;","text":"对于在机器上操作的人来说, 如果有 sudo 权限, 那 chattr 根本就不是事, 这也不是 chattr 的意义所在;对 chattr 来说, 其所要阻止的, 是那些有意无意想要修改机器上重要文件的程序, 从而保证机器上重要的文件不会因非人为因素而遭到非预期的操作; chattr 命令12345678# + 在原有参数基础上追加设置# - 在原有参数基础上移除设置# = 将设置更改为指定的参数# mode 指定的设置项sudo chattr +|-|=mode file_path# 递归设置指定目录下的所有文件sudo chattr -R +|-|=mode file_path 其中, mode 中常用的设置项如下:123a 设置只能向指定文件中追加内容, 不能删除i 设置文件不能修改, 删除, 不能被设置链接关系, 是最常用的 modes security, 当 rm 该文件时, 从磁盘上彻底删除它; chattr 并非万能, 以下几个目录 chattr 并不能干预:1234//dev/tmp/var lsattr 命令lsattr 命令用于查看文件被 chattr 设置的情况;12&gt; lsattr file_path----i--------e- file_path 可以发现, 有的时候 lsattr 所展示的文件属性掩码中, 有一个 e, 这在 chattr 的 manual 文档里是这么说的: The e attribute indicates that the file is using extents for mapping the blocks on disk. It may not be removed using chattr(1). 所以说, 对 chattr 来说, 这个掩码并不意味着什么; 常用的情景对于生产环境中的机器, 有如下一些重要文件一般会将其用 chattr 设为不可修改, 不可删除:123sudo chattr +i /etc/resolv.confsudo chattr +i /etc/hosts.allowsudo chattr +i /etc/hosts.deny 其中, /etc/hosts.allow 与 /etc/hosts.deny 是关于 ssh 的登陆白名单/黑名单信息, 安全考虑, 正常只允许跳板机 ssh 到本机, 而禁止其他所有的机器; 这两个文件绝不允许被无故修改;而 /etc/resolv.conf 则是关于 dns 解析的文件, 一旦被修改, 会导致一些网络请求中的域名无法正常解析, 所以也需要被 chattr 锁定防止无故修改; 参考链接 Linux的chattr与lsattr命令详解","categories":[{"name":"linux","slug":"linux","permalink":"http://zshell.cc/categories/linux/"},{"name":"disk","slug":"linux/disk","permalink":"http://zshell.cc/categories/linux/disk/"}],"tags":[{"name":"linux:disk","slug":"linux-disk","permalink":"http://zshell.cc/tags/linux-disk/"},{"name":"系统安全","slug":"系统安全","permalink":"http://zshell.cc/tags/系统安全/"}]},{"title":"elasticsearch 6.x 升级调研报告","slug":"elasticsearch--elasticsearch6.x升级调研报告","date":"2018-03-24T14:11:48.000Z","updated":"2018-09-06T12:02:34.803Z","comments":true,"path":"2018/03/24/elasticsearch--elasticsearch6.x升级调研报告/","link":"","permalink":"http://zshell.cc/2018/03/24/elasticsearch--elasticsearch6.x升级调研报告/","excerpt":"关于 elasticsearch, 吐槽最多的就是其前后版本的兼容性问题; 在任何一个上规模的系统体系里, 要将部署在生产环境中的 elasticsearch 提升一个 major 版本是一件非常有挑战性的事情; 为了迎接这一挑战, 作者所在部门专门抽调人力资源作前期调研, 故为此文以记之;在这篇文章中, 我将从 client 端, 索引创建, query dsl, search api, plugins, 监控体系等多方面讨论了从 2.4.2 版本迁移到 6.2.2 版本的一系列可能遇到的兼容性问题及解决方案;希望能给各位读者带来工作上的帮助!","text":"关于 elasticsearch, 吐槽最多的就是其前后版本的兼容性问题; 在任何一个上规模的系统体系里, 要将部署在生产环境中的 elasticsearch 提升一个 major 版本是一件非常有挑战性的事情; 为了迎接这一挑战, 作者所在部门专门抽调人力资源作前期调研, 故为此文以记之;在这篇文章中, 我将从 client 端, 索引创建, query dsl, search api, plugins, 监控体系等多方面讨论了从 2.4.2 版本迁移到 6.2.2 版本的一系列可能遇到的兼容性问题及解决方案;希望能给各位读者带来工作上的帮助! 万字长文, 高能预警! 如只希望了解最终结论, 请点击: #本文总结;&nbsp;戊戌年春, 历时余月, 本文终于迎来了收尾;这篇文章缘起于部门自建 elasticsearch 集群的一个线上故障, 这是我们技术 TL 在 elastic 论坛的提问: ES consume high cpu with threadlocal; 随着业务规模的扩大, 业务数据的积累, 我们意识到当前 2.4.2 版本的 elasticsearch 已经满足不了我们的需求, 此刻亟需升级我们的集群; 比较之后, 我们打算将 6.2.2 版本作为升级的目标, 并着手开始调研; 本文即是该升级调研的一个总结报告;相比于公司内部发表的版本, 本篇博客对所有涉及公司内部的信息作了脱敏处理, 并在开篇第一节补充介绍了一下我们使用 elasticsearch 的方式, 以方便外部读者更好得理解本文的其余部分内容; 客户端兼容性问题在这篇文章的编排结构中, 我将客户端兼容性问题摆在了第一的位置: 因为不管 rest api 如何变化, 或者如何不变, 都只能算是 “术”; 我们真正跑在生产环境中的系统, 使用的是 elasticsearch java client; client 端的基础兼容性问题才是根本之 “道”; 巨轮转向的前提: es-adapter我相信, 搞过 elasticsearch major 版本升级的人都对 elastic 公司深有体会: 从不按牌理出牌, 一个毫不妥协的技术理想主义者, 在其世界里根本没有兼容性这个词; 对于这样的公司做出的产品, 升级必定是一个痛苦的过程;如果请求 elasticsearch 的代码逻辑散落在部门众多业务线的众多系统里, 要推动他们修改代码势必比登天还难: 因为这个过程对他们的 PKI 没有任何帮助, 只会挤占他们的工时, 增加他们的额外负担和 “无效” 工作量, 他们一定不会积极配合, 我们将无法推动进展;还好部门的 VP 有技术远见,在各系统建立之初, 就定下了访问 elasticsearch 的规范: 禁止各系统自己主动连接 elasticsearch, 必须统一由专门的系统代理, 负责语法校验, 行为规范, 请求监控, 以及统一的调优; 其余的系统必须通过调用其暴露出去的 dubbo 接口间接访问 elasticsearch; 这个系统被命名为 es-adapter;当然, es-adapter 系统设计的早期也有一些硬伤, 并直接诱发了一个严重的线上故障: apache httpclient 初始化参数设置总结; 那次事故之后, 甚至有技术 TL 开始怀疑 es-adapter 成为了当前体系的瓶颈, 需要评估有无必要废弃该系统; 但是船大掉头难, 整改谈何容易? 最后还是老老实实完善了 es-adapter 的逻辑继续使用;有的时候 es-adapter 也会做一些语法兼容性的逻辑, 比如之前从 1.7.3 升级到 2.4.2 的时候, 部分 dsl 语法的改动就完全在 es-adapter 上代理了, 对业务线无感知, 轻描淡写地升级了一个 major 版本; 尽管这么做带来了一些技术债务, 但确实为有限时间内的快速升级提供了可能性; 在后面的时间, 业务线可以慢慢地迭代版本, 逐渐适配新 elasticsearch 版本的 api, 偿还债务; 正所谓: 万事之先, 圆方门户; 虽覆能复, 不失其度;不得不说, 当系统规模与复杂度发展到了一个 “船大难掉头” 的程度时, es-adapter 就像是《三体》中描述的 “水滴” 一样, 带领整个体系从一个更高的维度完成 “平滑” 转向; 没有 es-adapter, 升级 elasticsearch 到 6.2.2 就无从谈起; 只不过这次的情形相比上一次有些难看, 没法做到完全透明了, es-adapter 部分特有的逻辑设计在这次升级可能会栽一个跟头, 具体的内容请见下文: #search api 的兼容性; 升级过渡期 client 端的技术选型关于 elasticsearch java 官方客户端, 除了 TransportClient 之外, 最近又新出了一个 HighLevelClient, 而且官方准备在接下来的一两个 major 版本中, 让 HighLevelClient 逐步取代 TransportClient, 官方原话是这样描述的: We plan on deprecating the TransportClient in Elasticsearch 7.0 and removing it completely in 8.0. 所以没有什么好对比的, 我们必须选择 HighLevelClient, 否则没两年 TransportClient 就要被淘汰了; 现在唯一需要考虑的是, 在升级过渡期, 怎么处理 es-adapter 中新 client 和旧 client的关系, 如何同时访问 6.2.2 与 2.4.2 两个集群;值得注意的是, HighLevelClient 是基于 http 的 rest client, 这样一来, 在客户端方面, elasticsearch 将 java, python, php, javascript 等各种语言的底层接口就都统一起来了; 与此同时, 使用 rest api, 还可以屏蔽各版本之前的差异, 之前的 TransportClient 使用 serialized java object, 各版本之前的微小差异便会导致不兼容;要使用 HighLevelClient, 其 maven 坐标需要引到如下三个包:123456789101112131415161718&lt;!-- elasticsearch core --&gt;&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt; &lt;version&gt;6.2.2&lt;/version&gt;&lt;/dependency&gt;&lt;!-- low level rest client --&gt;&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch-rest-client&lt;/artifactId&gt; &lt;version&gt;6.2.2&lt;/version&gt;&lt;/dependency&gt;&lt;!-- high level rest client --&gt;&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt; &lt;version&gt;6.2.2&lt;/version&gt;&lt;/dependency&gt; 后两者没的说, 都是新引入的坐标; 但是第一个坐标, elasticsearch 的核心 package, 就无法避免与现在 es-adapter 引的 2.4.2 版本冲突了;之前从 1.7.3 升 2.4.2 时, 由于 TransportClient 跨 major 版本不兼容, 导致 es-adapter 无法用同一个 TransportClient 访问两个集群, 只能苦苦寻找有没有 rest 的解决方案, 后来总算找到一个: Jest (github 地址: searchbox-io/Jest), 基本囊括了 elasticsearch 各种类别的请求功能;但这还是架不住各业务线种种小众的需求(比如 nested_filter, function_score, aggregations 等等), 以致于对两个不同版本的集群, es-adapter 不能完美提供一致的功能;这一次升 6.2.2, 又遇到了和上一次差不多的问题, 不过一个很大的不同是: 现在官方推荐的 HighLevelClient 是 rest client, 所以很有必要尝试验证下其向下兼容的能力;我们经过 demo 快速测试验证, 初步得出了结论:&nbsp;6.2.2 版本的 RestHighLevelClient 可以兼容 2.4.2 版本的 elasticsearch;&nbsp;这也体现了 elasticsearch 官方要逐步放弃 TransportClient 并推荐 HighLevelClient 的原因: 基于 http 屏蔽底层差异, 最大限度地提升 client 端的兼容性; 后来我在其官方文档中也看到了相关的观点: Compatibility;所以, 本次升级过渡期就不需要像上次 1.7.3 升 2.4.2 那么繁琐, 还要再引入一个第三方的 rest client; 现在唯一需要做的就是直接把 client 升级到 6.2.2, 使用 HighLevelClient 同时访问 2.4.2 和 6.2.2 两个版本; HighLevelClient 的使用注意事项(1) 初始化的重要选项HighLevelClient 底层基于 org.apache.httpcomponents, 一提起这个老牌 http client, 就不得不提起与它相关的几个关键 settings: CONNECTION_REQUEST_TIMEOUT CONNECT_TIMEOUT SOCKET_TIMEOUT MAX_CONN_TOTAL MAX_CONN_PER_ROUTE 不过, HighLevelClient 关于这几个参数的设置有些绕人, 它是通过如下两个回调实现的:123456789101112131415List&lt;HttpHost&gt; httpHosts = Lists.newArrayListWithExpectedSize(serverNum);serverAddressList.forEach((server) -&gt; httpHosts.add(new HttpHost(server.getAddr(), server.getPort(), \"http\")));private RestHighLevelClient highLevelClient = new RestHighLevelClient( RestClient.builder(httpHosts.toArray(new HttpHost[0])) // timeout settings .setRequestConfigCallback((callback) -&gt; callback .setConnectTimeout(CONNECT_TIMEOUT_MILLIS) .setSocketTimeout(SOCKET_TIMEOUT_MILLIS) .setConnectionRequestTimeout(CONNECTION_REQUEST_TIMEOUT_MILLIS)) // connections total and connections per host .setHttpClientConfigCallback((callback) -&gt; callback .setMaxConnPerRoute(MAX_CONN_PER_ROUTE) .setMaxConnTotal(MAX_CONN_TOTAL) )); (2) request timeout 的设置对于 index, update, delete, bulk, query 这几个请求动作, HighLevelClient 与它们相关的 Request 类都提供了 timeout 设置, 都比较方便; 但是, 偏偏 get 与 multiGet 请求没有提供设置 timeout 的地方;这就有点麻烦了, get 与 multiGet 是重要的请求动作, 绝对不能没有 timeout 机制: 之前遇到过的几次惨痛故障, 都无一例外强调了合理设置 timeout 的重要性;那么, 这种就只能自己动手了, 还好 HighLevelClient 对每种请求动作都提供了 async 的 api, 我可以结合 CountDownLatch 的超时机制, 来实现间接的 timeout 控制;首先需要定义一个 response 容器来盛装异步回调里拿到的 result:12345678class ResponseWrapper&lt;T&gt; &#123; private T response; private Exception exception; public T getResponse() &#123; return response; &#125; public void setResponse(T response) &#123; this.response = response; &#125; public Exception getException() &#123; return exception; &#125; public void setException(Exception exception) &#123; this.exception = exception;&#125;&#125; 下面是使用 CountDownLatch 实现 timeout 的 get 请求具体逻辑:1234567891011121314151617181920212223/* get request with timeout */final ResponseWrapper&lt;GetResponse&gt; wrapper = new ResponseWrapper&lt;&gt;();final CountDownLatch latch = new CountDownLatch(1);highLevelClient.getAsync(request, new ActionListener&lt;GetResponse&gt;() &#123; @Override public void onResponse(GetResponse documentFields) &#123; wrapper.setResponse(documentFields); latch.countDown(); &#125; @Override public void onFailure(Exception e) &#123; wrapper.setException(e); wrapper.setResponse(null); latch.countDown(); &#125;&#125;);try &#123; latch.await(getTimeOutTime(indexName, TimeUnit.MILLISECONDS);&#125; catch (InterruptedException e) &#123; throw new ElasticsearchTimeoutException(\"timeout\");&#125;if (wrapper.getResponse() == null) &#123; // 异常处理 &#125; else &#123; 处理 wrapper.getResponse() 的返回结果 &#125; (3) query 请求 dsl 的传参问题es-adapter 之前查询相关的请求动作, 对业务线提供的接口是基于 search api 设计的, 就是下面这样的模型:1234567891011&#123; \"query\": &#123; ... &#125;, \"_source\": &#123; \"include\": [ ... ], \"exclude\": [ ... ] &#125;, \"from\": xxx, \"size\": yyy, \"sort\": [ ... ], \"aggs\": &#123; ... &#125;&#125; 业务线需要提供以上参数给 es-adapter, 而这里面最重要的就是第一个 query 参数, 这里原先设计的是传一个 dsl 字符串; 但是现在我发现 HighLevelClient 的 SearchSourceBuilder 不能直接 set 一个字符串, 而必须是使用各种 QueryBuilder 去构造对应的 Query 对象;这个问题就比较严重了, 如果要改就是牵涉到所有的业务线; 而且即便是想改, 也没那么简单: 这些 QueryBuilders 都没有实现 Serializable 接口, 根本没法被 dubbo 序列化;权衡之下, 感觉还是要努力想办法把 dsl 字符串 set 进去; 我看到 SearchSourceBuilder 有一个方法是 fromXContent(XContentParser parser), 考虑到 dsl 字符串其实都是 json, 可以使用 JsonXContent 将 dsl 反序列化成各种 QueryBuilders; 摸索了一阵子, 验证了以下代码是可行的:123456String dslStr = \"...\";SearchModule searchModule = new SearchModule(Settings.EMPTY, false, Collections.emptyList());XContentParser parser = XContentFactory.xContent(XContentType.JSON).createParser( new NamedXContentRegistry(searchModule.getNamedXContents()), dslStr);SearchSourceBuilder searchSourceBuilder = SearchSourceBuilder.fromXContent(parser); (4) 无厘头的 adjust_pure_negative整个 HighLevelClient 中, 最让人感到费解的一个东西就是一个神秘的属性:123/* org.elasticsearch.index.query.BoolQueryBuilder */private static final ParseField ADJUST_PURE_NEGATIVE = new ParseField(\"adjust_pure_negative\");private boolean adjustPureNegative = ADJUST_PURE_NEGATIVE_DEFAULT; 先是看官方文档, 搜不到;然后搜 google, 就找到这么一个稍微相关一点的帖子: What does “adjust_pure_negative” flag do?, 而其给出的唯一回复是 “You can ignore it“;实在搜不到有效的信息, 我只好去扒源码; 然而, 除了如上所述的 BoolQueryBuilder 中的这坨, 再加上一些测试类, 就再也没在其他地方看到与 adjust_pure_negative 相关的逻辑了;也许真的如 elastic 讨论组中所说的 You can ignore it? 但是现在有一个问题让我无法忽略它: 这个属性无法被 2.4.2 的 elasticsearch 识别, 但在 6.2.2 的 elasticsearch 中, 各个 QueryBuilder 的 toString() 方法会自动将其带上:1234567891011&#123; \"query\": &#123; \"bool\": &#123; \"must\": &#123; ... &#125;, \"should\": &#123; ... &#125;, \"must_not\": &#123; ... &#125;, \"adjust_pure_negative\": true, \"boost\": 1.0 &#125; &#125;&#125; 在上一节中提到, es-adapter 接受业务线传来的 query dsl str, 使用 6.2.2 的 elasticsearch 便会将上述语句传给 es-adapter; 如果其访问的索引已经迁移到 6.2.2 新集群, 那么该语句没问题; 但如果其访问的索引还未来得及迁移到新集群, es-adapter 会将该请求路由到旧的 2.4.2 集群, 接着便会发生语法解析异常;&nbsp;这意味着, 在某个系统所需要访问的所有索引迁移到 6.2.2 新集群之前, 其 maven 依赖的 elasticsearch 版本, 不能提前升级到 6.2.2, 以阻止 adjust_pure_negative 的生成;当然考虑到 major 版本升级所带来的语法规则的巨变已被 es-adapter 缓冲掉了绝大部分, 我相信各业务线也不希望把 elasticsearch 的 maven 版本给直接升上去的; 毕竟那意味着代码将红成一大片, 要花费大量的精力修改代码, 这等于把 es-adapter 原本要替其做的事, 提前自己给办了; (5) 其他小众的需求以上展示的是业务线普遍会遇到的情况, 然后还有两个比较小众的需求, 在个别系统中会使用到, 也是上面所提到的 nested_filter 和 aggregations;关于 nested_filter 还稍顺利些, api 有一些变化但是新的 api 有新的解决方案:123456789// 6.2.2 版本: 构造一个 携带 nested_filter 的 sortprivate SortBuilder buildNestedSort(NestedSort nestedSort) &#123; QueryBuilder termFilter = QueryBuilders.termsQuery(nestedSort.getTermField(), nestedSort.getTermValue()); return SortBuilders.fieldSort(nestedSort.getSortName()) .setNestedSort(new NestedSortBuilder(nestedSort.getNestedPath()).setFilter(termFilter)) .order(nestedSort.getOrder()) .sortMode(SortMode.fromString(nestedSort.getSortMode())) .missing(nestedSort.getMissing());&#125; 只不过这种顺利是建立在之前的不顺利基础上的: org.elasticsearch.search.sort.SortBuilders 没有实现 java.io.Serializable 接口, 各业务线的系统没法通过 dubbo 接口把参数传给我, 所以不得不自定义了上面的 NestedSort 类用于盛装 nested sort filter 的相关参数:123456789public class NestedSort implements Serializable &#123; private String sortName; // 排序用的字段名 private SortOrder order = SortOrder.ASC; private String missing; // _first/_last,如果指定的字段不存在的排序逻辑 private String sortMode; // max/min/sum/avg private String nestedPath; private String termField; // filter对应的 term 的field,现在只支持terms; private Collection&lt;String&gt; termValue;&#125; 好在 nested_filter 相关参数类别可以固化, 比较稳定, 自定义类也算是个解决方案了;&nbsp;但是另一个小众需求就没那么省事了: aggregations; 之前 2.4.2 的 agg api 中, 有一个通用的方法:1234public SearchRequestBuilder setAggregations(byte[] aggregations) &#123; sourceBuilder().aggregations(aggregations); return this;&#125; elasticsearch 聚合的 api 比较丰富自由, 而上面方法中的 aggregations 参数是以字节的形式传过来的, 所以业务线可以自由发挥, 不受 es-adapter 的约束, 但可惜这个方法在 6.2.2 版本中取消了;这样一来不得不回到束缚之中, 针对不同的聚合类型作各自的处理了; 可惜各个聚合类型依然没有实现 java.io.Serializable 接口, 所以还是得自定义类型去盛装参数了; 比如以下是针对分位数的聚合:12345public class PercentileAggregation implements Serializable &#123; private String aggName; private String aggField; private double[] percents;&#125; 1234PercentilesAggregationBuilder percentileAggBuilder = AggregationBuilders.percentiles(param.getPercentileAggregation().getAggName()) .field(param.getPercentileAggregation().getAggField()) .percentiles(param.getPercentileAggregation().getPercents());searchSourceBuilder.aggregation(percentileAggBuilder) 其他的聚合类型不再一一列举; 关于 aggregations 的 api 变化着实比较大, 好在使用它的系统比较少, 推动其修改逻辑阻力亦不是很大;&nbsp;HighLevelClient 的使用基本上要解决的就是以上几个问题了; 解决了客户端的问题, 就是解决了 “道” 的问题, 剩下的 “术” 的问题, 都已不是主要矛盾了; 语法兼容性问题语法兼容性问题便是上文所提及 “术” 的问题的主要表现形式; 这一节主要讨论三个方面: 索引创建的兼容性, query dsl 的兼容性, search api 的兼容性; 索引创建的兼容性es 6.2 在索引创建方面, 有如下几点与 es 2.4 有区别:&nbsp;首先是 settings 中的区别;&nbsp;部分字段不能出现在索引创建语句中了, 只能由 elasticsearch 自动生成;1234567891011121314151617181920212223242526272829\"settings\":&#123; \"index\":&#123; // creation_date 不能出现在索引创建的定义语句里 \"creation_date\": \"1502713848656\", \"number_of_shards\":\"2\", \"analysis\":&#123; \"analyzer\":&#123; \"comma_analyzer\":&#123; \"type\":\"custom\", \"tokenizer\":\"comma_tk\" &#125; &#125;, \"tokenizer\":&#123; \"comma_tk\":&#123; \"pattern\":\",\", \"type\":\"pattern\" &#125; &#125; &#125;, \"number_of_replicas\":\"1\", // uuid 不能出现在索引创建的定义语句里 \"uuid\":\"Oa0tz0x-SpSfuC591_ASIQ\", // version.create, version.update 不能出现在索引创建的定义语句里 \"version\":&#123; \"created\":\"1070399\", \"upgraded\":\"2040299\" &#125; &#125;&#125; 这算是一个规范化, 这些字段原本就不该自己定义, 之前我们是复制的时候图省事, 懒得删掉, 现在不行了;&nbsp;然后是 mappings 中的区别;&nbsp;(1) 布尔类型的取值内容规范化elasticsearch 索引定义的 settings/mappings 里有很多属性是布尔类型的开关; 在 6.x 之前的版本, elasticsearch 对布尔类型的取值内容限制很宽松: true, false, on, off, yes, no, 0, 1 都可以接受, 产生了一些混乱, 对初学者造成了困扰:1234567891011121314151617181920212223242526272829// elasticsearch 2.4.2// xxx_idx/_mapping/field/xxx_field&#123; \"xxx_idx\":&#123; \"mappings\":&#123; \"xxx_type\":&#123; \"xxx_field\":&#123; \"full_name\":\"xxx_field\", \"mapping\":&#123; \"xxx_field\":&#123; \"type\":\"string\", \"index_name\":\"xxx_field\", // 以下属性都有布尔类型的含义, 但取值五花八门, 容易造成歧义 \"index\":\"not_analyzed\", \"store\":false, \"doc_values\":false, \"term_vector\":\"no\", \"norms\":&#123; \"enabled\":false &#125;, \"null_value\":null, \"include_in_all\":false &#125; &#125; &#125; &#125; &#125; &#125;&#125; 从 6.x 版本开始, 所有的布尔类型的属性 elasticsearch 只接受两个值: true 或 false;从当前 2.4.2 集群的使用状况来看, 这个改动对我们的影响不是特别大, 因为我们在定义索引创建 DSL 语句时, 很多布尔类型的选项都是用的默认值, 并未显式定义, 只有 index 属性可能会经常用到; (2) _timestamp 字段被废弃这个改变对我们的影响不是很大, 我们现在绝大部分索引都会自己定义 createTime / updateTime 字段, 用于记录该文档的创建 / 更新时间, 几乎不依赖系统自带的 _timestamp 字段;&nbsp;况且, _timestamp 字段在 2.4.2 版本时, 就已经默认不自动创建了, 要想添加 _timestamp 字段, 必须这样定义:123\"_timestamp\": &#123; \"enabled\": true&#125; 当然, 在 6.2.2 版本中, 以上定义就直接报 unsupported parameter 错误了; (3) _all 字段被 deprecated, include_in_all 属性被废弃在 elasticsearch 6.x, _all 字段被 deprecated 了, 与此同时, _all 字段的 enabled 属性默认值也由 true 改为了 false;之前, 为了阻止 _all 字段生效, 我们都会不遗余力得在每个索引创建语句中加上如下内容:123\"_all\": &#123; \"enabled\": false&#125; 从 6.0 版本开始, 这些语句就不需要再出现了, 出现了反而会导致 elasticsearch 打印 WARN 级别的日志, 告诉我们 _all 字段已经被 deprecated, 不要再对其作配置了;与 _all 密切相关的属性是 include_in_all, 在 6.0 版本之前, 这个属性值默认也是 true; 不过不像 _all 的过渡那么温和, 从 6.0 开始, 我在 elasticsearch reference 官方文档里就找不到这个属性的介绍了, 直接被废弃; 而在其上一个版本 5.6 中, 我还能看到它, 也没有被 deprecated, 着实有些突然;elasticsearch 放弃 _all 这个概念, 是希望让 query_string 时能够更加灵活, 其给出的替代者是 copy_to 属性:12345678910111213\"properties\": &#123; \"first_name\": &#123; \"type\": \"text\", \"copy_to\": \"full_name\" &#125;, \"last_name\": &#123; \"type\": \"text\", \"copy_to\": \"full_name\" &#125;, \"full_name\": &#123; \"type\": \"text\" &#125;&#125; 这样, 把哪些字段 merge 到一起, merge 到哪个字段里, 都是可以自定义的, 而不用束缚在固定的 _all 字段里;&nbsp;无论如何, _all 与 include_in_all 的废弃对我们来说影响都是很小的, 首先我们就很少有全文检索的场景, 其次我们也没有使用 query_string 查询 merged fields 的需求, 甚至将 _all 禁用已被列入了我们索引创建的规范之中; (4) 史诗级大改变: string 类型被废弃string 类型被废弃, 代替者是分词的 text 类型和不分词的 keyword 类型;当前正在使用的 2.4.2 版本的集群里, string 类型大概是被使用最多的类型了; 保守估计, 一个普通的索引里, 60% 以上的字段类型都是 string; 现在 6.x 把这个类型废弃了, 就意味着几乎所有索引里的大多数字段都要修改;&nbsp;不过好在, 这种修改也只是停留在 index 的 schema 映射层面, 对 store 于底层的 document 而言是完全透明的, 所有原始数据都不需要有任何修改;&nbsp;经过搜索发现, 其实早在 elasticsearch 5.0 时, string 类型就已经被 deprecated 了, 然后在 6.1 时被彻底废弃, 详细的 changelog 见官方文档: Changelog;仔细一想, 这个改变是有道理的: elasticsearch 想要结束掉目前混乱的概念定义;比如说, 在 5.0 之前的版本, 一个字符串类型的字段, 是这样定义的:1234567891011\"xxx\": &#123; \"type\": \"string\", \"index\": \"not_analyzed\" // 不需要分词, 但要索引&#125;,\"yyy\": &#123; \"type\": \"string\", \"index\": \"no\" // 不需要分词, 也不需要索引&#125;,\"zzz\": &#123; \"type\": \"string\" // 默认情况, 需要索引, 也需要分词&#125; index 的原本含义是定义是否需要索引, 是一个布尔概念; 但由于字符串类型的特殊性, 索引的同时还需要再区分是否需要分词, 结果 index 属性被设计为允许设置成 not_analyzed, analyzed, no 这样的内容; 然后其他诸如数值类型, 亦被其拖累, index 属性的取值也需要在 not_analyzed, no 中作出选择; 不得不说这非常混乱;要把这块逻辑理清楚, 第一个选择是再引入一个控制分词的开关 word_split, 只允许字符串类型使用, 第二种选择就是把字符串类型拆分成 text 和 keyword;至于 elasticsearch 为何选择了第二种方案, 我猜主要还是默认值不好确定; 对初学者而言, 一般都习惯于使用默认值, 但是究竟默认要不要分词? 以 elasticsearch 的宗旨和初衷来看, 要分词, search every where; 但是以实际使用者的情况来看, 很多的场景下都不需要分词; 如果是把类型拆分, 那么就得在 text 和 keyword 中二选一, 不存在默认值, 使用者自然会去思考自己真正的需求;现在逻辑理清楚了, index 的取值类型, 也就如上一节所说的, 必须要在 true 或 false 中选择, 非常清晰; (5) mapping 中取消 multi types从 elasticsearch 6.1 开始, 同一个 index(mapping) 下不允许创建多个 type, index 与 type 必须一一对应; 从下一个 major 版本开始, elasticsearch 将废弃 type 的概念, 详见官方文档: Removal of mapping types;由于底层 Lucene 的限制, 同一个 index 下的不同 type 中的同名的字段, 其背后是共享的同一个 lucene segment; 这就意味着, 同一个 index 下不同 type 中的同名字段, 类型定义也必须相同; 原文如下: In an Elasticsearch index, fields that have the same name in different mapping types are backed by the same Lucene field internally; In other words, both fields must have the same mapping (definition) in both types. &nbsp;这个改变对我们是有些影响的, 我们有小一部分的索引都存在 multi types 的问题, 这就意味着需要新建索引来承接多出来的 type, 这些索引的使用者必须要修改代码, 使用新的索引名访问不同的 type; query dsl 的兼容性索引创建的兼容性调研只能算是一个热身, 按照以往经验, elasticsearch 一旦有 major 版本升级, query dsl 变动都不会小, 这次也不例外; (1) filtered query 被废弃其实早在 2.0 版本时, filtered query 就已经被 deprecated 了, 5.0 就彻底废弃了; 这的确是一个不太优雅的设计, 在本来就很复杂的 query dsl 中又增添了一个绕人的概念;filtered query 原本的设计初衷是想在一个 query context 中引入一个 filter context 作前置过滤: Exclude as many document as you can with a filter, then query just the documents that remain. 然而, filtered query 这样的命名方式, 让人怎么也联系不了上面的描述; 其实要实现上述功能, elasticsearch 有另一个更加清晰的语法: bool query, 详细的内容在接下来的第 (2) 小节介绍;&nbsp;从目前 es-adapter 的使用情况来看, 依然有请求会使用到 filtered query; 好在 filtered 关键字一般出现在 dsl 的最外层, 比较固定, 这块可以在 es-adapter 中代理修改:1234567891011121314&#123; // 在 es-adapter 中删除 filtered \"filtered\": &#123; // 如果有 filter, 将其移动到 query -&gt; bool 中 \"filter\": &#123; ... &#125;, \"query\": &#123; \"bool\": &#123; \"must\": &#123; ... &#125;, \"should\": &#123; ... &#125;, \"must_not\": &#123; ... &#125; &#125; &#125; &#125;&#125; (2) filter context 被限定在 bool query 中使用如下所示, 以下 dsl 是 elasticsearch 6.x 中能够使用 filter context 的唯一方式, 用于取代第 (1) 小节所说的 filtered query:123456789101112&#123; \"query\": &#123; \"bool\": &#123; // 引入 filter context 作前置过滤 \"filter\": &#123; ... &#125;, \"must\": &#123; ... &#125;, \"should\": &#123; ... &#125;, \"must_not\": &#123; ... &#125; &#125; &#125;&#125; &nbsp;由于这个规范只是一个限定, 而不是废弃, 所以对目前生产环境肯定是没有影响, 只是需要各业务线慢慢将使用方式改成这种规范, 否则以后也会带来隐患; (3) and/or/not query 被废弃与 filtered query 不同, and query, or query, not query 这三个是语义清晰, 见名知意的 query dsl, 但是依然被 elasticsearch 废弃了, 所有 and, or, not 逻辑, 现在只能使用 bool query 去实现, 如第 (2) 小节所示;可以发现, elasticsearch 以前为了语法的灵活丰富, 定义了各种各样的关键字; 要实现同一个语义的查询, 可以使用几种不同的 query dsl; 很多时候, 这样导致的结果, 就是让新人感到眼花缭乱, 打击了学习热情;现在 and query, or query, not query 被废弃, 干掉了冗余的设计, 精简了 query dsl 的体系, 不得不说这是一件好事;但从另一个角度讲, 每逢 major 版本升级就来一次大动作, 破坏了前后版本的兼容性, 让使用者很头疼; 想想 java 为了兼容性到现在都还不支持真正的泛型, 要是换 elastic 公司来操作, 估计 JDK 1.6 就准备放弃兼容了;&nbsp;从 es-adapter 的使用情况来看, 目前业务线基本没有 and/or/not query 的使用, 相关逻辑大家都使用的 bool query, 所以这一点对我们影响有限; (4) missing query 被废弃要实现 missing 语义的 query, 现在必须统一使用 must_not exists:123456789101112GET /_search&#123; \"query\": &#123; \"bool\": &#123; \"must_not\": &#123; \"exists\": &#123; \"field\": \"xxx\" &#125; &#125; &#125; &#125;&#125; 这也算是对 query dsl 体系的精简化: 可以用 exists query 实现的功能, 就不再支持冗余的语法了;&nbsp;这个改动对我们是有一定影响的, 目前不少的 query 都还在使用 missing;另外, 由于从 missing 改为 must_not exists 结构变化大, 而且 missing 的使用比较灵活, 在 dsl 中出现的位置不固定, 这两个因素叠加, 导致在 es-adapter 中代理修改的难度非常高, 基本不可行;所以, 关于 missing , 必须由业务线自己来修改相关代码了; search api 的兼容性相比于 query dsl 的巨大改变, search api 总体上延续了之前的设计, 仅有部分 search type 被废弃; 感觉上比较温和, 可惜却因为 es-adapter 一些没有前瞻性的设计而闪着了腰; (1) search_type scan 被废弃关于这一点, 我们早就作好了心理准备; 早在从 1.7.3 升 2.4.2 的时候, 我们就已经发现 scan 这种 search type 被 deprecated 了, 从 5.0 开始, 就要被彻底废弃了, 所以 es-adapter 同期开始支持真正的 scroll 请求 (可惜业务线使用得不多);从类别上说, scan 只不过是 scroll 操作中的一种特例: 不作 sort, fetch 后不作 merge; 从执行效果上看, scan 相比 scroll 可能稍微快一些, 并会获得 shards_num * target_size 数量的结果集大小; 除此之外, 没有其他什么区别;&nbsp;然而, 理论上很简单, 实际上却很棘手: 这源于 es-adapter 一个比较糟糕的设计:12345678910/* es-adapter 的查询服务 */public ResponseContent query(RequestParam param) &#123; if (param.getSearchType().equals(SearchType.SCAN) || param.getUseScroll()) &#123; return scroll(param); &#125; else if (param.getSearchType().equals(SearchType.COUNT)) &#123; return count(param); &#125; else &#123; return normallyQuery(param); &#125;&#125; 可以发现, 在当前的逻辑中, 业务线的 scan 请求, 是通过调用 query 方法并设置 search type 为 scan 来实现的; 这里的 scroll(param) 方法是个 private 方法; 当 es-adapter 升级 api 到 6.2.2 后, 就识别不了 scan 了;这就要求 es-adapter 修改 scroll(param) 方法为 public, 然后各业务线直接调 scroll(param) 方法; 这需要一定的修改工作量; (2) search_type count 被废弃count 与 scan 一样早在 2.4.2 时就已经被 deprecated 了, 不过之前我们对 count 的关注度没有 scan 高; 在 2.4.2 版本 SearchType 类的源码注释中, elastic 官方是这么说明的:123456/** * Only counts the results, will still execute aggregations and the like. * @deprecated does not any improvements compared to &#123;@link #QUERY_THEN_FETCH&#125; with a `size` of &#123;@code 0&#125; */@DeprecatedCOUNT((byte) 5); 对于 es-adapter 来说, 修改方法很明显, 正如注释中所述: 该怎么请求就怎么请求, 拿到 response 后从里面取出 totalHits 就行了;&nbsp;可惜, 如上一节所述, 同样由于 es-adapter 中糟糕的逻辑, 业务线需要通过调用 query 方法并设置 search type 为 count 来实现 count 请求; 现在没有 count 这个 search type 了, 需要业务线改成直接调用 count(param) 方法; (3) search_type query_and_fetch 被 deprecated, dfs_query_and_fetch 被废弃这两个 search type 被 deprecated 的时间比 scan 和 count 稍晚一些; 好在这两个 search type 比较冷门, 业务线知道的不多, 所以用的也不多; 后来只要发现有人这么用, 我们就会告诉他们这个 api 已经不推荐了;&nbsp;所以, 相比 scan 和 count, query_and_fetch 和 dfs_query_and_fetch 被废弃的影响十分有限; 底层索引数据兼容性问题根据官方文档, 6.x 版本可以兼容访问 5.x 创建的索引; 5.x 版本可以兼容 2.x 创建的索引;背后其实是 lucene 版本的兼容性问题, 目前我们 2.4.2 版本的集群使用的 lucene 版本是 5.5.2, 而 6.2.2 版本的 elasticsearch 使用的 lucene 版本是 7.2.1; 由于主机资源有限, 没办法再弄出一组机器来搭建新集群, 我首先想到的是: 能否以 5.x 作跳板, 先原地升级到 5.x, 再从 5.x 升到 6.x;但是看了官方文档, 这个想法是不可行的: Reindex before upgrading; elasticsearch 只认索引是在哪个版本的集群中创建的, 并不关心这个索引现在在哪个集群; 一个索引在 2.4.2 集群中创建, 现在运行在 5.x 版本的 elasticsearch 中, 这时候将 5.x 的集群升级到 6.x, 该索引是无法在 6.x 中访问的; 其次我想到的是使用 hdfs snapshot / restore 插件来升级索引; 这种方式曾在之前 1.7.3 升级 2.4.2 版本时大量使用, 总体来说速度比普通的 scroll / index 全量同步要快很多; 但是看了官方文档, 发现这个想法也是不可行的, (文档链接: Snapshot And Restore): A snapshot of an index created in 5.x can be restored to 6.x.A snapshot of an index created in 2.x can be restored to 5.x.A snapshot of an index created in 1.x can be restored to 2.x. 接着我又想到了 elasticsearch 自带的 reindex 模块; reindex 模块也是官方文档推荐的从 5.x 升 6.x 时的索引升级方法; 经过 beta 测试, 我发现这个方法基本可行, 速度也尚可, 唯一需要注意的就是在 elasticsearch.yml 配置文件中要加上一段配置: reindex.remote.whitelist: oldhost:port 以允许连接远程主机作 reindex;以下是 _reindex api 的使用方法: 1234567891011121314151617POST _reindex&#123; \"source\": &#123; \"remote\": &#123; \"host\": \"http://oldhost:9273\" &#125;, \"index\": \"source_idx\", \"type\": \"source_type\", \"query\": &#123; \"match_all\": &#123;&#125; &#125; &#125;, \"dest\": &#123; \"index\": \"dest_idx\", \"type\": \"dest_type\" &#125;&#125; 除了 reindex 模块之外, 其实还有一种更保守的方法, 就是用基于 es-spark 的索引迁移工具来完成迁移, 这也是之前经常使用的工具; 工具兼容性问题http 访问工具兼容性目前我们经常使用的基于 http 的访问工具主要是 elasticsearch-head 和 cerebro;关于 http 请求, elasticsearch 6.2.2 也有一个重大的改变: Strict Content-Type Checking for Elasticsearch REST Requests;现在所有带 body 的请求都必须要加上 Content-Type 头, 否则会被拒绝; 我们目前正在使用的 elasticsearch-head:2 和 cerebro v0.6.1 肯定是不支持这点的, head 是所有针对数据的 CRUD 请求使用不了, cerebro 甚至连接机器都会失败;&nbsp;目前, cerebro 在 github 上已经发布了最新支持 elasticsearch 6.x 的 docker 版本: yannart/docker-cerebro; 经过部署测试, 完全兼容 elasticsearch 6.2.2;不过, elasticsearch-head 就没那么积极了, 目前最近的一次 commit 发生在半年之前, 那个时候 elasticsearch 的最新版本还是 v 5.5;&nbsp;没有 elasticsearch-head 肯定是不行的, 这个时候就只能自己动手了;首先, 肯定是希望从源码入手, 看能不能改一改, 毕竟只是加一个 Content-Type, 并不需要动大手术; 只可惜, 我 clone 下了 elasticsearch-head 的源码, 发现这个纯 javascript 的工程, 复杂度远远超出我的想象, 早已不是一个非前端工程师所能驾驭的了的; 我全局搜索了一些疑似 post 请求的逻辑, 但终究也没把握这些是不是真正要改的地方; 思来忖去, 只得作罢;然后, 我开始思考能否通过间接的方式解决问题; 我注意到一个现象, 凡是带 body 的请求, body 必定是一个 json, 无论是 POST 还是 PUT; 那就是说, 如果必须要指定 Content-Type 的时候, 那就指定为 application/json 就 OK 了; 与此同时, 如果是一个不带 body 的 GET 请求, 携带上该 header 理论上也不会造成额外影响;如果这个假设成立, 那我只需要对所有 elasticsearch-head 发起的请求挂一层代理, 全部转到 nginx 上去, 并统一加上个 header:123456789101112131415server &#123; listen 80; server_name esxxx.xxx.com; location / &#123; proxy_pass http://xxx.yyy.com; proxy_set_header X-Real-Scheme $scheme; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # 统一加上 application/json 的 Content-Type proxy_set_header Content-Type application/json; &#125;&#125; 测试环境下的实验验证了这个方案是完全可行的, 原本正常访问的请求以及原本不能正常访问的请求, 现在都没有任何问题了;其实, 这个方案相比之前还是有自己的好处的: 它隐藏了真正的 elasticsearch 节点地址与端口号, 只对业务线暴露了一个代理 url, 从而更加灵活与可控; 插件兼容性笼统上讲, cerebro 与 elasticsearch-head 也是插件, 只不过它们是独立部署的, 所以被划归到 http 访问工具的类别中了; 而这一小节要讲的, 则是真正的需要依赖于具体的 elasticsearch 节点的插件;(1) elasticfence这个插件追踪溯源的话是这个项目: elasticfence; 后来由于各种各样的需求, 我们在这个插件的基础之上, 作了大量的修改; 到目前为止, 跑在我们节点上的该插件代码已经与 github 上的原项目代码没有半毛钱关系了;当前我们版本的 elasticfence 最大的功能是整合了 qconfig, 使得其拥有热配置及时生效的能力; 然而, 也正是这个功能, 成了该插件本次兼容 elasticsearch 6.x 的噩梦;首先第一道困难是, 2.4 与 6.2 版本的插件 api 彻底大改变; 但这与接下来的困难相比, 也只不过是热个身而已;当我把 pom.xml 中的 elasticsearch 版本从 2.4.2 改成 6.2.2 时, 意料之中地发现代码红了一片, 不过仔细一看, 发现 api 变化的尺度之大, 还是超出了我的预计: RestFilter 接口直接被干掉了;123456789101112/** * A filter allowing to filter rest operations. */public abstract class RestFilter implements Closeable &#123; public int order() &#123;return 0;&#125; @Override public void close() &#123;&#125; /** * Process the rest request. Using the channel to send a response, or the filter chain to continue processing the request. */ public abstract void process(RestRequest request, RestChannel channel, RestFilterChain filterChain) throws Exception;&#125; 原本在 2.4.2 版本中, RestFilter 是该插件的核心组件, 所有的请求都经过该过滤器, 由其中的逻辑判断是否具有访问权限; 现在该类被干掉, 我又搜不到其他类似 filter 的代替者, 这就没法操作了;经过一段时间的努力, 我终于在 google 和 github 的帮助下找到了解决该问题的线索, 6.2 版本其实是提供了一个类似的 api 的:123456789// public interface ActionPlugin/** * Returns a function used to wrap each rest request before handling the request. * Note: Only one installed plugin may implement a rest wrapper. */default UnaryOperator&lt;RestHandler&gt; getRestHandlerWrapper(ThreadContext threadContext) &#123; return null;&#125; 让插件的 main class 继承此接口, 使用 lambda 表达式十分简洁地解决问题:123456789101112// public class ElasticfencePlugin extends Plugin implements ActionPlugin@Overridepublic UnaryOperator&lt;RestHandler&gt; getRestHandlerWrapper(ThreadContext threadContext) &#123; if (isPluginDisabled()) &#123; // 透传请求 return (originRestHandler) -&gt; authRestFilter.wrapNone(originRestHandler); &#125; else &#123; // 权限控制 return (originRestHandler) -&gt; authRestFilter.wrap(originRestHandler); &#125;&#125; 本以为搞定了 api 就万事大吉了, 然后就遇到了第二道困难: java security manager;换句话说, 就是基于安全考虑, 默认情况下不允许插件往任何磁盘路径写入东西, 大部分磁盘路径的内容不允许读取, 不允许发起 http 请求或 socket 连接, 不允许使用反射或者 Unsafe 类; 还有其他无数的动作限制…… 要想使用, 就必须申请权限!当前版本的 elasticfence 由于使用了 qconfig, 所以首先需要引入公司的 common 客户端以初始化标准 web 应用, 期间需要申请磁盘路径读写权限以及一些系统变量的读写权限; qconfig-client 本身也有定时任务发起 http 请求, 所以还需要申请 http 资源的请求权限;然而实际上, 申请权限却不是那么顺利: 我按照官方文档 Help for plugin authors 的步骤申请了对应的权限, 重启节点, 发现无济于事: 该被禁止的依然被禁止; 我对 java security manager 的机制不熟悉, google 求助但所获甚少, 按正常的思路似乎遇到了阻碍;&nbsp;根据官方的描述, 从 6.x 开始, security manager 已无法被 disable, 要想在当前版本里 run 起来, 安全机制就是绕不开的问题; 听起来似乎已经绝了, 遂内心生发出一个狠想法: 去改 elasticsearch 源码, 把 security manager 相关代码全部注释掉, 然后重新编译, 堂而皇之, 若无其事!想了下我们确实没有代码行为方面的安全需求, 这个 security manager 对我们而言其实是可有可无, 现在它阻碍了其他对我们很有必要的东西, 那么它就是可无的;不过 elasticsearch 可不是一般的 java 项目, 其体系之复杂, 依赖之错综, 让人望而生畏; 小心翼翼得 pull 下来最新的代码, checkout 到目标 tag v6.2.2, 然后傻了: gradle 下载不了任何依赖, 代码全是红色的一片;在网上搜了一阵子, 按部就班地操作, 还算顺利, 总算在 Intellij IDEA 里将项目正常加载起来了; 不得不感叹, 关于 elasticsearch 6.x, 即便是本地 IDE 的环境问题, 也值得写一篇文章好好总结一下;源码中与 java security manager 相关的代码主要有以下几个地方:首先是 elasticsearch 的主方法( elasticsearch 启动后执行的第一个逻辑便是设置 security manager):12345678910111213141516171819// org.elasticsearch.bootstrap.Elasticsearchpublic static void main(final String[] args) throws Exception &#123; // we want the JVM to think there is a security manager installed so that if internal policy // decisions that would be based on the presence of a security manager // or lack thereof act as if there is a security manager present (e.g., DNS cache policy) System.setSecurityManager(new SecurityManager() &#123; @Override public void checkPermission(Permission perm) &#123; // grant all permissions so that we can later set the security manager to the one that we want &#125; &#125;); LogConfigurator.registerErrorListener(); final Elasticsearch elasticsearch = new Elasticsearch(); int status = main(args, elasticsearch, Terminal.DEFAULT); if (status != ExitCodes.OK) &#123; exit(status); &#125;&#125; 接着是 Bootstrap 类:123456789101112// org.elasticsearch.bootstrap.Bootstrapprivate void setup(boolean addShutdownHook, Environment environment) throws BootstrapException &#123; ...... // install SM after natives, shutdown hooks, etc. try &#123; Security.configure(environment, BootstrapSettings.SECURITY_FILTER_BAD_DEFAULTS_SETTING.get(settings)); &#125; catch (IOException | NoSuchAlgorithmException e) &#123; throw new BootstrapException(e); &#125; ......&#125; 最后是 BootstrapChecks 类:1234567891011121314151617181920212223242526272829// org.elasticsearch.bootstrap.BootstrapChecks// the list of checks to executestatic List&lt;BootstrapCheck&gt; checks() &#123; final List&lt;BootstrapCheck&gt; checks = new ArrayList&lt;&gt;(); ...... checks.add(new AllPermissionCheck()); return Collections.unmodifiableList(checks);&#125;static class AllPermissionCheck implements BootstrapCheck &#123; @Override public final BootstrapCheckResult check(BootstrapContext context) &#123; if (isAllPermissionGranted()) &#123; return BootstrapCheck.BootstrapCheckResult.failure(\"granting the all permission effectively disables security\"); &#125; return BootstrapCheckResult.success(); &#125; boolean isAllPermissionGranted() &#123; final SecurityManager sm = System.getSecurityManager(); assert sm != null; try &#123; sm.checkPermission(new AllPermission()); &#125; catch (final SecurityException e) &#123; return false; &#125; return true; &#125;&#125; 与 java security manager 相关的代码就在以上三个类中了; 可以发现它们都在 org.elasticsearch.bootstrap 包中;重新编译后, 使用新处理过的 elasticsearch, 重启节点, 加载插件, 完美启动; 尽管这个问题暂时解决了, 但总是 “不太光彩”; 如果有人知道如何通过常规方法解决 security manager 的问题, 还请不吝赐教; (2) elasticsearch-analysis-ik这个插件没的说, 作为唯一一个在 elastic 公司任职的中国人, medcl 一定会在新版本发布第一时间更新 elasticsearch-analysis-ik, 与公司共进退;安装了最新的 6.2.2 版本的 elasticsearch-analysis-ik, 重启节点, 加载插件, 完美运行; (3) 其余插件在 2.4.2 中, 还有两个使用到的插件, marvel 和 licence; 在 6.x 中, 这些插件已经被 x-pack 取代了, 下一节将会介绍, 此处不再赘述; 监控体系基于 rest api + graphite + grafana 的方案基于 elasticsearch 的 rest api, 我们可以使用脚本定时收集到集群内各种状态的指标; 使用 graphite 收集 elasticsearch 汇报的指标, 并以 grafana 作为前端展示; 使用以上开源框架自建的监控系统, 已经成为我们监控 elasticsearch 集群健康状况的主力工具 (这篇文章详细介绍了 elasticsearch 各种 rest api 收集到的指标以及将其可视化的方法: 使用 rest api 可视化监控 elasticsearch 集群);将收集指标的脚本部署到 elasticsearch 6.x 测试节点, 发现 rest api 有了一些变化;首先是 rest api 调用的参数的细微变化:123# 2.4.2 的 _stats api 可以加一个不痛不痒的 all 参数_nodes/stats?all=true_stats?all=true all 参数在 6.x 中已经不支持了, 不过这是个不痛不痒的参数, 加与不加对结果的输出似没有任何影响;其余的 api 在调用的路径和参数上都没有什么变化, 比较顺利;然后是调用 api 返回的内容有一些细微的变化:123456# 2.4.2 的 load 指标$node_name.os.load_avergae# 6.2.2 的 load 指标$node_name.os.cpu.load_average.1m$node_name.os.cpu.load_average.5m$node_name.os.cpu.load_average.15m 6.2.2 的机器 load 指标收集, 随系统细分为了 1min, 5min 和 15min 三种, 也算是更精致了; elastic 官方组件 x-pack在 x-pack 诞生之前, elastic 官方提供了如下几个辅助工具: kibana, shield, marvel, watcher, 分别用于数据可视化, 权限控制, 性能监控和系统报警; 功能很强大, 可惜除了基础功能外, 进阶功能都要收费;从 elasticsearch 5.0 开始, 这些独立的工具被 elastic 公司打成了一个包: x-pack, 同时在原有的基础之上, 又进一步提供了机器学习, 可视化性能诊断 (visual search profiler) 等其他特性, 并以 kibana 为呈现这些功能的载体; 只不过, 收费的功能还是一个都没少: x-pack-fee-table 对我们来说, 之前我们主要使用到的是 marvel, 用于观察索引分片转移的源目节点与复制进度 (shard activity), 偶尔也会用于辅助自建的监控系统, 观察一些请求的 qps 和 latency;我分别在 elasticsearch node 与 kibana 上安装了 x-pack 套件, 剔除了需要付费的 security, watcher, ml, graph 模块;可以看到, monitoring 部分相比以前的 marvel, 总体结构上没有太大变化: x-pack-monitor 另外, 在 x-pack 免费的功能里, 还有一个比较实用的工具: dev-tools; 这里面有两个子栏目: search profiler 和 grok debugger; 其中, search profiler 在之前的 search api 基础上实现了可视化的诊断, 相比之前在 response json 字符串里面分析查询性能瓶颈, 这样的工具带来了巨大的直观性: x-pack-search-profiler 除了以上免费功能, kibana 本身还有最基础的 Discover 和 Visualize 数据可视化功能, 只不过各业务线都习惯于使用 head 工具来访问线上数据, 并且 kibana 的该部分功能较之以前无显著变化, 此处便不再详述;以上便是 elasticsearch 6.x 下 x-pack 最常见的使用情况; 本文总结本文主要讨论当前生产环境下从 elasticsearch 2.4.2 升级到 6.2.2 的可行性与兼容性问题;首先是客户端兼容性问题:elastic 公司新推出的 RestHighLevelClient 从 http 层面最大限度得屏蔽了各版本间的差异, 使得跨版本调用成为了可能; 使用 6.2.2 的 RestHighLevelClient 可以正常访问 2.4.2 的集群, 这为集群升级带来了便利; 对各业务线而言, 只有有限的 (诸如 aggregations) api 被迫需要修改, 其余的都可以延续下去;其次是语法兼容性问题:此处仍需细分为三个方面: create index, query dsl 和 search api ;create index 方面, 其他的零碎变化都显得不痛不痒, 对我们的影响微乎其微, 唯一一个显著的大改变就是废弃了 string 类型, 改而细分出两个司职更明确的类型: text 与 keyword, 分别对应于分词和不分词的情形; 这个大改变需要我们对现有所有的索引作一次大整改;query dsl 方面, 对我们的影响也在控制范围之内: 只有 missing 语句被废弃需要业务线作一定的修改, 其他的大多可以由 es-adapter 代理兼容;search api 方面, 可能影响就比较大了: scan 和 count 两种 search type 被废弃, 并在 es-adapter 糟糕的设计之下, 影响被放大, 需要麻烦各业务线配合修改;然后是索引数据迁移兼容性问题:经过多方测试, 发现只有两种方法可以在我们这种跨两个 major 版本的情况下迁移索引数据: reindex 模块和 es-spark 工具; 好在这两种方法 (由其是后者) 之前就是我们主要的索引迁移工具;接着是工具兼容性问题:经过不断探索与变通, 最后 cerebro, elasticsearch-head, elasticfence, elasticsearch-analysis-ik, curator 等一系列原有生产环境下的 elasticsearch 工具 (插件) 都 “顺利” 实现了对 6.2.2 版本的兼容;这其中, elasticfence 实现兼容的过程比较坎坷, 甚至还重新编译了 elasticsearch 的源码才解决了 security manager 的问题; 如果以后能通过常规方式解决安全的问题, 一定还得弄回去;最后是监控体系兼容性问题:得益于 6.x 版本 rest api 对先前的延续 (除了极个别 api 有细微调整之外), 之前生产环境使用的基于一系列开源方案的自建监控系统, 在 6.x 下依然做到了正常运转;另外, 从 5.0 开始横空出世的 x-pack, 也在本次调研中被部署测试; 其中 monitoring, search-profiler 等功能都展示出了其实用的价值; &nbsp;以上便是本文的全部内容; 站内相关文章 apache httpclient 初始化参数设置总结 使用 rest api 可视化监控 elasticsearch 集群 参考链接 Changelog Removal of mapping types Strict Content-Type Checking for Elasticsearch REST Requests Compatibility State of the official Elasticsearch Java clients Elasticsearch 6 新特性与重要变更解读 Help for plugin authors Intellij Idea 编译 Elasticsearch 源码 elasticsearch: Building from Source Sequence IDs: Coming Soon to an Elasticsearch Cluster Near You Kibana+X-Pack Subscriptions that Go to Work for You","categories":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://zshell.cc/categories/elasticsearch/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://zshell.cc/tags/elasticsearch/"},{"name":"httpcomponents","slug":"httpcomponents","permalink":"http://zshell.cc/tags/httpcomponents/"}]},{"title":"java gc 日志学习笔记","slug":"jvm-gc--java_gc日志学习笔记","date":"2018-03-06T10:04:22.000Z","updated":"2018-05-20T12:12:36.041Z","comments":true,"path":"2018/03/06/jvm-gc--java_gc日志学习笔记/","link":"","permalink":"http://zshell.cc/2018/03/06/jvm-gc--java_gc日志学习笔记/","excerpt":"关于 gc 日志, 网上有丰富的资料, 另外周志明的《深入理解 Java 虚拟机: JVM 高级特性与最佳实践》一书, 在第二版中的第 3.5.8 小节也补充了关于 gc 日志的介绍;但是真等拿到一个具体的 gc log, 才发现网上很多的内容都停留在一个比较初级的层次, 只是介绍了最基本的情况; 其对于生产环境中正在使用的 CMS, G1 收集器涉及很少, 对各种 gc 相关的 jvm 参数, 它们在 gc 日志中的具体作用, 也少见一个详细的整理; 另外, 对 gc 日志的管理运维, 我也很难看到一篇好文章来认真讨论;基于以上状况, 我决定在这里写下这篇文章, 从我自己的角度去对 java gc 作一个全面的总结;补充说明: 本文所述内容涉及的 jvm 版本是: Java HotSpot(TM) 64-Bit Server VM (25.60-b23) for linux-amd64 JRE (1.8.0_60-b27);","text":"关于 gc 日志, 网上有丰富的资料, 另外周志明的《深入理解 Java 虚拟机: JVM 高级特性与最佳实践》一书, 在第二版中的第 3.5.8 小节也补充了关于 gc 日志的介绍;但是真等拿到一个具体的 gc log, 才发现网上很多的内容都停留在一个比较初级的层次, 只是介绍了最基本的情况; 其对于生产环境中正在使用的 CMS, G1 收集器涉及很少, 对各种 gc 相关的 jvm 参数, 它们在 gc 日志中的具体作用, 也少见一个详细的整理; 另外, 对 gc 日志的管理运维, 我也很难看到一篇好文章来认真讨论;基于以上状况, 我决定在这里写下这篇文章, 从我自己的角度去对 java gc 作一个全面的总结;补充说明: 本文所述内容涉及的 jvm 版本是: Java HotSpot(TM) 64-Bit Server VM (25.60-b23) for linux-amd64 JRE (1.8.0_60-b27); 与 gc 相关的 jvm 选项以下选项可以开启 gc 日志:123456# 打印 gc 的基本信息-verbose:gc# 与 -verbose:gc 功能相同-XX:+PrintGC# 打印 gc 的详细信息-XX:+PrintGCDetails -verbose:gc 与 -XX:+PrintGC 在功能上是一样的; 其区别在于 -verbose 是 jvm 的标准选项, 而 -XX 是 jvm 的非稳定选项; 另外, -XX:+PrintGCDetails 在启动脚本中可以自动开启 PrintGC 选项; 以下选项可以控制 gc 打印的内容:12345678910111213141516# 输出 gc 发生的时间, 形如: yyyy-MM-dd'T'HH:mm:ss.SSSZ +0800-XX:+PrintGCDateStamps# 输出 gc 发生时, 从进程启动到当前时刻总共经历的时间长度, 单位为秒-XX:+PrintGCTimeStamps# 打印 gc 的原因, jdk7 以上支持, 从 jdk8 开始默认打印 gc 原因-XX:+PrintGCCause# 打印 jvm 进入 safepoint 时的状态统计-XX:+PrintSafepointStatistics# 打印每次 \"stop the world\" 持续的时间-XX:+PrintGCApplicationStoppedTime# gc 发生前打印堆的状态-XX:+PrintHeapAtGC# gc 发生时打印每一个岁数上对象存活数量分布图-XX:+PrintTenuringDistribution gc 日志开头的元信息输出一般在 jvm 启动时, gc.log 都会在开头打印出与当前 jvm 相关的一些元信息:1234567# jvm 版本信息Java HotSpot(TM) 64-Bit Server VM (25.60-b23) for linux-amd64 JRE (1.8.0_60-b27), built on Aug 4 2015 12:19:40 by \"java_re\" with gcc 4.3.0 20080428 (Red Hat 4.3.0-8)# 内存信息Memory: 4k page, physical 65859796k(37547692k free), swap 0k(0k free)# jvm 选项CommandLine flags: -XX:+DisableExplicitGC -XX:+FlightRecorder -XX:+G1SummarizeConcMark -XX:+HeapDumpOnOutOfMemoryError -XX:InitialHeapSize=33285996544 -XX:MaxHeapSize=33285996544 -XX:+PrintClassHistogram -XX:+PrintGC -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintTenuringDistribution -XX:+UnlockCommercialFeatures -XX:+UnlockDiagnosticVMOptions -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseG1GC 在 jvm 选项中使用不同的收集器, 所输出的 gc 日志格式会有所不同, 尤其是 G1, CMS 等实现复杂的收集器; 不过, 在一些细节的区别之外, 大部分收集器在整体结构上都会维持一定的共性, 以方便使用者阅读; gc 日志内容分析我选取了几段有代表性的 gc 日志, 包括 ParNew, PS, CMS, G1, 其中相同或相似的内容我作了合并, 内容不同的部分则单独整理; 同时我也选取了一些有代表性的 gc 日志选项所打印的内容, 作重点介绍; (1) 打印 gc 发生的时间点, 与 jvm 启动后经历的时间长度对应的 jvm 选项是 PrintGCDateStamps 和 PrintGCTimeStamps; 其中, gc timestamp 是从 jvm 启动至日志打印当时所经历的秒数;123# -XX:+PrintGCDateStamps# -XX:+PrintGCTimeStamps2018-02-06T11:46:09.444+0800: 30.455: [...] (2) 打印 gc 发生的原因及类型对应的 jvm 选项是 PrintGCCause; 当然, 在 jdk8 之后, 默认会打印 gc cause;这里 G1 和其他的收集器在格式上稍有区别, 因为它的设计与其他收集器差异较大, gc 的条件及类型都不尽相同;G1 收集器的格式, 第一个括号内是 gc 原因, 第二个括号内为 gc 类型:123456# -XX:+PrintGCCause# G1 收集器的四种基本 gc 原因GC pause (G1 Evacuation Pause) (mixed)GC pause (GCLocker Initiated GC) (young)GC pause (G1 Humongous Allocation) (young)GC pause (Metadata GC Threshold) (young) 其他收集器的格式, 括号内是 gc 原因, 括号之前是 gc 类型:123# -XX:+PrintGCCauseGC (Allocation Failure)Full GC (Metadata GC Threshold) 其中 gc 类型是这样界定的: 没有 STW 则为 GC, 若发生了 STW, 则为 Full GC; (3) 打印 gc 发生时每一个岁数上对象存活量分布图对应的 jvm 选项是 PrintTenuringDistribution, 这是一个十分有用的性能调参选项;1234567# -XX:+PrintTenuringDistribution# from / to survivor 的大小为 104857600 bytes, 所以 survivor 区的总大小需要 * 2Desired survivor size 104857600 bytes, new threshold 15 (max 15) # -XX:MaxTenuringThreshold=15# |--当前 age 的对象大小--| |--各 age 累积总大小--|- age 1: 38129576 bytes, 38129576 total- age 2: 34724160 bytes, 72853736 total- age 3: 4290896 bytes, 77144632 total 这里需要注意的是, 最后一列 “各 age 累积总大小”, 是将从 age 1 到当前 age 的所有 size 累积相加而成的; 它们驻留在 survivor 区中, 如果其累积 size 超过了 “Desired survivor size”, 将会有部分装不下 survivor 的对象晋升至年老代;与此同时, 即便没有超过 “Desired survivor size”, 达到 “MaxTenuringThreshold” 的对象也将进入年老代; 为了避免数据频繁地从年轻代晋升至年老代, MaxTenuringThreshold 的合理值应该在 15 左右;如果 survivor 区的 size 设置过小, 则每次达到 “Desired survivor size” 时的最大 age 都将远小于 15, 这同样会造成数据频繁地从年轻代晋升至年老代, 此时就需要考虑是否要调大 survivor 区的大小了; (4) 打印 jvm 运行时间与 STW 的时间对应的 jvm 选项是 PrintGCApplicationStoppedTime 和 PrintGCApplicationConcurrentTime;当发生 “stop the world”, jvm 便会在 gc 日志里记录应用运行的时间:12# -XX:+PrintGCApplicationConcurrentTime2018-02-14T21:35:19.896+0800: 9.433: Application time: 0.0000892 seconds 而当 gc 结束时, jvm 便会在 gc 日志中记录停顿的时间:12# -XX:+PrintGCApplicationStoppedTime2018-02-14T17:45:06.305+0800: 4.189: Total time for which application threads were stopped: 0.0553667 seconds, Stopping threads took: 0.0000412 seconds (5) 打印 jvm 进入 safepoint 的统计信息对应的 jvm 选项是 PrintSafepointStatistics; 除了 gc pause 之外, 还有很多因素会导致 jvm STW 进入 safepoint, 例如: 反优化(deoptimize), 偏向锁生成(enable biased locking) 与偏向锁撤销(revoke bias), thread dump 等;123456789# -XX:+PrintSafepointStatistics –XX:PrintSafepointStatisticsCount=1 vmop [threads: total initially_running wait_to_block][time: spin block sync cleanup vmop] page_trap_count0.169: Deoptimize [ 11 0 0 ] [ 0 0 0 0 0 ] 0 vmop [threads: total initially_running wait_to_block][time: spin block sync cleanup vmop] page_trap_count9.933: RevokeBias [ 52 0 0 ] [ 0 0 0 0 0 ] 0 vmop [threads: total initially_running wait_to_block][time: spin block sync cleanup vmop] page_trap_count49.785: BulkRevokeBias [ 52 1 1 ] [ 0 0 0 0 0 ] 0 vmop [threads: total initially_running wait_to_block][time: spin block sync cleanup vmop] page_trap_count49.821: GenCollectForAllocation [ 52 2 2 ] [ 0 0 0 0 22 ] 0 其中:第一列 vmop 是 vm operation, 本次 stw 要做的事情;total 是 stw 发生时, jvm 的总线程数;initially_running 是正在运行, 尚未进入 safepoint 的线程数, 对应后面的时间是 spin;wait_to_block 是进入 safepoint 后尚未阻塞的线程数, 对应后面的时间是 block;所以, sync = spin + block + cleanup;最后一列 vmop 则是 jvm 进入 safepoint 实际动作所消耗的时间; &nbsp;以上就是一些典型的与 gc 相关的 jvm 选项; 下面要说的是各典型的收集器日志; (6) ParNew 收集器的日志这种是最标准的 gc 日志格式, 也是各种资料上介绍得最多的内容, 日志的含义我已标注在注释上:123# -XX:+PrintGCDetails# |--gc 前后该区域的 size 变化---| |--gc 的时间--| |--gc 前后整个堆的 size 变化--| |--gc 总耗时--| [275184K-&gt;1998K(306688K), 0.0151232 secs] 598728K-&gt;325543K(2063104K), 0.0152605 secs] [Times: user=0.05 sys=0.00, real=0.02 secs] (7) Paravel Scavenge 收集器的日志PS 虽然也不是按照标准框架实现的收集器, 但是其 gc 日志与 ParNew 等相比几乎是一脉相承, 几无二致, 此处便不再赘述;12# -XX:+PrintGCDetails[PSYoungGen: 585755K-&gt;2888K(640000K)] 1625561K-&gt;1042703K(2038272K), 0.0278206 secs] [Times: user=0.03 sys=0.02, real=0.03 secs] (8) CMS 收集器的日志CMS 的 gc 日志基本上是按照 CMS 收集算法的执行过程详细记录的;123# -XX:+PrintGCDetails# CMS-initial-mark2018-02-14T17:45:06.250+0800: 4.134: [GC (CMS Initial Mark) [1 CMS-initial-mark: 0K(1756416K)] 190272K(2063104K), 0.0550579 secs] [Times: user=0.18 sys=0.00, real=0.05 secs] 12345678910# CMS-concurrent-mark-start2018-02-14T17:45:06.305+0800: 4.189: [CMS-concurrent-mark-start]2018-02-14T17:45:06.320+0800: 4.203: [CMS-concurrent-mark: 0.014/0.014 secs] [Times: user=0.05 sys=0.00, real=0.02 secs] # CMS-concurrent-preclean2018-02-14T17:45:06.320+0800: 4.203: [CMS-concurrent-preclean-start]2018-02-14T17:45:06.324+0800: 4.208: [CMS-concurrent-preclean: 0.004/0.004 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 2018-02-14T17:45:06.325+0800: 4.208: Total time for which application threads were stopped: 0.0009297 seconds, Stopping threads took: 0.0000444 seconds2018-02-14T17:45:06.325+0800: 4.209: [CMS-concurrent-abortable-preclean-start] CMS: abort preclean due to time 2018-02-14T17:45:11.592+0800: 9.475: [CMS-concurrent-abortable-preclean: 4.211/5.267 secs] [Times: user=10.30 sys=0.27, real=5.27 secs] 2018-02-14T17:45:11.592+0800: 9.476: Total time for which application threads were stopped: 0.0001745 seconds, Stopping threads took: 0.0000389 seconds 123456789101112# CMS-final-remark2018-02-14T17:45:11.592+0800: 9.476: [GC (CMS Final Remark) [YG occupancy: 173321 K (306688 K)]2018-02-14T17:45:11.592+0800: 9.476: [Rescan (parallel) , 0.0380948 secs]2018-02-14T17:45:11.630+0800: 9.514: [weak refs processing, 0.0001539 secs]2018-02-14T17:45:11.630+0800: 9.514: [class unloading, 0.0082249 secs]2018-02-14T17:45:11.639+0800: 9.522: [scrub symbol table, 0.0051294 secs]2018-02-14T17:45:11.644+0800: 9.528: [scrub string table, 0.0010024 secs][1 CMS-remark: 19239K(1756416K)] 192561K(2063104K), 0.0549428 secs] [Times: user=0.17 sys=0.00, real=0.05 secs] ``` ``` bash# CMS-concurrent-sweep2018-02-14T17:45:11.647+0800: 9.531: [CMS-concurrent-sweep-start]2018-02-14T17:45:11.651+0800: 9.535: [CMS-concurrent-sweep: 0.004/0.004 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] # CMS-concurrent-reset2018-02-14T17:45:11.651+0800: 9.535: [CMS-concurrent-reset-start]2018-02-14T17:45:11.668+0800: 9.552: [CMS-concurrent-reset: 0.015/0.017 secs] [Times: user=0.05 sys=0.02, real=0.01 secs] 关于 CMS 收集算法的流程逻辑, 请参见另一篇文章: CMS 收集算法学习与整理; (9) G1 收集器的日志123456789101112131415161718192021222324252627282930# -XX:+PrintGCDetails# 老生代的 gc 时间状况 [Parallel Time: 107.6 ms, GC Workers: 23] [GC Worker Start (ms): Min: 30455.3, Avg: 30455.6, Max: 30455.8, Diff: 0.5] [Ext Root Scanning (ms): Min: 0.7, Avg: 1.6, Max: 16.4, Diff: 15.7, Sum: 37.8] [Update RS (ms): Min: 0.0, Avg: 0.5, Max: 0.9, Diff: 0.9, Sum: 12.6] [Processed Buffers: Min: 0, Avg: 0.9, Max: 2, Diff: 2, Sum: 21] [Scan RS (ms): Min: 0.0, Avg: 0.1, Max: 0.2, Diff: 0.2, Sum: 1.3] [Code Root Scanning (ms): Min: 0.0, Avg: 2.3, Max: 26.9, Diff: 26.9, Sum: 52.4] [Object Copy (ms): Min: 78.3, Avg: 102.5, Max: 105.7, Diff: 27.4, Sum: 2357.9] [Termination (ms): Min: 0.0, Avg: 0.1, Max: 0.1, Diff: 0.1, Sum: 1.3] [Termination Attempts: Min: 1, Avg: 63.0, Max: 79, Diff: 78, Sum: 1448] [GC Worker Other (ms): Min: 0.0, Avg: 0.1, Max: 0.1, Diff: 0.1, Sum: 1.5] [GC Worker Total (ms): Min: 106.9, Avg: 107.2, Max: 107.5, Diff: 0.6, Sum: 2464.8] [GC Worker End (ms): Min: 30562.7, Avg: 30562.7, Max: 30562.8, Diff: 0.1] [Code Root Fixup: 3.2 ms] [Code Root Purge: 0.1 ms] [Clear CT: 0.6 ms] [Other: 4.4 ms] [Choose CSet: 0.0 ms] [Ref Proc: 1.6 ms] [Ref Enq: 0.0 ms] [Redirty Cards: 0.4 ms] [Humongous Register: 0.2 ms] [Humongous Reclaim: 0.1 ms] [Free CSet: 1.0 ms]# 新生代的 gc 状况 [Eden: 1472.0M(1464.0M)-&gt;0.0B(1384.0M) Survivors: 120.0M-&gt;200.0M Heap: 1781.0M(31.0G)-&gt;682.3M(31.0G)]# gc 时间统计 [Times: user=2.36 sys=0.06, real=0.11 secs] 关于 CMS 收集算法的流程逻辑, 请参见另一篇文章: G1 收集算法学习与整理; gc 日志文件的运维最佳实践关于 gc 日志文件本身的管理运维, 也是存在一些经验的, 错误的运维方法将为性能排查甚至系统运行带来麻烦与阻碍;(1) 避免新的 gc 日志覆盖旧的 gc 日志使用 -Xloggc 可以指定 gc 日志的输出路径, 错误的经验会引导我们作如下设置:1-Xloggc:$&#123;CATALINA_BASE&#125;/logs/gc.log 这种设置带来的问题是: 当系统重启后, 新的 gc 日志的路径与老的 gc 日志路径相同, 新日志便会将旧日志覆盖;系统一般不会随便重启, 如果重启, 很可能是出现了故障, 或者性能问题; 在这种设置下, 如果重启前忘了备份当前的 gc 日志, 那重启后就没有性能诊断的依据了 (当然也可能事先使用 jstack, jmap 等工具作了部分现场的保留, 并非完全无法作诊断, 这里只是单从 gc 的角度讨论);所以, 最佳的方法是为 gc 日志的命名带上时间戳:1-Xloggc:$&#123;CATALINA_BASE&#125;/logs/gc.log-$(date +%Y-%m-%d-%H-%M) 这样只要不是在同一分钟内两次重启, gc 日志都不会被覆盖; (2) gc 日志的 rolling 滚动如果系统一直在健康运行, 那么 gc 日志的大小就会稳定地增长, 占用磁盘空间, 最后导致磁盘空间报警; 显然我们需要对 gc 日志作 rolling, 主流的方式是使用 jvm 自己的选项作控制:123456# 启用 gc 日志 rolling-XX:+UseGCLogFileRotation# 设置 gc 日志的最大 size, 一旦触发该条件就滚动切分-XX:GCLogFileSize=10M# 设置保留滚动 gc 日志的最大文件数量-XX:NumberOfGCLogFiles=5 最后日志目录下的内容类似于下面这个样子:12345gc.log-2018-03-01-17-58.0gc.log-2018-03-01-17-58.1gc.log-2018-03-01-17-58.2gc.log-2018-03-01-17-58.3gc.log-2018-03-01-17-58.4.current 最后一个带 “.current” 后缀的就是当前正在写的 gc 日志;但这种方式有个问题, 日志文件名没有规范 当达到最大文件数量后, jvm 会选择回头覆盖最老的那个日志文件, 并把 “.current” 后缀也挪过去, 这种模式对日志收集相当得不友好, 我们很难定位当前正在写入的 log 文件;于是有另外一种思路想来解决 gc 日志收集的问题, 其采用了挪走并写空的方式:1234# 按天作 rollingcp /home/q/www/$i/logs/gc.log /home/q/www/$i/logs/gc.log.$(date -d \"yesterday\" +%F)echo &gt; /home/q/www/$i/logs/gc.loggzip /home/q/www/$i/logs/gc.log.$(date -d \"yesterday\" +%F) 这种方法看似可行, 但忽略了一个问题: cp 和 echo 写空这两步并非原子操作, 在这个处理过程中, jvm 依然在试图往日志里写内容, 这就造成了写空后的 gc.log 接不上被 rolling 的老日志了, 甚至在字节层面上都不是完整的编码了, 打开看一下就报了这种错:1\"gc.log\" may be a binary file. See it anyway? 即便是使用 strings 命令搜索文本内容, 也只能得到一些残缺的内容, 完全无法分析问题了;说到底, gc 日志的收集陷入这样的困境, 其实是 jvm 自己的支持度不够好; 像 nginx, 使用 kill -USER1 便可以作到原子切割日志; logback 的 RollingFileAppender 也是自身提供了完整的支持; 可惜 jvm gc log 没有走类似的路线, 而是采用了一种古怪的类似于 rrd 的环状模式, 直接造成了收集日志的困难; gc 日志的辅助分析工具其实拿到一个冗长的 gc 日志文件, 对着枯燥的数字, 我们很难对 待诊断的系统建立起一个直观而感性的性能健康状态的认识;这里有一个十分出色的 gc 日志可视化分析工具: gceasy, 其对于 gc 问题的诊断可谓是如虎添翼;上传 gc 日志并分析诊断, gceasy 可以给出多维度的可视化分析报告, 以友好的交互自动诊断系统的问题所在: Heap Statistics (堆状态统计) heap_statistics GC Phases Statistics (gc 算法流程各阶段的时间统计) gc_phase_statistics GC Time (gc 时间统计) gc_time_statistics GC Cause (gc 原因分布统计) gc_cause_statistics tenuring summary (survivor 区每一个岁数上存活对象 szie 统计) tenuring_summary 站内相关文章 CMS 收集算法学习与整理 G1 收集算法学习与整理 参考链接 深入理解 Java 虚拟机: JVM 高级特性与最佳实践 (第2版) 3.5.8 理解 GC 日志 Understanding G1 GC Logs Java -verbose:gc 命令 jvm参数-verbose:gc和-XX:+PrintGC有区别? (阿里云) jvm参数-verbose:gc和-XX:+PrintGC有区别? (segmentfault) Some junk characters displaying at start of jboss gc log file GC日志中的 stop-the-world java GC进入safepoint的时间为什么会这么长 ROTATING GC LOG FILES Forwarding JVM Garbage Collector Logs jvm-对象年龄(-XX:+PrintTenuringDistribution)","categories":[{"name":"jvm","slug":"jvm","permalink":"http://zshell.cc/categories/jvm/"},{"name":"gc","slug":"jvm/gc","permalink":"http://zshell.cc/categories/jvm/gc/"}],"tags":[{"name":"jvm:gc","slug":"jvm-gc","permalink":"http://zshell.cc/tags/jvm-gc/"},{"name":"jvm 选项","slug":"jvm-选项","permalink":"http://zshell.cc/tags/jvm-选项/"}]},{"title":"python module 使用总结: 定时调度器","slug":"python-module--python_module_使用总结_定时调度器","date":"2018-02-23T15:23:21.000Z","updated":"2018-03-24T07:08:34.770Z","comments":true,"path":"2018/02/23/python-module--python_module_使用总结_定时调度器/","link":"","permalink":"http://zshell.cc/2018/02/23/python-module--python_module_使用总结_定时调度器/","excerpt":"在 java 里, 第三方定时调度框架比较常用的是 quartz 和 springframework 提供的 schedule 功能; 不过在各大公司里, 一般都会开发自己能集中管理与灵活调控的调度组件; 这样一来, 第三方的调度框架反而就接触的少了;我相信在以 python 为主要使用语言的公司里, 一定也有自己的调度中间件; 但是对于以 java 为主的公司里, 肯定不可能专为 python 维护一套调度系统, 所以就很有必要了解一下 python 里的定时调度模块; 本文将介绍几种常用的 python 定时调度框架: 简单的实现: sched 与 schedule; 功能增强版: apscheduler; 分布式调度器: celery;","text":"在 java 里, 第三方定时调度框架比较常用的是 quartz 和 springframework 提供的 schedule 功能; 不过在各大公司里, 一般都会开发自己能集中管理与灵活调控的调度组件; 这样一来, 第三方的调度框架反而就接触的少了;我相信在以 python 为主要使用语言的公司里, 一定也有自己的调度中间件; 但是对于以 java 为主的公司里, 肯定不可能专为 python 维护一套调度系统, 所以就很有必要了解一下 python 里的定时调度模块; 本文将介绍几种常用的 python 定时调度框架: 简单的实现: sched 与 schedule; 功能增强版: apscheduler; 分布式调度器: celery; schedsched 是 python 官方提供的定时调度模块, 其实现非常的简单, sched.py 的代码量只有一百多行, 且只有一个类: scheduler;123456789101112131415# sched.pyclass scheduler: \"\"\" @param timefunc 能够返回时间戳的计时函数, 要求该函数是一个无参函数 @param delayfunc 能够阻塞给定时间的阻塞函数, 要求该函数能接收一个数值类型的参数 \"\"\" def __init__(self, timefunc, delayfunc); \"\"\" @param delay 需要延迟的时间 @param priority 当多个任务需要在同一个时间调度时的优先级 @param action 需要调度的函数 @param argument 需要调度函数的参数列表 \"\"\" def enter(self, delay, priority, action, argument); 如上所示, scheduler 是使用构造器传进来的计时函数与阻塞函数去实现调度逻辑的; sched 的局限性与解决方案不过说真的, 把 sched 定义为定时调度模块真的很牵强:常规意义上, 我们所理解的定时调度器, 应该是能够像 cron 那样, 按给定的时间间隔或在指定的时间点上循环执行指定的任务; 但是 sched 并不能做到这一点, sched 所做的, 只是从某一个时间点开始, delay 一段我们给定的延时时间, 然后执行给定方法, 仅执行这一次;12345678910import timefrom sched import schedulerdef do_task(time_str): print('task run: %s' % time_str)s = scheduler(time.time, time.sleep)# delay 5 秒后执行 do_task 函数, 仅执行一次s.enter(5, 0, do_task, (time.time(),))s.run() 要想 sched 做到循环执行, 还需要在其基础上包装上一层类似’递归’的概念:12345678s = scheduler(time.time, time.sleep)# 在任务函数中将自己再次用 sched 调度以实现循环def do_task(time_str): s.enter(5, 0, do_task, (time.time(),)) print('task run: %s' % time_str) s.enter(5, 0, do_task, (time.time(),))s.run() 当然, 这只是将函数自己的引用传给了 scheduler, 神似递归但并非递归, 所以也就不存在找不到递归出口而爆栈的问题了;很明显, 采用这种方式才能实现真正的定时调度, 可谓非常麻烦而蹩脚; sched 的调度原理sched 使用 heapq 优先队列来管理需要调度的任务(关于 heapq 的详细内容请参考: python module 使用总结: heapq); 在调用了 scheduler 类的 enter 方法后, 其实是生成了一个任务的快照, 并放入了优先队列里:12event = Event(time, priority, action, argument)heapq.heappush(self._queue, event) 在调用 scheduler.run() 方法后, sched 在一个死循环里, 不断得从优先队列里取出任务执行, 计算最近的下一个任务的等待时间并阻塞:12345678910111213q = self._queue while q: time, priority, action, argument = checked_event = q[0] now = timefunc() if now &lt; time: delayfunc(time - now) else: event = pop(q) if event is checked_event: action(*argument) delayfunc(0) else: heapq.heappush(q, event) 总体来说, sched 的设计还是比较紧凑清晰的, 轻量化; 但是由于其固有的缺陷, 在复杂的场景中, 往往不能胜任, 我们需要功能更强大的调度框架; scheduleschedule 是一个广泛使用的 python 定时调度框架, 其 github 地址如下: https://github.com/dbader/schedule, 目前 4k 多个 stars;和 python 官方的 sched 相比, schedule 的 API 要人性化得多, 而且它基本实现了真正意义上的定时调度:123456789101112131415161718import scheduleimport timedef do_task(time_str=time.time()): print('task run: %s' % time_str)# 每 10 分钟执行一次任务schedule.every(10).minutes.do(do_task)# 每隔 5 到 10 分钟之间的任意一个时间执行一次任务schedule.every(5).to(10).days.do(do_task)# 每 1 小时执行一次任务schedule.every().hour.do(do_task, time_str='1519351479.19554')# 每天 10:30 执行一次任务schedule.every().day.at(\"10:30\").do(do_task)while True: schedule.run_pending() time.sleep(1) schedule 模块的 Scheduler 类其实, schedule 模块的整体设计, 是把任务的自我管理部分做的很详细, 而把上层的调度做的很轻很薄, 关键逻辑点采用回调的方式, 依赖任务的自我管理去实现;而上一节所讲的 sched 模块, 则是在上层调度部分使用了复杂的逻辑 (优先队列) 去统一管理, 而任务本身携带的信息很少; sched 与 schedule 两个模块, 在整体设计上, 形成了鲜明的对比;Scheduler 类的实例中, 维护了一个列表: jobs, 专门存储注册进来的任务快照;123Class Scheduler(object): def __init__(self): self.jobs = [] Scheduler 类最重要的方法是 run_pending(self), 其主要逻辑是遍历 jobs 列表中的所有 job, 从中找出当前时间点需要调度的 job, 并执行;这其中最重要的逻辑是判断一个 job 当前时间点是否需要被调度, 而这个过程是一个回调, 具体的逻辑则封装在 job.should_run 方法里, 下一小节将会详细介绍;可以发现, 总共只用了三行代码, 以此可见其轻量化;1234def run_pending(self): _jobs = (job for job in self.jobs if job.should_run) for job in sorted(runnable_jobs): self._run_job(job) 值得注意的是, schedule 模块中并没有专门的逻辑去定时执行 run_pending 方法, 要想让定时调度持续跑起来, 需要自己实现:123while True: schedule.run_pending() time.sleep(1) 相比 sched 模块的 ‘伪递归’ 而言, 这样的设计算是比较人性化的了, 可以认为它基本实现了真正意义上的定时调度; schedule 模块的 Job 类正如上一节所述, schedule 模块实现了非常详细的任务自我管理逻辑; 相比 sched 的 Event 类, schedule 定义了一个控制参数更丰富的 Job 类:12345678910111213class Job(object): def __init__(self, interval, scheduler=None): self.interval = interval # pause interval * unit between runs self.latest = None # upper limit to the interval self.job_func = None # the job job_func to run self.unit = None # time units, e.g. 'minutes', 'hours', ... self.at_time = None # optional time at which this job runs self.last_run = None # datetime of the last run self.next_run = None # datetime of the next run self.period = None # timedelta between runs, only valid for self.start_day = None # Specific day of the week to start on self.tags = set() # unique set of tags for the job self.scheduler = scheduler # scheduler to register with Job 类的参数众多, 单个任务的调度肯定不可能涉及到所有的参数, 这些参数往往是以局部几个为组合, 控制调度节奏的; 但是无论什么组合, 往往都会以 scheduler.every(interval=1) 方法开始, 以 Job.do(self, job_func, *args, **kwargs) 方法结束:(1) schedule.every 方法构造出一个 Job 实例, 并设置该实例的第一个参数 interval;123456789default_scheduler = Scheduler()def every(interval=1): return default_scheduler.every(interval)class Scheduler(object): def every(self, interval=1): job = Job(interval, self) return job 这里想吐槽的是, 这个方法出现在 Scheduler 类中有点突兀, 而且方法名叫 every, 只体现了设置 interval 参数的含义, 但并不能从中看出其新构造一个 Job 实例的意图;(2) Job.do 方法包装了传递进来的任务函数, 将其设置为自己的 job_func 参数, 并将自己作为一个任务快照放进 scheduler 的任务列表里;1234567891011Class Job(object): def do(self, job_func, *args, **kwargs): self.job_func = functools.partial(job_func, *args, **kwargs) try: functools.update_wrapper(self.job_func, job_func) except AttributeError: pass # 计算下一次调度的时间 self._schedule_next_run() self.scheduler.jobs.append(self) return self 在这两个方法之间, 就是通过建造者模式, 构造出其他控制参数的组合, 以实现各种各样的调度节奏;下面来重点讲一下各参数组合如何实现调度节奏的控制;从上一节关于 Scheduler 类的描述中可以看到, 上层调度中最关键的逻辑, 判断每一个注册的 job 是否应该被调度, 其实是 Job 类的一个回调方法 should_run:12def should_run(self): return datetime.datetime.now() &gt;= self.next_run 而 should_run 方法中的判断的依据, 是当前时间有没有到达 next_run 这个实例字段给出的时间点;next_run 字段的设置则通过在 Job.do(self, job_func, *args, **kwargs) 方法 (上文已给出) 和 Job.run(self) 方法中调用 __schedule_next_run() 方法来实现:1234567def run(self): logger.info('Running job %s', self) ret = self.job_func() self.last_run = datetime.datetime.now() # 计算下一次调度的时间 self._schedule_next_run() return ret 所以, 所有的秘密就存在于 _schedule_next_run() 方法里了; 下面将结合几大类参数组合的设置, 拆开来分析 _schedule_next_run() 方法的逻辑;这些 Job 类的参数组合, 大致可分为这几类: 总基调: 指定调度的周期以下方法将会设置 unit 参数, 与 interval 参数结合, 定义调度区间间隔:12345def second(self): def seconds(self): # self.unit = 'seconds'def minute(self): def minutes(self): # self.unit = 'minutes'def hour(self): def hours(self): # self.unit = 'hours'def day(self): def days(self): # self.unit = 'days'def week(self): def weeks(self): # self.unit = 'weeks' 其对应的 _schedule_next_run() 逻辑如下:12345678910# def _schedule_next_run(self) assert self.unit in ('seconds', 'minutes', 'hours', 'days', 'weeks') if self.latest is not None: assert self.latest &gt;= self.interval interval = random.randint(self.interval, self.latest) else: interval = self.interval self.period = datetime.timedelta(**&#123;self.unit: interval&#125;) self.next_run = datetime.datetime.now() + self.period 先不管其中涉及到的 latest 字段 (下文描述), 其他的逻辑清晰可见: 使用 unit 和 interval 构造出一个指定的 timedelta, 加上当前时间得到下次调度的时间;&nbsp;这是最简单的一类, 定下了整个调度的总体节奏; 而下面几个类别的参数并不能单独决定调度周期, 而是在第一类参数的基础之上实施局部调整, 以达到综合控制; 局部调整1: 指定调度的起始 weekday以下方法将会设置 start_day 参数, 确定调度开始的时间点; 同时统一设置 unit 参数为 ‘weeks’:123456789101112131415161718192021def monday(self): self.start_day = 'monday' self.unit = 'weeks'def tuesday(self): self.start_day = 'tuesday' self.unit = 'weeks'def wednesday(self): self.start_day = 'wednesday' self.unit = 'weeks'def thursday(self): self.start_day = 'thurday' self.unit = 'weeks'def friday(self): self.start_day = 'friday' self.unit = 'weeks'def saturday(self): self.start_day = 'saturday' self.unit = 'weeks'def sunday(self): self.start_day = 'sunday' self.unit = 'weeks' 其对应的 _schedule_next_run() 逻辑如下:12345678910# def _schedule_next_run(self) if self.start_day is not None: assert self.unit == 'weeks' weekdays = ('monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday') assert self.start_day in weekdays weekday = weekdays.index(self.start_day) days_ahead = weekday - self.next_run.weekday() if days_ahead &lt;= 0: # Target day already happened this week days_ahead += 7 self.next_run += datetime.timedelta(days_ahead) - self.period 可以发现, start_day 只是在 next_run 原有的 weekday 基础上增加了一个 offset, 相当于是 delay time; 局部调整2: 指定调度的起始时间以下方法将会设置 at_time 参数, 其针对 unit == ‘hours’ 只设置 minute 变量, 而对 unit == ‘days’ 或 ‘weeks’ 才会设置 hour 变量;123456789101112def at(self, time_str): assert self.unit in ('days', 'hours') or self.start_day hour, minute = time_str.split(':') minute = int(minute) if self.unit == 'days' or self.start_day: hour = int(hour) assert 0 &lt;= hour &lt;= 23 elif self.unit == 'hours': hour = 0 assert 0 &lt;= minute &lt;= 59 self.at_time = datetime.time(hour, minute) return self 其对应的 _schedule_next_run() 逻辑也与上面类似, 针对 unit == ‘days’ 或 ‘weeks’ 才设 hour 字段, 否则只设置 minute 和 second;1234567891011# def _schedule_next_run(self) if self.at_time is not None: assert self.unit in ('days', 'hours') or self.start_day is not None kwargs = &#123; 'minute': self.at_time.minute, 'second': self.at_time.second, 'microsecond': 0 &#125; if self.unit == 'days' or self.start_day is not None: kwargs['hour'] = self.at_time.hour self.next_run = self.next_run.replace(**kwargs) 局部调整3: 在给定范围内随机安排调度时刻对应的就是上文提及的 latest 参数:123def to(self, latest): self.latest = latest return self 其对应的 _schedule_next_run() 逻辑如下:123456# def _schedule_next_run(self) if self.latest is not None: assert self.latest &gt;= self.interval interval = random.randint(self.interval, self.latest) else: interval = self.interval 具体逻辑就是在给定的 [interval, latest) 区间内, 生成一个随机数作为下次调度的 interval;&nbsp;至此, Job 类的逻辑就都分析完了; apschedulercelery站内相关文章 python module 使用总结: heapq 参考链接 8.8. sched — Event scheduler python sched模块学习 python中的轻量级定时任务调度库: schedule","categories":[{"name":"python","slug":"python","permalink":"http://zshell.cc/categories/python/"},{"name":"module","slug":"python/module","permalink":"http://zshell.cc/categories/python/module/"}],"tags":[{"name":"python","slug":"python","permalink":"http://zshell.cc/tags/python/"},{"name":"python:module","slug":"python-module","permalink":"http://zshell.cc/tags/python-module/"}]},{"title":"一个 dev 的拙劣前端笔记: 使用 jQuery ajax 上传文件","slug":"web--一个dev的拙劣前端笔记_使用jQuery_ajax上传文件","date":"2018-02-03T13:48:08.000Z","updated":"2018-02-07T15:43:29.215Z","comments":true,"path":"2018/02/03/web--一个dev的拙劣前端笔记_使用jQuery_ajax上传文件/","link":"","permalink":"http://zshell.cc/2018/02/03/web--一个dev的拙劣前端笔记_使用jQuery_ajax上传文件/","excerpt":"从传统的刷新提交到 ajax 提交, 从间接的 iframe 刷新 ajax 提交到真正意义上的 ajax 提交, 关于前端文件上传的方法, 伴随着 web 技术与标准的演进, 不断推陈出新;本文整理了从传统方式到 ajax 方式上传文件的各种方法;","text":"从传统的刷新提交到 ajax 提交, 从间接的 iframe 刷新 ajax 提交到真正意义上的 ajax 提交, 关于前端文件上传的方法, 伴随着 web 技术与标准的演进, 不断推陈出新;本文整理了从传统方式到 ajax 方式上传文件的各种方法; 传统的上传文件方式form 表单有三种可能的 MIME 编码类型: 默认的 application/x-www-form-urlencoded, 不对字符编码而保留原始信息的 multipart/form-data, 以及纯文本 text/plain;如果没有异步刷新的需求, 只需要将 form 表单的 enctype 属性设置为 multipart/form-data, 便可以二进制的方式提交表单内容, 以达到上传文件的目的:12345&lt;form id=\"form_id\" enctype=\"multipart/form-data\"&gt; &lt;input type=\"text\" name=\"str\" /&gt; &lt;input type=\"file\" name=\"fileAttach\" /&gt; &lt;input type=\"submit\" value=\"upload\" /&gt; &lt;/form&gt; 关于 MIME 类型 multipart/form-data 的更多内容, 请参见: 一个 dev 的拙劣前端笔记: content-type 之 multipart/form-data 规范整理;&nbsp;下面来讨论如何使用 ajax 实现文件上传; 使用 jQuery ajaxFileUpload 插件实现文件上传ajax 默认使用的 MIME 类型是 application/x-www-form-urlencoded, 这种方式只适用于传输普通字符串类型的数据; 由于在 HTML4 时代, 没有对 javascript 提供文件读取的接口, 使用 document.getElementById(&#39;field_id&#39;).value 也只能获得文件的 name, 并不能拿到文件的二进制数据; 所以, 想直接使用 ajax 无刷新提交表单是无法做到的;所以只能采用间接的方案, 比如基于 jQuery 拓展的 ajaxFileUpload 插件, 其代码逻辑大致如下: function createUploadIframe():创建一个独立的 iframe, 并追加到 body 中; function createUploadForm(file_elem_id):创建一个独立的 form, 设置 enctype 为 multipart/form-data;根据 file_elem_id 找到页面里的目标 &lt;input type=&quot;file&quot; /&gt; 对象, 使用 jQuery.clone 方法, 将新的克隆对象替换到目标对象的位置, 而将原目标对象追加到新建的 form 中(偷梁换柱);最后将新创建的 form 追加到 body 中; function addOtherRequestsToForm(data, new_form):将页面中目标表单的其他元素数据, 一并追加到新创建的 form 里; function ajaxFileUpload:调用 createUploadForm 方法创建新 form;调用 addOtherRequestsToForm 方法捎带除 file 之外的其余元素数据;调用 createUploadIFrame 方法创建 iframe;将新 form 的 target 属性设置为新创建 iframe 的 id, 以实现间接的无刷新;submit 提交新 form; &nbsp;ajaxFileUpload 的实现逻辑并不复杂, 类似这样的插件在 github 上有各种各样的版本, 我选取了一个比较典型的实现: carlcarl/AjaxFileUpload/ajaxfileupload.js;然后开发者在实际使用时需要调用的是 jQuery.ajaxFileUpload 方法, 设置一些参数与回调方法:123456789101112131415161718192021222324252627282930313233function ajax_submit(field_id) &#123; $.ajaxFileUpload(&#123; fileElementId: field_id, // &lt;input id=\"field_id\" type=\"file\"&gt;, 对应元素的 id data: fetch_form_data('form_id'), // 捎带其余元素的数据 url: '/xxx/yyy/upload' type: 'post', dataType: 'json', secureuri: false, //是否启用安全提交，默认为false async : true, //是否是异步 success: function(data) &#123; if (data['status'] == 0) &#123; window.location.reload(); alert(\"提交成功\"); &#125; else &#123; window.location.reload(); alert(\"提交失败:\" + data['message']); &#125; &#125;, error: function(data, status, e) &#123; window.location.reload(); alert(\"提交失败:\" + data['message']); &#125; &#125;);&#125;// 将给定的表单数据转为对象function fetch_form_data(form_id) &#123; var params = $('#' + form_id).serializeArray(); var values = &#123;&#125;; for( x in params ) &#123; values[params[x].name] = params[x].value; &#125; return values&#125; 抛开 iframe 的性能影响不谈, 看起来这样的 api 还是相当友好的, 与 jQuery.ajax 同样方便, 还解决了 ajax 不能传输二进制流的问题;另外, 由于这种方式真正提交的表单完全是 javascript 创建出来的, 页面上自己写的那个表单, 只作为数据 clone 的载体, 所以只需要确保表单和其中的 file input 元素有自己的 id, 最后提交按钮的 onclick 事件指向了目标方法即可;12345&lt;form id=\"form_id\"&gt; &lt;input type=\"text\" name=\"str\" /&gt; &lt;input id=\"file_attach\" type=\"file\" name=\"fileAttach\" /&gt; &lt;input type=\"button\" onclick=\"ajax_submit('file_attach')\" value=\"upload\" /&gt;&lt;/form&gt; 使用 jQuery ajax 结合 HTML5 API 实现文件上传使用 ajaxFileUplaod 插件, 无论怎么优化改造, 其需要使用 iframe 作间接无刷新的逻辑是没法绕开的; 而使用 iframe 必然会带来额外资源的消耗, 如果有更原生直接的解决方案, 我们一定乐于在项目中取代 ajaxFileUpload;于是, 在 HTML5 时代, 出现了一个新的接口: FormData, 它给出了完美的解决方案;1var form_content = new FormData(document.getElementById(\"form_id\")); 这行代码便拿到了目标表单对象的所有信息; 我们只需要确保表单的 enctype 属性为 multipart/form-data, 通过该接口获得的 FormData 对象, 便是完整的二进制序列化信息:12345&lt;form id=\"form_id\" enctype=\"multipart/form-data\"&gt; &lt;input type=\"text\" name=\"str\" /&gt; &lt;input type=\"file\" name=\"fileAttach\" /&gt; &lt;input type=\"button\" onclick=\"upload_file()\" value=\"upload\" /&gt;&lt;/form&gt; 这样, 一个 onclick 事件触发 upload_file 方法, 使用原生的 jQuery ajax 就实现了上传文件的功能了, 同时表单内的其他字符串数据, 也一并以 multi part 的形式上传上去了;对应的 javascript upload_file 方法如下:1234567891011121314151617181920212223function uplaod_file() &#123; var form_content = new FormData(document.getElementById('form_id')); $.ajax(&#123; type: 'POST', url: '/xxx/yyy/upload', data: form_content, processData: false, // 阻止默认的 application/x-www-form-urlencoded 对象处理方法 contentType: false, // 与 processData 保持一直, 不使用默认的 application/x-www-form-urlencoded success: function (data) &#123; if (data['status'] == 0) &#123; window.location.reload(); alert(\"提交成功\"); &#125; else &#123; window.location.reload(); alert(\"提交失败:\" + data['message']); &#125; &#125;, fail: function (data) &#123; window.location.reload(); alert(\"提交失败:\" + data['message']); &#125; &#125;);&#125; 以上代码需要注意的是:processData 参数默认为 true, 即将 data 转为 url 键值对形式, 这里已经是序列化后的二进制数据, 不需要再次处理, 所以应主动设置其为 false;同时, contentType 默认为 application/x-www-form-urlencoded, 这里不应该使用默认值;关于 jQuery ajax 方法, 更多的内容请参见: jQuery ajax 阅读与理解;&nbsp;这便是 HTML5 时代下, ajax 异步上传文件的最佳实践; 站内相关文章 一个 dev 的拙劣前端笔记: content-type 之 multipart/form-data 规范整理 jQuery ajax 阅读与理解 参考链接 jquery Ajax提交表单(使用jquery Ajax上传附件) JQuery的ajaxFileUpload的使用 carlcarl/AjaxFileUpload/ajaxfileupload.js jquery插件–ajaxfileupload.js上传文件原理分析","categories":[{"name":"web","slug":"web","permalink":"http://zshell.cc/categories/web/"}],"tags":[{"name":"ajax","slug":"ajax","permalink":"http://zshell.cc/tags/ajax/"},{"name":"jQuery","slug":"jQuery","permalink":"http://zshell.cc/tags/jQuery/"},{"name":"文件上传","slug":"文件上传","permalink":"http://zshell.cc/tags/文件上传/"}]},{"title":"logrotate 配置与运维","slug":"linux-varlog--logrotate配置与运维","date":"2018-01-14T16:23:27.000Z","updated":"2018-01-27T14:53:07.577Z","comments":true,"path":"2018/01/15/linux-varlog--logrotate配置与运维/","link":"","permalink":"http://zshell.cc/2018/01/15/linux-varlog--logrotate配置与运维/","excerpt":"本文主要讨论以下几个方面: logrotate 的关键配置文件和配置项语法; logrotate 的使用与运维技巧; logrotate 的运行原理; 特殊场景下 logrotate 的代替方案;","text":"本文主要讨论以下几个方面: logrotate 的关键配置文件和配置项语法; logrotate 的使用与运维技巧; logrotate 的运行原理; 特殊场景下 logrotate 的代替方案; 配置文件与配置语法logrotate 的配置文件主要是 /etc/logrotate.conf 和 /etc/logrotate.d 目录;/etc/logrotate.conf 文件作为主配置文件, include 了 /etc/logrotate.d 目录下具体的配置内容;以下是 /etc/logrotate.conf 的默认内容:123456789101112# 默认的历史日志保留周期单位: 周weekly# 历史日志保留四个周期单位, 即四周, 一个月rotate 4# use the syslog group by default, since this is the owning group of /var/log/syslog.su root syslog# 当旧日志作了 rotate 之后, 将会创建一个和旧日志同名的新文件create# 默认使用 gzip 压缩旧日志文件compress# 将 /etc/logrotate.d 下面的所有独立配置文件都 include 进来include /etc/logrotate.d /etc/logrotate.conf 的默认配置优先级比 /etc/logrotate.d/ 目录下的独立配置要低, /etc/logrotate.d 下所有的独立配置文件中的配置项可以覆盖 /etc/logrotate.conf;以 rsyslog 的配置文件为例, 以下是 /etc/logrotate.d/rsyslog 的内容:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/var/log/syslog &#123; # 以 天 为周期单位, 保留 7 天的日志 daily rotate 7 # 忽略任何错误, 比如找不到文件 missingok # not if empty, 当日志内容为空时, 不作 rotate notifempty # 压缩日志, 但是采用延时压缩, 即本轮周期产生的日志不压缩, 而在下一个周期时压缩之 compress delaycompress # postrotate/endscript 内的命令, 作为后处理, 会在本轮周期 rotate 之后回调执行 postrotate invoke-rc.d rsyslog rotate &gt; /dev/null endscript&#125;# 可以同时指定多个目标日志使用同一段配置/var/log/mail.info/var/log/mail.warn/var/log/mail.err/var/log/mail.log/var/log/daemon.log/var/log/kern.log/var/log/auth.log/var/log/user.log/var/log/lpr.log/var/log/cron.log/var/log/debug/var/log/messages &#123; weekly rotate 4 missingok notifempty compress delaycompress # 共享处理脚本, 仅对 prerotate/postrotate 定义时生效 sharedscripts postrotate invoke-rc.d rsyslog rotate &gt; /dev/null endscript&#125; 注意: sharedscripts 选项打开后, 所有使用该段配置作 rotate 的目标日志名都会作为参数一次性传给 prerotate/postrotate;而默认的选项 nosharedscripts 则是将每一个日志名分别作为参数传给 prerotate/postrotate; logrotate 支持的周期单位, 有 hourly, daily, weekly, monthly; 但是这里有坑: hourly 默认是不生效的, 具体原因见本文第三节; &nbsp;如上所叙, prerotate/postrotate 是一种在 rotate 过程中某个时机回调的一段脚本, 像这样类似的配置项总共有如下几种 (所有的配置项必须与 endscript 成对出现):1234567891011# 在所有匹配的日志 rotate 之前, 仅执行一次firstaction/endscript# 在日志 rotate 之前回调prerotate/endscript# 在日志 rotate 之后回调postrotate/endscript# 在所有匹配的日志 rotate 之后, 仅执行一次lastaction/endscript# 在某个日志将要被删除之前回调执行preremove/endscript 这几种回调时间点的设计, 不禁让人想到 junit 测试类几种注解的方法执行时机, 不得不说有异曲同工之妙;&nbsp;rsyslog 的 logrotate 配置是一个典型, 但同时 logrotate 还有着其他的个性化配置选项:1234567891011121314151617# 以下是另一段案例/var/log/test.log &#123; # 不以时间为周期单位, 而是以 日志size 为周期单位, 当日志大小达到 100MB 时, 作一次 rotate, 日志保留 5 个周期 size=100M rotate 5 # 使用日期命名 rotate 后的旧文件, 日期格式采用 -%Y-%m-%d dateext dateformat -%Y-%m-%d # 以指定的权限掩码, owner/group 创建 rotate 后的新文件 create 644 root root postrotate /usr/bin/killall -HUP rsyslogd endscript&#125; logrotate 命令的常用运维选项1.指定目标配置文件, 手动执行:1234# 将会执行 /etc/logrotate.d/ 下所有的配置logrotate /etc/logrotate.conf# 将会只执行指定配置文件中的配置logrotate /etc/logrotate.d/xxx.log 2.debug 验证配置文件正误:123456789# -d: --debug&gt; logrotate -d /etc/logrotate.d/redis-server.log# outputreading config file /etc/logrotate.d/redis-serverHandling 1 logsrotating pattern: /var/log/redis/redis-server*.log weekly (12 rotations)empty log files are not rotated, old logs are removedconsidering log /var/log/redis/redis-server.log log does not need rotating 3.强制 rotate:即便当前不满足 rotate 的条件, force rotate 也会强制作一次 rotate, 而那些超过指定轮数的旧日志将会被删除;force rotate 比较适用于加入了新的配置文件, 需要对其存量历史立即作一次 rotate;12# -f: --forcelogrotate -f /etc/logrotate.d/xxx.log 4.verbose 详细信息:12# -v: --verboselogrotate -vf /etc/logrotate.d/xxx.log 5.指定 logrotate 自身的日志文件路径:123# -s: --state# 默认 logrotate 的日志路径: /var/lib/logrotate/statuslogrotate -s /tmp/logrotate.log /etc/logrotate.conf logrotate 的运行原理及其缺陷logrotate 并不是一个 daemon service, 其本质上只是一个 ‘什么时候调用就什么时候立即执行一次’ 的 C 程序;所以 logrotate 的执行, 依赖于其他 daemon service 的调用, 那么最自然的就是通过 crond 定时任务来调用了;默认情况下, logrotate 是一天被调用一次的, 因为与它相关的 crontab 配置在 /etc/cron.daily 里:1234567891011121314#!/bin/sh# Clean non existent log file entries from status filecd /var/lib/logrotatetest -e status || touch statushead -1 status &gt; status.cleansed 's/\"//g' status | while read logfile datedo [ -e \"$logfile\" ] &amp;&amp; echo \"\\\"$logfile\\\" $date\"done &gt;&gt; status.cleanmv status.clean statustest -x /usr/sbin/logrotate || exit 0/usr/sbin/logrotate /etc/logrotate.conf 如本文第二节所述, 由于 logrotate 的执行方式是通过 cron 默认 1 天执行一次, 所以按小时 rotate 的 hourly 配置项, 默认是不生效的; logrotate 的 manual 文档里也有说明: hourly Log files are rotated every hour. Note that usually logrotate is configured to be run by cron daily. You have to change this configuration and run logrotate hourly to be able to really rotate logs hourly. 不过, 这还不是最大的问题, 毕竟我们只要把上述脚本放到 cron.hourly 里, 就能解决该问题;这种靠定时任务来运行的方式, 最大的问题是: 当我们对某个日志配置成按 size 来 rotate 时, 无法做到当日志触达 size 条件时及时切分, 其所能实现的最小延时是一分钟 (当把 logrotate 脚本的定时任务配成 * * * * *, 即每分钟执行一次时), 没法更短了; 其他的特殊场景logrotate 集日志切分, 日志压缩, 删除旧日志, 邮件提醒等功能为一体, 提供了非常完整的日志管理策略; 不过, 并不是所有的系统日志, 自身都不具有上述功能, 都需要依赖 logrotate 来管理自己;有一个非常典型, 而且使用十分广泛的场景: tomcat web 服务器; 当我们在 tomcat 上部署的服务使用了诸如 logback 之类的第三方日志框架时, 日志切分, 日志压缩等服务它自己便能够胜任了 (与 logback 相关功能的文章请见: logback appender 使用总结), 而且我们绝大部分人 (去哪儿网), 即便不怎么接触 logback 的日志压缩功能, 也至少都习惯于使用 logback RollingFileAppender 的基础功能去作日志切分;基于以上, 我们只需要一个简单的脚本, 便能够满足日常的 tomcat web 服务器日志运维:12345678#!/bin/bashHOUR1=$(date -d \"1 hours ago\" +%F-%H)DATE7=$(date -d \"7 days ago\" +%F-%H)# for example: /home/web/my_server/logsfor i in `find /home/web/ -maxdepth 2 \\( -type d -o -type l \\) -name logs`; do find -L $i -maxdepth 1 -type f \\( -name \"*$&#123;HOUR1&#125;*\" -a ! -name \"*.gz\" \\) -exec gzip &#123;&#125; \\; find -L $i -maxdepth 1 -type f \\( -name \"*$&#123;DATE7&#125;*\" -a -name \"*.gz\" \\) -exec rm -f &#123;&#125; \\;done 本节内容讨论的是针对 tomcat web 系统上的日志切分, 压缩, 以及删除等常规运维内容; 其实, 针对公司各业务线 web 系统的业务日志, 除此之外至少还有另外两项重要的运维内容: 日志冷备份收集 与 日志实时收集及其可视化 (ELK); 与之相关的内容请参见如下文章: 改造 flume-ng: 融入公司的技术体系; 日志冷备份收集的方案选型; 站内相关文章 cron 相关全梳理 logback appender 使用总结 改造 flume-ng: 融入公司的技术体系 日志冷备份收集的方案选型 参考链接 Linux日志文件总管——logrotate 被遗忘的 Logrotate","categories":[{"name":"linux","slug":"linux","permalink":"http://zshell.cc/categories/linux/"},{"name":"varlog","slug":"linux/varlog","permalink":"http://zshell.cc/categories/linux/varlog/"}],"tags":[{"name":"linux:varlog","slug":"linux-varlog","permalink":"http://zshell.cc/tags/linux-varlog/"}]},{"title":"财富先锋 2017 年各股池成绩单","slug":"证券-财富先锋--财富先锋2017年各股池成绩单","date":"2017-12-31T14:00:00.000Z","updated":"2018-01-27T14:53:07.581Z","comments":true,"path":"2017/12/31/证券-财富先锋--财富先锋2017年各股池成绩单/","link":"","permalink":"http://zshell.cc/2017/12/31/证券-财富先锋--财富先锋2017年各股池成绩单/","excerpt":"综合来看, 同花顺财富先锋 2017 年的几个股池系统的年度收益率还是比较令人满意的;‘热点轮动’, ‘股东增持’ 两个股池系统的收益率达到了 200%, ‘支撑压力’ 股池系统的收益率超过 150%;不过 ‘多头趋势’ 股池系统的表现比较糟糕, 2017 年净收益为负;另外还有 ‘深一度’ 股池系统的收益率未显示相关指标, 暂无法统计;各个股池系统 2017 年度收益率的指标, 反映出了各个选股策略在 2017 年 A 股市场上的成效; 以此为鉴, 2018 年的中国资本市场, 我们继续前行;","text":"综合来看, 同花顺财富先锋 2017 年的几个股池系统的年度收益率还是比较令人满意的;‘热点轮动’, ‘股东增持’ 两个股池系统的收益率达到了 200%, ‘支撑压力’ 股池系统的收益率超过 150%;不过 ‘多头趋势’ 股池系统的表现比较糟糕, 2017 年净收益为负;另外还有 ‘深一度’ 股池系统的收益率未显示相关指标, 暂无法统计;各个股池系统 2017 年度收益率的指标, 反映出了各个选股策略在 2017 年 A 股市场上的成效; 以此为鉴, 2018 年的中国资本市场, 我们继续前行; 支撑压力 2017 支撑压力 final review 热点轮动 2017 热点轮动 final review 股东增持 2017 股东增持 final review 多头趋势 2017 多头趋势 final review","categories":[{"name":"证券","slug":"证券","permalink":"http://zshell.cc/categories/证券/"},{"name":"财富先锋","slug":"证券/财富先锋","permalink":"http://zshell.cc/categories/证券/财富先锋/"}],"tags":[{"name":"证券:财富先锋","slug":"证券-财富先锋","permalink":"http://zshell.cc/tags/证券-财富先锋/"}]},{"title":"nginx module 使用总结: ngx_http_gzip_module","slug":"nginx-module--nginx_module_使用总结_ngx_http_gzip_module","date":"2017-12-21T07:13:33.000Z","updated":"2018-05-13T06:36:48.762Z","comments":true,"path":"2017/12/21/nginx-module--nginx_module_使用总结_ngx_http_gzip_module/","link":"","permalink":"http://zshell.cc/2017/12/21/nginx-module--nginx_module_使用总结_ngx_http_gzip_module/","excerpt":"ngx_http_gzip_module 是十分有用的 nginx 模块, 其有效压缩了 http 请求大小, 节省了流量, 加快了传输速度, 提升了用户体验;当然, 其在使用上也有一些坑, 本文将具体讨论一下相关内容;","text":"ngx_http_gzip_module 是十分有用的 nginx 模块, 其有效压缩了 http 请求大小, 节省了流量, 加快了传输速度, 提升了用户体验;当然, 其在使用上也有一些坑, 本文将具体讨论一下相关内容; ngx_http_gzip_module 这个模块的名字其实是 官方文档 里定义的; 然而在 nginx 源码里 (v1.11.2), 这个模块所在的源码文件名叫 src/http/ngx_http_gzip_filter_module.c; gzip 模块的安装ngx_http_gzip_module 编译默认安装, 无需额外操作; gzip 模块的配置gzip 模块的配置可以在如下位置: nginx.conf 中的 http 指令域下; 某个具体 vhost.conf 配置下的 server 指令域下; 某个具体 server 指令下的 location 指令域下; 123456789101112131415161718192021static ngx_command_t ngx_http_gzip_filter_commands[] = &#123; &#123; ngx_string(\"gzip\"), NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF|NGX_HTTP_LIF_CONF |NGX_CONF_FLAG, ngx_conf_set_flag_slot, NGX_HTTP_LOC_CONF_OFFSET, offsetof(ngx_http_gzip_conf_t, enable), NULL &#125;, &#123; ngx_string(\"gzip_buffers\"), NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF|NGX_CONF_TAKE2, ngx_conf_set_bufs_slot, NGX_HTTP_LOC_CONF_OFFSET, offsetof(ngx_http_gzip_conf_t, bufs), NULL &#125;, ...... ngx_null_command&#125;; 以上代码片段列举了 gzip 指令与 gzip_buffers, 其余的指令与 gzip_buffers 在使用上下文设置上基本相同, 都是 NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF;从源码中可以看出, 在 gzip 模块里, gzip 指令相比其他指令有一个特别的地方: 除了 http, server, location 之外, 还有一个地方可以使用 gzip 指令, NGX_HTTP_LIF_CONF, 即 location 指令域中的 if 配置下; 以下是一个典型完整的 gzip 配置:1234567891011121314151617181920212223242526272829# 开启/关闭, 默认 offgzip on | off;# 当 response header 中包含 Via 头信息时, 根据 request header 中某些头信息决定是否需要开启 gzip, 默认 offgzip_proxied off | expired | no-cache | no-store | private | no_last_modified | no_etag | auth | any;# 根据 User-Agent 的值匹配, 针对部分请求不使用 gzip, 比如老旧的 IE6gzip_disable \"msie6\";# 在 response header 中添加 Vary: Accept-Encoding, 告诉 cache/cdn 同时缓存 压缩与非压缩两种版本的 response, 默认 offgzip_vary on | off;# 使用 gzip 的最小 size, size 值取决于 Content-length 的值, 默认 20 bytesgzip_min_length 1k;# 用于 gzip 压缩缓冲区的 num 与 size# 建议 num 为 cpu 核心数, size 为 cpu cache page 大小gzip_buffers 32 8k;# 支持 gzip 模块的最低 http 版本, 默认 1.1gzip_http_version 1.0;# gzip 压缩级别, [1-9], 默认 1, 级别越高, 压缩率越高, 同时消耗的 cpu 资源越高gzip_comp_level 1;# 针对哪些 Content-type 使用 gzip, 默认是 text/html# text/html 不需要设置到 gzip_types 中, 在其他条件满足时, text/html 会自动被压缩# 若设置了 text/html 反而会输出 warn gzip_types text/css application/javascript application/json; gzip 模块实践中遇到的坑(1) gzip_comp_level 级别的选择在 stackoverflow 上的一个问题 里曾讨论到, gzip_comp_level 压缩级别, 虽然其越高压缩率越高, 但是压缩边际提升率在 level = 1 之后却是在下降的:1234567891011121314151617181920212223# 针对 text/html0 55.38 KiB (100.00% of original size)1 11.22 KiB ( 20.26% of original size)2 10.89 KiB ( 19.66% of original size)3 10.60 KiB ( 19.14% of original size)4 10.17 KiB ( 18.36% of original size)5 9.79 KiB ( 17.68% of original size)6 9.62 KiB ( 17.37% of original size)7 9.50 KiB ( 17.15% of original size)8 9.45 KiB ( 17.06% of original size)9 9.44 KiB ( 17.05% of original size)# 针对 application/x-javascript0 261.46 KiB (100.00% of original size)1 95.01 KiB ( 36.34% of original size)2 90.60 KiB ( 34.65% of original size)3 87.16 KiB ( 33.36% of original size)4 81.89 KiB ( 31.32% of original size)5 79.33 KiB ( 30.34% of original size)6 78.04 KiB ( 29.85% of original size)7 77.85 KiB ( 29.78% of original size)8 77.74 KiB ( 29.73% of original size)9 77.75 KiB ( 29.74% of original size) 随着压缩级别的提高, 更高的 cpu 消耗却换不来有效的压缩提升效率; 所以 gzip_comp_level 的最佳实践是将其设为 1, 便足够了;&nbsp; (2) gzip_min_length 的陷阱一般经验上, 我们会将 gzip_min_length 设置为 1KB, 以防止 response size 太小, 压缩后反而变大;只是, ngx_http_gzip_module 取决于 response headers 里的 Content-length; 如果 response 里面有这个 header, 那没有任何问题, 但是如果 response 里面没这个 header, gzip_min_length 设置就失效了;这种情况其实并不少见: Transfer-Encoding: chunked; 参考链接 Module ngx_http_gzip_module nginx の gzip 使用 加速nginx: 开启gzip和缓存 标头 “Vary:Accept-Encoding” 指定方法及其重要性分析 What is the best nginx compression gzip level 关于 nginx 配置文件 gzip 的配置问题: 不太明白这个 gzip_proxied 的作用是什么, 应该如何正确配置","categories":[{"name":"nginx","slug":"nginx","permalink":"http://zshell.cc/categories/nginx/"},{"name":"module","slug":"nginx/module","permalink":"http://zshell.cc/categories/nginx/module/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://zshell.cc/tags/nginx/"},{"name":"nginx:module","slug":"nginx-module","permalink":"http://zshell.cc/tags/nginx-module/"}]},{"title":"apache benchmark 使用笔记","slug":"linux-other--apache_benchmark_使用笔记","date":"2017-11-25T12:41:55.000Z","updated":"2018-08-18T03:00:51.949Z","comments":true,"path":"2017/11/25/linux-other--apache_benchmark_使用笔记/","link":"","permalink":"http://zshell.cc/2017/11/25/linux-other--apache_benchmark_使用笔记/","excerpt":"各个公司或多或少都在推出自己的压力测试工具, 形形色色, 种类繁多; 其实, 在开源世界已经有了一个经典成熟的压力测试工具 —- apache benchmark;小巧, 简单, 基于 http 的普适性, 这些都是 apache benchmark 被广泛使用的原因;","text":"各个公司或多或少都在推出自己的压力测试工具, 形形色色, 种类繁多; 其实, 在开源世界已经有了一个经典成熟的压力测试工具 —- apache benchmark;小巧, 简单, 基于 http 的普适性, 这些都是 apache benchmark 被广泛使用的原因; apache benchmark, 其对应的命令被简称为 ab, 是 httpd-tools 里使用最广泛的工具; httpd-tools 安装直接用 yum install ab 是找不到软件包的, 因为 ab 并没有单独提供, 而是封装在 httpd-tools 里面;1sudo yum install -y httpd-tools 安装完后, httpd-tools 提供的系列工具如下:1234567apache benchmarkhtdbmhtdigesthtpasswordhttxt2dbmlogresolve 后面的 5 个工具, 都是与 apache 服务器相关的辅助工具, 一旦脱离了 apache server 则作用有限; 但是 apache benchmark 却不一样, 虽然它本来的设计目的也是为了压测 apache server, 但既然是 http 请求, 那么大部分 web server 都可以使用其作压力测试; ab 的使用方法1234567891011121314151617# 最简单使用: -c concurrency 并发数; -n requests 请求数量ab -n 10000 -c 100 $&#123;target_url&#125;# post 请求: -p 指定需要 post 的数据文件, -T 指定 content-typeab -n 10000 -c 100 -p params.file -T 'application/x-www-form-urlencoded' $&#123;target_url&#125;# -s: timeout, 单位为秒ab -n 10000 -c 100 -s 20 $&#123;target_url&#125;# -t: timelimit, 指定本次压测的最长时间限制# 如果不指定 -n, 这里还会默认指定一个 -n 50000ab -c 100 -s 20 -t 60000 $&#123;target_url&#125;# -r: 当发生 socket error 时不退出, 而是继续执行请求# -k: 在 http 请求的 headers 中加上 Connection: keep-alive, 以保持连接 ab -n 10000 -c 100 -r -k $&#123;target_url&#125;# 将压测数据记录为 gunplot 可以分析的 dump 文件, 以供其渲染ab -n 10000 -c 100 -g data.plt $&#123;target_url&#125; ab 的输出分析顺利完成测试任务的输出12345678910111213# 部分 version, licene 信息已省略&gt; ab -n 100 -c 10 http://www.baidu.com/......Server Software: BWS/1.1Server Hostname: www.baidu.comServer Port: 80Document Path: /Document Length: 111488 bytesConcurrency Level: 10Time taken for tests: 2.055 secondsComplete requests: 100 这里有一个需要注意的地方: failed requests;ab 请求失败的原因分为几类: Connect: tcp 连接错误, 属于网路问题; Length: http response 的 Content-Length 与第一次接收的值不一致, 这种属于业务问题, 并不能严格将其归为失败; Exceptions: 服务器端异常, 一般 status code 为 5XX; 不过, 如果返回客户端错误 4XX, ab 不会判定为 failed requests, 这里需要注意; 1Failed requests: 89 (Connect: 0, Receive: 0, Length: 89, Exceptions: 0) 如上所示, 像 baidu.com 这种属于动态网页, 每次返回的内容长度不固定, 所以大量请求被 ab 判定为 failed requests;类似这种情况的场景很多, 所以这就提醒我们在使用 ab 作压力测试时, 构造的 mock 接口一定要能够返回固定长度的内容, 而被测试接口的返回内容校验, 应该放在 mock 接口内部逻辑中实现; 一旦校验失败, 不要在返回内容上作标记, 而是直接抛出异常, 以让 ab 识别为 failed requests; 1234567Write errors: 0Total transferred: 11320607 bytesHTML transferred: 11223796 bytesRequests per second: 48.65 [#/sec] (mean)Time per request: 205.533 [ms] (mean)Time per request: 20.553 [ms] (mean, across all concurrent requests)Transfer rate: 5378.84 [Kbytes/sec] received 传输各个阶段的统计指标:1234567Connection Times (ms)# 最短时间 平均时间 标准差 中位数时间 最长时间 min mean [+/-sd] median maxConnect: 36 38 0.8 38 39Processing: 113 154 14.5 152 198Waiting: 37 39 1.0 39 42Total: 150 192 14.7 190 237 最后是 rt 响应时间的分位数统计:12345678910Percentage of the requests served within a certain time (ms) 50% 190 66% 192 75% 194 80% 195 90% 198 95% 230 98% 234 99% 237 100% 237 (longest request) 测试被迫终止以上是一个顺利完成压测任务的输出; 有的时候压力测试并不会很顺利得结束, 如果压得比较猛, 可能待测服务会发生各种问题, 这时 ab 就有可能被迫提前终止任务;情况一 tcp connection error12apr_socket_recv: Connection timed out (110)apr_socket_recv: Connection reset by peer (104) 当 ab 遇到 connection error 时默认会直接 exit; 此时可以使用 -r 选项: -r Don’t exit on socket receive errors. 这样 ab 就不会在遇到 connection error 时退出了; 但这有时并不能从根本上解决问题, 比如在某些高并发环境下, 待测服务所在的系统内核开启了 SYN flood 攻击保护, 故意拖慢了请求速度, 造成 connection error, 这可能会导致所有的请求都失败, 从而失去了压测意义; 这种情况下, 往往需要调整内核参数, 关闭一些安全保护:12# 关闭洪流攻击保护net.ipv4.tcp_syncookies = 0 &nbsp;情况二 tcp read/write error1apr_pollset_poll: The timeout specified has expired (70007) 以上输出反映了 ab 在测试途中遇到了 read/write timeout, 请求服务超过了选项 -s 设置的 timeout 时间; 这其实是一个不合理的设计, 一个请求超时是很正常的事情, 但是它一遇到超时就直接 exit, 这就让使用者不爽了, 它完全可以放到最后的统计里面的;但是除非你修改 ab 的 source code 重新编译, 否则对于这种错误你也只能是修改 -s 增大超时时间了; 一个典型的使用实践光说不练肯定是不行的, 这里正好有一个比较系统性地压力测试报告, 其将 apache benchmark 作为了一个主要的分析工具, 可以分享一下: berkeley db 7.x 压力测试报告; 其他类似工具有一个与 ab 类似的开源 http 压力测试工具: wrk - a HTTP benchmarking tool, 在 github 上也获得了 1.7 万的 stars;wrk 与 ab 的类似之处在于它们都是基于 http 的命令行工具, 通过命令选项控制压测条件; 但是 wrk 在某种程度上只能算是 ab 的一个子集:wrk 只能通过给定一个确定的压测时间限制, 在给定的时间内以给定的并发度请求, 当时间到了, 压力测试结束, 其并不能设置请求多少次后结束测试;另外, wrk 的输出与 ab 也不太相同:1234567891011Running 30s test @ http://127.0.0.1:8080/index.html 12 threads and 400 connections Thread Stats Avg Stdev Max +/- Stdev Latency 635.91us 0.89ms 12.92ms 93.69% Req/Sec 56.20k 8.07k 62.00k 86.54% 22464657 requests in 30.00s, 17.76GB read Requests/sec: 748868.53Transfer/sec: 606.33MB 相比 ab 的报告略显简洁, 只能说是见仁见智吧; 站内相关文章 berkeley db 7.x 压力测试报告 参考链接 Package httpd-tools Apache Benchmark安装、参数含义&amp;使用总结、结果分析 ab输出信息解释以及Failed requests原因分析 apachebench(ab)压测遇到问题的解决方案记录 ab - Apache HTTP server benchmarking tool apache ab压力测试报错 (apr_socket_recv: Connection reset by peer (104))","categories":[{"name":"linux","slug":"linux","permalink":"http://zshell.cc/categories/linux/"},{"name":"other","slug":"linux/other","permalink":"http://zshell.cc/categories/linux/other/"}],"tags":[{"name":"linux:perf","slug":"linux-perf","permalink":"http://zshell.cc/tags/linux-perf/"},{"name":"linux:other","slug":"linux-other","permalink":"http://zshell.cc/tags/linux-other/"}]},{"title":"sysvinit / systemd 命令使用与对比","slug":"linux-init--sysvinit_systemd命令使用与对比","date":"2017-11-12T09:18:06.000Z","updated":"2018-04-23T15:34:44.269Z","comments":true,"path":"2017/11/12/linux-init--sysvinit_systemd命令使用与对比/","link":"","permalink":"http://zshell.cc/2017/11/12/linux-init--sysvinit_systemd命令使用与对比/","excerpt":"当用户空间引导程序 systemV init 被 systemd 所取代, centos 7 下操纵与查看 daemon service 的命令也随之而改变;不过, 由于 systemd 的庞大复杂, 命令选项繁多, 本文对 systemd 的整理主要集中于与 sysvinit 所提供的功能重合度最高的 systemctl 命令;","text":"当用户空间引导程序 systemV init 被 systemd 所取代, centos 7 下操纵与查看 daemon service 的命令也随之而改变;不过, 由于 systemd 的庞大复杂, 命令选项繁多, 本文对 systemd 的整理主要集中于与 sysvinit 所提供的功能重合度最高的 systemctl 命令; 传统的 sysvinit 相关命令与传统的 systemV init 引导程序相匹配的 daemon service 操纵命令主要是 service 与 chkconfig/ntsysv;其中:service 命令用于 启, 停, 查看 具体的 daemon service;chkconfig 命令用于 修改, 查看 具体 daemon service 的 runlevel 及启停信息;ntsysv 命令提供了一个 GUI 界面用于操纵各个 runlevel 上各 daemon service 的启停; service 的使用方式12345# 启动, 停止, 重启, 查看sudo service ntpd startsudo service ntpd stopsudo service ntpd restartsudo service ntpd status chkconfig 的使用方式123456789101112131415# 列举所有的 daemon service 在各个 runlevel 上的启停状态sudo chkconfig --list# 列举指定的 daemon service 在各个 runlevel 上的启停状态&gt; sudo chkconfig --list ntpdntpd 0:on 1:on 2:on 3:on 4:on 5:on 6:off# 添加一个 daemon servicesudo chkconfig --add mysqld# 在默认的 2, 3, 4, 5 四个 runlevel 上自动启动 mysqldsudo chkconfig mysqld on# 在指定的 3, 5 两个 runlevel 上自动启动 mysqldsudo chkconfig --level 35 mysqld on# 删除一个 daemon servicesudo chkconfig --del rngd ntsysv 的使用方式ntsysv 在 centos 7 之前的各发行版本上都默认安装, 不过从 centos 7 之后, 该命令的 GUI 形式已经不再默认提供, 只提供了 chkconfig 命令用于兼容照顾老的 systemV init 方式;1234# 默认情况下 ntsysv 配置的是当前 user session 所在的 runlevelsudo ntsysv# 配置 runlevel = 5 的 daemon servicesudo ntsysv --level 5 主流的 systemd 相关命令systemd 相比 sysvinit 就要复杂多了, 同时也比 sysvinit 强大多了;systemd 相比 sysvinit 更强大的其中一个重要点是, systemd 不仅仅管理系统中的各进程, 它管理 linux 系统中的所有资源, 并把不同的资源称为 unit:123456789101112service unit: 系统服务target unit: 多个 unit 构成的一个组device unit: 硬件设备mount unit: 文件系统的挂载点automount unit: 自动挂载点path unit: 文件或路径scope unit: 不是由 systemd 启动的外部进程slice unit: 进程组snapshot unit: systemd 快照, 可以切回某个快照socket unit: 进程间通信的 socketswap unit: swap 文件timer unit: 定时器, 可与 crond 相对比, 可圈可点 其中, service unit 在 12 类 unit 中是最主要的一类, 也是日常操作中最频繁接触的一类, 当然也是与传统的 sysvinit 可以直接比较的对象;另外, systemd 里另外一个比较有意思的是 timer unit, 关于此的详细内容可以参见: systemd 的定时器功能;&nbsp;systemd 主要涉及到的命令有: systemctl, hostnamectl, localectl, timedatectl, loginctl, journalctl 等, 其中: systemctl 是最重要的命令, 最核心的操作都与此命令有关, 比如启停服务, 管理各 unit 等; hostnamectl 用于管理主机信息等; localectl 用于本地化设置管理; timedatectl 用于时区管理; loginctl 用于管理当前登录的用户; journalctl 用于管理 systemd 与各 unit 的输出日志, 用于辅助其余命令查看状态与日志; &nbsp;本主要整理与 systemctl 有关的内容, 其余的如 timedatectl, journalctl 请参见另一篇文章: sysvinit / systemd 日志系统的使用与对比; systemctl 的常用命令列表systemctl 的使用场景十分广泛, 从大的角度来说, 可以分为 系统管理 和 unit 管理 两大类;系统管理类的命令如下:1234567891011121314# 重启系统sudo systemctl reboot# 关闭系统, 切断电源sudo systemctl poweroff# CPU 停止工作sudo systemctl halt# 暂停系统sudo systemctl suspend# 让系统进入冬眠状态sudo systemctl hibernate# 让系统进入交互式休眠状态sudo systemctl hybrid-sleep# 启动进入救援状态 (单用户状态, runlevel = 1)sudo systemctl rescue unit 管理类 的命令种类繁多, 大致可以再细分为两小类: 查看管理类 与 操纵动作类;查看管理类仅仅是统计与查看, 并不改变 unit 的状态:(1) 从整体角度管理 units12345678910# 默认列出正在运行的 unitsudo systemctl list-units# 列出所有 unit, 包括没有找到配置文件的或者启动失败的sudo systemctl list-units --all# 列出所有没有运行的 unitsudo systemctl list-units --all --state=inactive# 列出所有加载失败的 unitsudo systemctl list-units --failed# 列出所有正在运行的, 类型为 service 的 unit; -t: --typesudo systemctl list-units --type=service (2) 管理具体的某个 unit12345678910111213141516# 显示某个 unit 的状态sudo systemctl status rsyslog.service# 显示某个 unit 是否正在运行sudo systemctl is-active rsyslog.service# 显示某个 unit 是否处于启动失败状态sudo systemctl is-failed rsyslog.service# 显示某个 unit 服务是否建立了启动链接sudo systemctl is-enabled rsyslog.service# 显示某个 unit 的启动是否依赖其他 unit 的启动, --all 展开所有 target unit 下的每一个详细 unitsudo systemctl list-dependencies --all rsyslog.service# 显示某个 unit 的所有底层参数sudo systemctl show rsyslog.service# 显示某个 unit 的指定属性的值sudo systemctl show -p CPUShares rsyslog.service 操纵动作类, 主要是针对 service unit:123456789101112131415# 设置为开机启动sudo systemctl enable nginx.service# 启动sudo systemctl start nginx.service# 停止sudo systemctl stop nginx.service# 重启sudo systemctl restart nginx.service# 杀死一个服务的所有子进程sudo systemctl kill nginx.service# 重新加载一个服务的配置文件sudo systemctl reload nginx.service# 设置某个 unit 的指定属性sudo systemctl set-property nginx.service CPUShares=500 systemctl 的状态与诊断使用 systemctl status 输出服务详情状态:12345678910111213141516# Loaded: 该 unit 配置文件的位置以及是否开机启动# Active: 运行状态# Main PID: 父进程 pid# CGroup: 所有的子进程列表# 最后是 service 的日志&gt; sudo systemctl status rsyslog.service● rsyslog.service - System Logging Service Loaded: loaded (/usr/lib/systemd/system/rsyslog.service; enabled; vendor preset: enabled) Active: active (running) since Wed 2017-07-19 16:01:19 CST; 6 months 10 days ago Main PID: 504 (rsyslogd) CGroup: /system.slice/rsyslog.service └─504 /usr/sbin/rsyslogd -nJul 19 16:01:19 localhost.localdomain systemd[1]: Starting System Logging Service...Jul 19 16:01:19 localhost.localdomain systemd[1]: Started System Logging Service. 使用 journalctl 查看日志:12345678910# 指定查看某个 unit 的日志sudo journalctl -u nagios# 指定时间范围 --since= --until=sudo journalctl -u nagios -S \"2017-04-19 09:00:00\"sudo journalctl -u nagios -S \"2 days ago\"sudo journalctl -u nagios -U \"2017-12-31 23:59:59\"# 指定某次启动后的所有日志sudo journalctl -u nagios -b [-0] # 当前启动后sudo journalctl -u nagios -b -1 # 上次启动后sudo journalctl -u nagios -b -2 # 继续往上追溯 关于 journalctl 的详细内容, 请参见另外一篇文章: sysvinit / systemd 日志系统的使用与对比; 站内相关文章 sysvinit/systemd/upstart 初始化过程梳理 systemd 的定时器功能 systemd 相关配置文件整理 sysvinit / systemd 日志系统的使用与对比 参考链接 Linux下chkconfig命令详解 ntsysv命令 CentOS 7 启动, 重启, chkconfig 等命令已经合并为 systemctl RHEL 7 中 systemctl 的用法 (替代service 和 chkconfig) Systemd 入门教程: 命令篇 systemctl 命令完全指南","categories":[{"name":"linux","slug":"linux","permalink":"http://zshell.cc/categories/linux/"},{"name":"init","slug":"linux/init","permalink":"http://zshell.cc/categories/linux/init/"}],"tags":[{"name":"linux:init","slug":"linux-init","permalink":"http://zshell.cc/tags/linux-init/"},{"name":"systemd","slug":"systemd","permalink":"http://zshell.cc/tags/systemd/"}]},{"title":"bash 结束死循环的方法","slug":"linux-shell--bash结束死循环的方法","date":"2017-11-04T16:00:00.000Z","updated":"2018-06-16T05:08:39.512Z","comments":true,"path":"2017/11/05/linux-shell--bash结束死循环的方法/","link":"","permalink":"http://zshell.cc/2017/11/05/linux-shell--bash结束死循环的方法/","excerpt":"linux 中有很多实用的工具, 采用了这样一种工作方式:定时执行(1/s, 1/3s 等)一次指定逻辑, 当用户按下 ctrl + c 发出 SIGINT 信号时, 结束进程; 如果接收不到 SIGINT/SIGTERM 等信号, 进程则会一直执行下去;类似的工具包括 iostat, dstat, jstat 等;本文整理了实现上述逻辑的一些典型方法;","text":"linux 中有很多实用的工具, 采用了这样一种工作方式:定时执行(1/s, 1/3s 等)一次指定逻辑, 当用户按下 ctrl + c 发出 SIGINT 信号时, 结束进程; 如果接收不到 SIGINT/SIGTERM 等信号, 进程则会一直执行下去;类似的工具包括 iostat, dstat, jstat 等;本文整理了实现上述逻辑的一些典型方法; 一次偶然的机会, 我不小心写了一个 bash 脚本, 在一个 while 1 循环里调用一个命令; 结果执行的时候发现, 我按下 ctrl + c, 只结束了循环内的命令, 但结束不了 while 循环本身, 造成了该脚本停不下来了, 最后不得不打开另一个终端 kill 掉它;这个事情突然引起了我的兴趣, 于是我总结了一下 bash 结束 while 1 死循环的几种方法; 方法1: 监听命令返回值根据 GNU 相关规范, 如果一个进程是由于响应信号 signal 而终止, 其返回码必须是 128 + signal_number;那么, 可以通过判断其返回码 $? 是否大于 128 而判断 COMMAND 是否响应了信号;1234while [ 1 ]; do COMMAND test $? -gt 128 &amp;&amp; breakdone 更精确的, 如果只想判断 COMMAND 是否响应了 SIGINT 信号, 可以直接判断:12# SIGINT = 2, 128 + SIGINT = 130test $? -eq 130 &amp;&amp; break 特殊的情况下, COMMAND 忽略了 SIGINT 信号, 可以使用 -e 选项强制其响应 SIGINT 信号:1234while [ 1 ]; do COMMAND -e test $? -gt 128 &amp;&amp; breakdone 方法2: 命令返回值短路方法2 是方法1 的简化版本:123while [ 1 ]; do COMMAND -e || breakdone 其本质是监听 COMMAND 的返回值 $? 是否为 0, 如果是 0, 那么 break 中断命令就被短路了; 如果是非 0, 便会执行 break, 跳出死循环;这种方法巧妙得使用 || 逻辑运算符简化了代码, 但是有一个缺陷: 当 COMMAND 并非因为响应 ctrl + c 而是其他错误返回了非 0 的状态时, 循环也会结束;这是方法2 相比 方法1 略显不精准的地方; 方法3: 使用 trap 捕获信号12345# 捕获到 SIGINT 即 exit 0 正常退出trap &quot;exit 0&quot; SIGINTwhile [ 1 ]; do COMMAND -edone 方法4: 使用 ctrl + z 配合 SIGTERM 信号当命令运行在前台, 使用 ctrl + z 挂起进程, 会得到以下输出:12345678910# ^Z[1]+ Stopped COMMAND# 1 是挂起进程的作业号(job number), kill [job_number] 会向该作业发送 SIGTERM 信号kill %1# 发送 SIGTERM 信号给最近一次被挂起的进程kill %%# 执行的结果[1]+ Terminated COMMAND 方法5: 使用 -e 选项使用 set -e, 开启命令返回码校验功能, 一旦 COMMAND 返回非 0, 立即结束进程;12345#!/bin/bashset -ewhile [ 1 ]; do COMMAND -edone 或者作为 bash 的参数:1234#!/bin/bash -ewhile [ 1 ]; do COMMAND -edone 参考链接 Terminating an infinite loop 3.7.5 Exit Status How to stop the loop bash script in terminal Unix/Linux 脚本中 “set -e” 的作用","categories":[{"name":"linux","slug":"linux","permalink":"http://zshell.cc/categories/linux/"},{"name":"shell","slug":"linux/shell","permalink":"http://zshell.cc/categories/linux/shell/"}],"tags":[{"name":"linux:shell","slug":"linux-shell","permalink":"http://zshell.cc/tags/linux-shell/"}]},{"title":"ulimit 调参与优化","slug":"linux-conf--ulimit调参与优化","date":"2017-10-28T15:23:05.000Z","updated":"2018-06-16T12:13:31.522Z","comments":true,"path":"2017/10/28/linux-conf--ulimit调参与优化/","link":"","permalink":"http://zshell.cc/2017/10/28/linux-conf--ulimit调参与优化/","excerpt":"ulimit 未正确设置是很多线上故障的根源:Too many open files;java.lang.OutOfMemoryError: unable to create new native thread;对于生产环境来说, ulimit 的调参优化至关重要;本文详细介绍并梳理一下与 ulimit 相关的林林总总;","text":"ulimit 未正确设置是很多线上故障的根源:Too many open files;java.lang.OutOfMemoryError: unable to create new native thread;对于生产环境来说, ulimit 的调参优化至关重要;本文详细介绍并梳理一下与 ulimit 相关的林林总总; ulimit 是 linux 对于每个通过 PAM 登录的用户 ( 每个进程 ) 的资源最大使用限制的设置;注意, 这里仅仅对通过 PAM 登陆的用户起作用, 而对于那些随系统启动而启动的 daemon service, ulimit 是不会去限制其资源使用的;在 /etc/security/limits.conf 文件中的第一段注释如下: This file sets the resource limits for the users logged in via PAM.It does not affect resource limits of the system services. 关于 linux PAM 相关的内容, 可以前往另外一篇文章: pam 认证与配置; ulimit 基本信息123456789101112131415161718# 查看所有 ulimit 设置&gt; ulimit -acore file size (blocks, -c) 0data seg size (kbytes, -d) unlimitedscheduling priority (-e) 0file size (blocks, -f) unlimitedpending signals (-i) 15018max locked memory (kbytes, -l) 64 # 每个进程可以锁住而不被 swap 出去的内存max memory size (kbytes, -m) unlimited # 每个进程可使用的最大内存大小open files (-n) 1024 # 每个进程可打开的文件数pipe size (512 bytes, -p) 8POSIX message queues (bytes, -q) 819200real-time priority (-r) 0stack size (kbytes, -s) 8192 # 每个进程可使用的最大堆栈大小cpu time (seconds, -t) unlimitedmax user processes (-u) 4096 # 每个用户的最大进程数virtual memory (kbytes, -v) unlimitedfile locks (-x) unlimited ulimit 需要优化的场景及待优化参数linux 默认的 ulimit 限制, 是出于安全考虑, 设置的有些保守; 实际的生产环境下, 往往需要对其作出适当的调整, 方可发挥机器的最大性能; 场景1: tomcat web 容器 一台 4C4G60G 的标准虚拟主机, 其上部署了一个 tomcat 实例, 启动 catalina 进程的是 tomcat:tomcat 用户;如果该服务是一个网络 IO 密集的应用, 需要打开的 socket file 远不止 1024, ulimit 设置的 max open files 就会限制其性能; 另外, 该主机只部署了这一个服务, tomcat 用户是唯一一个需要占用大量资源的用户, ulimit 对单个用户的限制便会造成机器资源闲置, 极低的使用率, 降低 web 服务的性能;所以, 可以对该机器的 ulimit 作出如下调整:1231. max memory size -&gt; unlimit2. open files -&gt; 655363. stack size -&gt; unlimit 另外, 我们还遇到一种特殊的情况, 用标准配置虚拟机跑 dubbo 的服务治理: 当时发现, 如果服务注册到 zookeeper 的数量达到一定级别, 线上就会报 java.lang.OutOfMemoryError: unable to create new native thread 的异常;最后确定问题的原因是 ulimit -u max user processes 的数量配置过低, 增大后解决问题:14. max user processes -&gt; 65535 具体的情况可以参见这篇文章: dubbo 服务治理系统设计; 场景2: elasticsearch data node32C64G4T 的配置, 为确保指针压缩特性被打开, 一般我们都会控制 jvm 的最大堆内存与最小堆内存: ‘-Xmx30g -Xms30g’, 并希望能锁住所有的内存, 避免堆内存被 swap 到磁盘, 降低了搜索性能; 这种场景下我们当然不希望 ulimit 限制了 max memory size 以及 max locked memory;所以, 可以对该机器的 ulimit 作出如下调整:12341. max locked memory -&gt; unlimit2. max memory size -&gt; unlimit3. open files -&gt; 655364. stack size -&gt; unlimit 对于 max locked memory, elasticsearch.yml 本身有一个配置项 bootstrap.mlockall/bootstrap.memory_lock = true, 其背后实现就是通过类似于 ulimit -l unlimit 的方法完成的; 只是, elasticsearch 试图自己主动改变该配置能生效的前提, 是 ulimit 配置文件里要允许其这样设置, 具体的逻辑请看本文下下节: #ulimit 的永久修改; &nbsp;另外, 还有其他的一些场景, 可能需要调整其他参数以作优化, 此处不一而论;以上是需要调整 ulimit 参数的场景举例, 下面的内容是关于如何 临时/永久 修改 ulimit 设置; ulimit 当前 session 下的临时修改ulimit 的临时调整, 只对当前 session 下的当前用户, 以及当前用户所起的进程生效;其调整方法也已经在 ulimit -a 中被注明了:123456789# max locked memulimit -l unlimit# max mem sizeulimit -m unlimit# open filesulimit -n 65536# max user processesulimit -u 65536... ulimit 的永久修改上一节的方法, 只能在当前 session 下对当前用户作临时调整, 而 要想对 ulimit 作永久调整, 需要修改一些配置文件: /etc/security/limits.conf; /etc/security/limits.d 目录; 这些文件用于持久化每个用户的资源限制设置;其中, /etc/security/limits.conf 自不必说, 这是配置 ulimit 的主要文件:1234567891011121314151617181920212223242526272829303132domain 限制的目标: username 用户名; @groupname 组名, 需加 '@' 前缀; * 通配所有用户/组; %groupname 这种写法只能用于限制 某个 group 的 maxlogin limit, 即最大登陆用户数限制; type 限制的属性: `soft` 对 domain 给出的用户设置默认值; `hard` 限制 domain 给出的用户自己所能设置的最大值; `-` 将 soft 与 hard 都设为相同的值; item 限制的资源类型, 与 ulimit 所限制的资源类型大致相同: - core - limits the core file size (KB) - data - max data size (KB) - fsize - maximum filesize (KB) - memlock - max locked-in-memory address space (KB) - nofile - max number of open file descriptors - rss - max resident set size (KB) - stack - max stack size (KB) - cpu - max CPU time (MIN) - nproc - max number of processes - as - address space limit (KB) - maxlogins - max number of logins for this user - maxsyslogins - max number of logins on the system - priority - the priority to run user process with - locks - max number of file locks the user can hold - sigpending - max number of pending signals - msgqueue - max memory used by POSIX message queues (bytes) - nice - max nice priority allowed to raise to values: [-20, 19] - rtprio - max realtime priorityvalue 限制的具体值; 以下是一个具体的例子:1234567#&lt;domain&gt; &lt;type&gt; &lt;item&gt; &lt;value&gt;* soft nproc 65536* hard nproc 65536* - nofile 65536%guest - maxlogins 10elastic - memlock unlimit@dev hard fsize 10737418240 如上所示, 系统允许 elastic 用户的最大 memlock 为 unlimit, 如果这个值被设置为了一个比较小的值, 那么上上节 elasticsearch 试图将其改成 unlimit 便会失败; &nbsp;而对于 /etc/security/limits.d 目录的作用, /etc/security/limits.conf 文件中的第二段与第三段有如下注释: Also note that configuration files in /etc/security/limits.d directory,which are read in alphabetical order, override the settings in thisfile in case the domain is the same or more specific.&nbsp;That means for example that setting a limit for wildcard domain herecan be overriden with a wildcard setting in a config file in thesubdirectory, but a user specific setting here can be overriden onlywith a user specific setting in the subdirectory. 也就是说, limits.conf 配置文件, 可以在用户级别上被 limits.d 目录下的配置文件覆盖;举一个例子, 在 redhat/centos 各发行版本中, limits.d 目录下就有一个文件 20-nproc.conf:12345# Default limit for number of user's processes to prevent# accidental fork bombs.# See rhbz #432903 for reasoning.* soft nproc 4096root soft nproc unlimited 这里面对除了 root 用户之外的所有用户作了一个最大进程/线程数目的 soft 限制;如果修改 limits.conf 文件:1* hard nproc 65535 这时会发现, 除非自己试图 ulimit -u 修改 max processes, 否则这个值会依然被限制为 4096;而要想将该值默认放到 65535, 就必须修改 20-nproc.conf 文件方才生效; 永久修改生效的必要条件站内相关文章 pam 认证与配置 dubbo 服务治理系统设计 参考链接 ulimit 命令详解 linux /etc/security/limits.conf的相关说明","categories":[{"name":"linux","slug":"linux","permalink":"http://zshell.cc/categories/linux/"},{"name":"conf","slug":"linux/conf","permalink":"http://zshell.cc/categories/linux/conf/"}],"tags":[{"name":"linux:conf","slug":"linux-conf","permalink":"http://zshell.cc/tags/linux-conf/"}]},{"title":"bash 数组与映射","slug":"linux-shell--bash数组与映射","date":"2017-10-22T15:32:19.000Z","updated":"2018-01-03T15:18:11.226Z","comments":true,"path":"2017/10/22/linux-shell--bash数组与映射/","link":"","permalink":"http://zshell.cc/2017/10/22/linux-shell--bash数组与映射/","excerpt":"注: bash 映射 (map) 在文档里叫做 关联数组 (associated array), 使用关联数组的最低 bash 版本是 4.1.2;","text":"注: bash 映射 (map) 在文档里叫做 关联数组 (associated array), 使用关联数组的最低 bash 版本是 4.1.2; 数组/关联数组 的创建静态创建使用类型限定 declare 定义:123456# 数组declare -a array1=('a' 'b' 'c')declare -a array2=(a b c)# 关联数组declare -A map1=([\"a\"]=\"aa\" [\"b\"]=\"bb\" [\"c\"]=\"cc\")declare -A map2=([a]=aa [b]=bb [c]=cc) 如果不带类型限定, bash 不会自动推断 关联数组 类型:12object1=(a b c)object2=([\"a\"]=\"aa\" [\"b\"]=\"bb\" [\"c\"]=\"cc\") 对于以上两者, bash 都将推断为 普通数组 类型, 其中 object2 中有三个 string 元素: [“a”]=”aa”, [“b”]=”bb” 与 [“c”]=”cc”; 动态创建以上展示了 数组/动态数组 的静态创建方式;更复杂的场景是, 由一段其他复杂命令的输出, 赋值构建一个数组类型:1234567891011pair_array=(`sed -n -e '6,/&#125;/p' -e '$d' $&#123;formatted_curl_response_file&#125; | awk -F ':' '&#123; log_length = length($1); app_code_length = length($2); log_path = substr($1, 2, log_length - 2); app_code = substr($2, 2, app_code_length - 2); map[log_path] = app_code&#125; END &#123; for (key in map) &#123; printf (\"%10s=%10s \", key, map[key]) &#125;&#125;'`) 以上逻辑, 由 sed 与 awk 两重管道输出目标内容, 作为创建数组的参数, 以达到动态创建的目的;但是, 以上方式只适用于创建 数组, 而不适用于创建 关联数组, 原因与上一节 静态创建数组 中所表述的相同: 即使输出格式符合定义规范, bash 并不会自动推断为 关联数组;&nbsp;另外, 企图通过 declare 强制限定类型去动态创建, 也是不合法的:1234&gt; declare -A map=(`last -n 1 | head -n 1 | awk '&#123;map[$1]=$3&#125; END&#123;for (key in map) &#123;printf (\"[%10s]=%10s \", key, map[key])&#125;&#125;'`)# 以上语句会报如下错误:-bash: map: [: must use subscript when assigning associative array-bash: map: zshell.z]=113.44.125.146: must use subscript when assigning associative array 因为, 通过 ``, $() 等命令代换, [zshell.z]=113.44.125.146 这样的输出内容被当作命令执行, 而 [ 这是一个 bash 的内置命令, 用于条件判断;显然 zshell.z]=113.44.125.146 这样的语句是不符合条件判断的参数输入的; 数组/关联数组 的使用单独赋值:12map['a']='aaa'array[0]=aaa 获取数据:12345678910111213# 获得所有 valuesecho $&#123;map[@]&#125;echo $&#123;array[@]&#125;# 获得某个单独的值var=$&#123;map['a']&#125;var=$&#123;array[0]&#125;# 获得所有 keys (对于数组而言, 就是获得所有的索引下标)for key in $&#123;!map[@]&#125;; do ...donefor key in $&#123;!array[@]&#125;; do ...done 参考链接 shell中的map使用","categories":[{"name":"linux","slug":"linux","permalink":"http://zshell.cc/categories/linux/"},{"name":"shell","slug":"linux/shell","permalink":"http://zshell.cc/categories/linux/shell/"}],"tags":[{"name":"linux:shell","slug":"linux-shell","permalink":"http://zshell.cc/tags/linux-shell/"}]},{"title":"rsyncd 配置与运维","slug":"rsync--rsyncd配置与运行","date":"2017-10-14T15:20:21.000Z","updated":"2018-01-27T14:53:07.577Z","comments":true,"path":"2017/10/14/rsync--rsyncd配置与运行/","link":"","permalink":"http://zshell.cc/2017/10/14/rsync--rsyncd配置与运行/","excerpt":"本文主要梳理 rsync server 的基本配置与使用方式;","text":"本文主要梳理 rsync server 的基本配置与使用方式; rsync server 的几个关键配置文件 /etc/rsyncd.conf: 主配置文件; /etc/rsyncd.password/rsyncd.secrets: 秘钥文件; /etc/rsyncd.motd: rysnc 服务器元信息, 非必须; 其中, rsyncd.password 秘钥文件的掩码必须是 600:123&gt; ll /etc/ | grep rsyncd-rw-r--r-- 1 root root 361 Apr 6 2017 rsyncd.conf-rw------- 1 root root 24 Apr 6 2017 rsyncd.password rsyncd.conf 配置说明一个典型的 rsyncd.conf 文件如下:123456789101112131415161718192021222324252627282930# rsyncd 守护进程运行系统用户全局配置, 可在具体的块中配置uid=nobodygid=nobody# 是否需要 chroot, 若为 yes, 当客户端连接某模块时, 首先 chroot 到 模块的 path 目录下user chroot = nomax connections = 200timeout = 600pid file = /data1/trans_file/rsyncd.pidlock file = /data1/trans_file/rsyncd.locklog file = /data1/trans_file/rsyncd.log# 用户秘钥文件, 可在具体的模块中配置secrets file = /etc/rsyncd.password# 服务器元信息, 非必选# motd file = /etc/rsyncd/rsyncd.motd# 指定不需要压缩就可以直接传输的文件类型dont compress = *.gz *.tgz *.zip *.z *.Z *.rpm *.deb *.bz2# 模块配置[wireless_log]# 模块使用的 user, 此模块将使用 rsyncd.password 文件中 sync 用户对应的秘钥进行文件传输auth users = syncpath = /data1/trans_file/files/wireless_logignore errors# 是否只读read only = no# 是否允许列出模块里的内容list = no rsyncd.password / rsyncd.secrets 配置说明以 : 分隔, 用户名和密码, 每行一个:12user1:password1user2:password2 rsyncd 启动方式12# 当负载高时, 以守护进程的方式运行 rsyncdsudo /usr/bin/rsync --daemon --config=/etc/rsyncd.conf 参考链接 centos下配置rsyncd服务器 RSync实现文件备份同步","categories":[{"name":"rsync","slug":"rsync","permalink":"http://zshell.cc/categories/rsync/"}],"tags":[{"name":"rsync","slug":"rsync","permalink":"http://zshell.cc/tags/rsync/"}]},{"title":"jstack 命令使用经验总结","slug":"jvm-tools--jstack命令使用经验总结","date":"2017-09-24T09:11:51.000Z","updated":"2018-06-16T12:16:42.229Z","comments":true,"path":"2017/09/24/jvm-tools--jstack命令使用经验总结/","link":"","permalink":"http://zshell.cc/2017/09/24/jvm-tools--jstack命令使用经验总结/","excerpt":"jstack 在命令使用上十分简洁, 然而其输出的内容却十分丰富, 信息量足, 值得深入分析;以往对于 jstack 产生的 thread dump, 我很少字斟句酌得分析过每一部分细节, 针对 jstack 的性能诊断也没有一个模式化的总结; 今天这篇文章我就来详细整理一下与 jstack 相关的内容;","text":"jstack 在命令使用上十分简洁, 然而其输出的内容却十分丰富, 信息量足, 值得深入分析;以往对于 jstack 产生的 thread dump, 我很少字斟句酌得分析过每一部分细节, 针对 jstack 的性能诊断也没有一个模式化的总结; 今天这篇文章我就来详细整理一下与 jstack 相关的内容; jstack 命令的基本使用jstack 在命令使用上十分简洁, 其信息量与复杂度主要体现在 thread dump 内容的分析上;1234567# 最基本的使用sudo -u xxx jstack &#123;vmid&#125;# 从 core dump 中提取 thread dumpsudo -u xxx jstack core_file_path# 除了基本输出外, 额外展示 AbstractOwnableSynchronizer 锁的占有信息# 可能会消耗较长时间sudo -u xxx jstack -l &#123;vmid&#125; jstack 输出内容结构分析首先展示几段 thread dump 的典型例子:正在 RUNNING 中的线程:12345\"elasticsearch[datanode-39][[xxx_index_v4][9]: Lucene Merge Thread #2403]\" #45061 daemon prio=5 os_prio=0 tid=0x00007fb968213800 nid=0x249ca runnable [0x00007fb6843c2000] java.lang.Thread.State: RUNNABLE ... at org.elasticsearch.index.engine.ElasticsearchConcurrentMergeScheduler.doMerge(ElasticsearchConcurrentMergeScheduler.java:94) at org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:626) 阻塞在 java.util.concurrent.locks.Condition 上:1234567\"DubboServerHandler-10.64.16.66:20779-thread-510\" #631 daemon prio=5 os_prio=0 tid=0x00007fb6f4ce5800 nid=0x1743 waiting on condition [0x00007fb68ed2f000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000e2978ef0&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039) ... 阻塞在内置锁上:1234567\"qtp302870502-26-acceptor-0@45ff00a-ServerConnector@63475ace&#123;HTTP/1.1&#125;&#123;0.0.0.0:9088&#125;\" #26 prio=5 os_prio=0 tid=0x00007f1830d3a800 nid=0xdf64 waiting for monitor entry [0x00007f16b5ef9000] java.lang.Thread.State: BLOCKED (on object monitor) at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:234) - waiting to lock &lt;0x00000000c07549f8&gt; (a java.lang.Object) at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:377) ... at java.lang.Thread.run(Thread.java:745) 12345678\"JFR request timer\" #6 daemon prio=5 os_prio=0 tid=0x00007fc2f6b1f800 nid=0x18070 in Object.wait() [0x00007fb9aa96b000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x00007fba6b50ea38&gt; (a java.util.TaskQueue) at java.lang.Object.wait(Object.java:502) at java.util.TimerThread.mainLoop(Timer.java:526) - locked &lt;0x00007fba6b50ea38&gt; (a java.util.TaskQueue) at java.util.TimerThread.run(Timer.java:505) 以上展示了四个线程的 jstack dump, 有 running 状态, 也有阻塞状态, 覆盖面广, 具有典型性; 下面来对 jstack 的输出内容作详细梳理; 输出内容的结构首先还是要说一下 jstack 输出的内容结构, 就以上方举的第四个线程为例:以下是第一部分内容, 记录了线程的一些基本信息, 从左到右每个元素的含义已经以注释标注在元素上方; 其中比较重要的是 nid, 它是 java 线程与操作系统的映射, 在 linux 中它和与其对应的轻量级进程 pid 相同 (需要十六进制与十进制转换), 这将为基于 java 线程的性能诊断带来帮助, 详细请见本文后面段落 #线程性能诊断的辅助脚本;12//|-----线程名------| |-线程创建次序-| |是否守护进程| |---线程优先级---| |-------线程 id-------| |-所映射的linux轻量级进程id-| |-------------线程动作--------------| \"JFR request timer\" #6 daemon prio=5 os_prio=0 tid=0x00007fc2f6b1f800 nid=0x18070 in Object.wait() [0x00007fb9aa96b000] 以下是第二部分内容, 表示线程当前的状态;1java.lang.Thread.State: WAITING (on object monitor) 以下是第三部分内容, 主要记录了线程的调用栈; 其中比较重要的是一些关键调用上的 #动作修饰, 这些为线程死锁问题的排查提供了依据;123456at java.lang.Object.wait(Native Method)- waiting on &lt;0x00007fba6b50ea38&gt; (a java.util.TaskQueue)at java.lang.Object.wait(Object.java:502)at java.util.TimerThread.mainLoop(Timer.java:526)- locked &lt;0x00007fba6b50ea38&gt; (a java.util.TaskQueue)at java.util.TimerThread.run(Timer.java:505) 线程的动作线程动作的记录在每个 thread dump 的第一行末尾, 一般情况下可分为如下几类: runnable, 表示线程在参与 cpu 资源的竞争, 可能在被调度运行也可能在就绪等待; sleeping, 表示调用了 Thread.sleep(), 线程进入休眠; waiting for monitor entry [0x...], 表示线程在试图获取内置锁, 进入了等待区 Entry Set, 方括号内的地址表示线程等待的资源地址; in Object.wait() [0x...], 表示线程调用了 object.wait(), 放弃了内置锁, 进入了等待区 Wait Set, 等待被唤醒, 方括号内的地址表示线程放弃的资源地址; waiting on condition [0x...], 表示线程被阻塞原语所阻塞, 方括号内的地址表示线程等待的资源地址; 这种和 jvm 的内置锁体系没有关系, 它是 jdk5 之后的 java.util.concurrent 包下的锁机制; 线程的状态线程的状态记录在每个 thread dump 的第二行, 并以 java.lang.Thread.State 开头, 一般情况下可分为如下几类: RUNNABLE, 这种一般与线程动作 runnable 一起出现; BLOCKED (on object monitor), 这种一般与线程动作 waiting for monitor entry 一起出现, 不过在其线程调用栈最末端并没有一个固定的方法, 因为 synchronized 关键字可以修饰各种方法或者同步块; WAITING (on object monitor) 或者 TIMED_WAITING (on object monitor), 这种一般与线程动作 in Object.wait() [0x...] 一起出现, 并且线程调用栈的最末端调用方法为 at java.lang.Object.wait(Native Method), 以表示 object.wait() 方法的调用;另外, WAITING 与 TIMED_WAITING 的区别在于是否设置了超时中断, 即 wait(long timeout) 与 wait() 的区别; WAITING (parking) 或者 TIMED_WAITING (parking), 这种一般与线程动作 waiting on condition [0x...] 一起出现, 并且线程调用栈的最末端调用方法一般为 at sun.misc.Unsafe.park(Native Method);Unsafe.park 使用的是线程阻塞原语, 主要在 java.util.concurrent.locks.AbstractQueuedSynchronizer 类中被使用到, 很多基于 AQS 构建的同步工具, 如 ReentrantLock, Condition, CountDownLatch, Semaphore 等都会诱发线程进入该状态;另外, WAITING 与 TIMED_WAITING 的区别与第三点中提到的原因一致; 线程的重要调用修饰thread dump 的第三部分线程调用栈中, 一般会把与锁相关的资源使用状态以附加的形式作重点修饰, 这与线程的动作及状态有着密切的联系, 一般情况下可分为如下几类: locked &lt;0x...&gt;, 表示其成功获取了内置锁, 成为了 owner; parking to wait for &lt;0x...&gt;, 表示其被阻塞原语所阻塞, 通常与线程动作 waiting on condition 一起出现; waiting to lock &lt;0x...&gt;, 表示其在 Entry Set 中等待某个内置锁, 通常与线程动作 waiting for monitor entry 一起出现; waiting on &lt;0x...&gt;, 表示其在 Wait Set 中等待被唤醒, 通常与线程动作 in Object.wait() [0x...] 一起出现;另外, waiting on 调用修饰往往与 locked 调用修饰一同出现, 如之前列举的第四个 thread dump:123456at java.lang.Object.wait(Native Method) - waiting on &lt;0x00007fba6b50ea38&gt; (a java.util.TaskQueue) at java.lang.Object.wait(Object.java:502) at java.util.TimerThread.mainLoop(Timer.java:526) - locked &lt;0x00007fba6b50ea38&gt; (a java.util.TaskQueue) at java.util.TimerThread.run(Timer.java:505) 这是因为该线程之前获得过该内置锁, 现在因为 object.wait() 又将其放弃了, 所以在调用栈中会出现先后两个调用修饰; 死锁检测的展示在 jdk5 之前, Doug Lea 大神还没有发布 java.util.concurrent 包, 这个时候提及的锁, 就仅限于 jvm 监视器内置锁; 此时如果进程内有死锁发生, jstack 将会把死锁检测信息打印出来:12345678910111213141516Found one Java-level deadlock:=============================\"Thread-xxx\": waiting to lock monitor 0x00007f0134003ae8 (object 0x00000007d6aa2c98, a java.lang.Object), which is held by \"Thread-yyy\"\"Thread-yyy\": waiting to lock monitor 0x00007f0134006168 (object 0x00000007d6aa2ca8, a java.lang.Object), which is held by \"Thread-xxx\"Java stack information for the threads listed above:===================================================\"Thread-xxx\": ...\"Thread-yyy\": ...Found 1 deadlock. 然而后来 Doug Lea 发布了 java.util.concurrent 包, 当谈及 java 的锁, 除了内置锁之外还有了基于 AbstractOwnableSynchronizer 的各种形式; 由于是新事物, 彼时 jdk5 的 jstack 没有及时提供对以 AQS 构建的同步工具的死锁检测功能, 直到 jdk6 才完善了相关支持; 常见 java 进程的 jstack dump 特征首先, 不管是什么类型的 java 应用, 有一些通常都会存在的线程: VM Thread 与 VM Periodic Task Thread虚拟机线程, 属于 native thread, 凌驾与其他用户线程之上;VM Periodic Task Thread 通常用于虚拟机作 sampling/profiling, 收集系统运行信息, 为 JIT 优化作决策依据; C1 / C2 CompilerThread虚拟机的 JIT 及时编译器线程:123456\"C1 CompilerThread2\" #10 daemon prio=9 os_prio=0 tid=0x00007feb34114000 nid=0x18b2 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE\"C2 CompilerThread1\" #9 daemon prio=9 os_prio=0 tid=0x00007feb34112000 nid=0x18b1 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE\"C2 CompilerThread0\" #8 daemon prio=9 os_prio=0 tid=0x00007feb3410f800 nid=0x18b0 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE Reference Handler 线程与 Finalizer 线程这两个线程用于虚拟机处理 override 了 Object.finalize() 方法的实例, 对实例回收前作最后的判决;Reference Handler 线程用于将目标对象放入 reference queue:123456\"Reference Handler\" #2 daemon prio=10 os_prio=0 tid=0x00007f91e007f000 nid=0xa80 in Object.wait() [0x...] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) at java.lang.Object.wait(Object.java:502) at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:157) - locked &lt;0x00000000c0495140&gt; (a java.lang.ref.Reference$Lock) Finalizer 线程用于从 reference queue 中取出对象以执行其 finalize 方法:1234567\"Finalizer\" #3 daemon prio=8 os_prio=0 tid=0x00007f91e0081000 nid=0xa81 in Object.wait() [0x...] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143) - locked &lt;0x00000000c008db88&gt; (a java.lang.ref.ReferenceQueue$Lock) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:164) at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:209) gc 线程这块对于不同的 gc 收集器选型有各自不同的线程状态 (线程数视 cpu 核心数而定);123# Parallel Scavenge\"GC task thread#0 (ParallelGC)\" os_prio=0 tid=0x00007f91e0021000 nid=0xa7a runnable \"GC task thread#1 (ParallelGC)\" os_prio=0 tid=0x00007f91e0023000 nid=0xa7b runnable 123# ParNew\"Gang worker#0 (Parallel GC Threads)\" os_prio=0 tid=0x00007feb3401e800 nid=0x18a4 runnable \"Gang worker#1 (Parallel GC Threads)\" os_prio=0 tid=0x00007feb34020000 nid=0x18a5 runnable 12# CMS\"Concurrent Mark-Sweep GC Thread\" os_prio=0 tid=0x00007feb34066800 nid=0x18a8 runnable 12345678# G1\"G1 Main Concurrent Mark GC Thread\" os_prio=0 tid=0x00007fc2f4091800 nid=0x1805e runnable\"Gang worker#0 (G1 Parallel Marking Threads)\" os_prio=0 tid=0x00007fc2f4093800 nid=0x1805f runnable \"Gang worker#1 (G1 Parallel Marking Threads)\" os_prio=0 tid=0x00007fc2f4095800 nid=0x18060 runnable\"G1 Concurrent Refinement Thread#0\" os_prio=0 tid=0x00007fc2f4079000 nid=0x1805d runnable \"G1 Concurrent Refinement Thread#1\" os_prio=0 tid=0x00007fc2f4077000 nid=0x1805c runnable 以上便是 java 进程里通常都会存在的线程; 纯 tomcat 容器tomcat with dubboelasticsearch datanode 节点相关衍生工具使用代码作 thread dump除了使用 jstack 之外, 还有其他一些方法可以对 java 进程作 thread dump, 如果将其封装为 http 接口, 便可以不用登陆主机, 直接在浏览器上查询 thread dump 的情况;使用 jmx 的 api123456public void threadDump() &#123; ThreadMXBean threadMxBean = ManagementFactory.getThreadMXBean(); for (ThreadInfo threadInfo : threadMxBean.dumpAllThreads(true, true)) &#123; // deal with threadInfo.toString() &#125;&#125; 使用 Thread.getAllStackTraces() 方法12345678910111213public void threadDump() &#123; for (Map.Entry&lt;Thread, StackTraceElement[]&gt; stackTrace : Thread.getAllStackTraces().entrySet()) &#123; Thread thread = (Thread) stackTrace.getKey(); StackTraceElement[] stack = (StackTraceElement[]) stackTrace.getValue(); if (thread.equals(Thread.currentThread())) &#123; continue; &#125; // deal with thread for (StackTraceElement stackTraceElement : stack) &#123; // deal with stackTraceElement &#125; &#125;&#125; 线程性能诊断的辅助脚本使用 jstack 还有一个重要的功能就是分析热点线程: 找出占用 cpu 资源最高的线程;首先我先介绍一下手工敲命令分析的方法: 使用 top 命令找出 cpu 使用率高的 thread id: 1234# -p pid: 只显示指定进程的信息# -H: 展示线程的详细信息top -H -p &#123;pid&#125;# 使用 P 快捷键按 cpu 使用率排序, 并记录排序靠前的若干 pid (轻量级进程 id) 作进制转换: 123# 将记录下的十进制 pid 转为十六进制thread_id_0x=`printf \"%x\" $thread_id``echo \"obase=16; $thread_id\" | bc` 由于 thread dump 中记录的每个线程的 nid 是与 linux 轻量级进程 pid 一一对应的 (只是十进制与十六进制的区别), 所以便可以拿转换得到的十六进制 thread_id_0x, 去 thread dump 中搜索对应的 nid, 定位问题线程;&nbsp; 下面介绍一个脚本, 其功能是: 按照 cpu 使用率从高到低排序, 打印指定 jvm 进程的前 n 个线程;123456789101112131415161718192021222324252627#!/bin/shdefault_lines=10top_head_info_padding_lines=8default_stack_lines=15jvm_pid=$1jvm_user=$2((thread_stack_lines=$&#123;3:-$default_lines&#125;+top_head_info_padding_lines))threads_top_capture=$(top -b -n1 -H -p $jvm_pid | grep $jvm_user | head -n $thread_stack_lines)jstack_output=$(echo \"$(sudo -i -u $jvm_user jstack $jvm_pid)\")top_output=$(echo \"$(echo \"$threads_top_capture\" | perl -pe 's/\\e\\[?.*?[\\@-~] ?//g' | awk '&#123;gsub(/^ +/,\"\");print&#125;' | awk '&#123;gsub(/ +|[+-]/,\" \");print&#125;' | cut -d \" \" -f 1,9 )\\n \")echo \"***********************************************************\"uptimeecho \"Analyzing top $top_threads threads\"echo \"***********************************************************\"printf %s \"$top_output\" | while IFS= read linedo pid=$(echo $line | cut -d \" \" -f 1) hexapid=$(printf \"%x\" $pid) cpu=$(echo $line | cut -d \" \" -f 2) echo -n $cpu \"% [$pid] \" echo \"$jstack_output\" | grep \"tid.*0x$hexapid \" -A $default_stack_lines | sed -n -e '/0x'$hexapid'/,/tid/ p' | head -n -1done 该脚本有多种版本, 在我司的每台主机上的指定路径下都存放了一个副本; 出于保密协议, 该脚本源码不便于公开, 上方所展示的版本是基于美团点评的技术专家王锐老师在一次 问答分享 中给出的代码所改造的; thread dump 可视化分析工具与 gceasy.io 一道, 同出自一家之手: fastthread.io; 参考链接 如何使用jstack分析线程状态 java命令–jstack 工具 7 个抓取 Java Thread Dumps 的方式 你与Java大牛的距离，只差这24个问题","categories":[{"name":"jvm","slug":"jvm","permalink":"http://zshell.cc/categories/jvm/"},{"name":"tools","slug":"jvm/tools","permalink":"http://zshell.cc/categories/jvm/tools/"}],"tags":[{"name":"jvm:tools","slug":"jvm-tools","permalink":"http://zshell.cc/tags/jvm-tools/"}]},{"title":"nagios 配置文件梳理及运维实践","slug":"alert-nagios--nagios配置文件梳理及运维实践","date":"2017-08-25T12:19:32.000Z","updated":"2018-06-05T12:23:55.904Z","comments":true,"path":"2017/08/25/alert-nagios--nagios配置文件梳理及运维实践/","link":"","permalink":"http://zshell.cc/2017/08/25/alert-nagios--nagios配置文件梳理及运维实践/","excerpt":"nagios 的优点在于其插件拓展式的设计, 不过 nagios 给 ops 映像最深刻的, 是其出离复杂的配置文件; nagios 真的可以说是把配置文件当数据库使了;作为备忘, 本文主要梳理 nagios 配置文件中的各种角色的关系与交互流程, 并就日常工作的经验总结一些 nagios 配置文件的部署及运维实践;","text":"nagios 的优点在于其插件拓展式的设计, 不过 nagios 给 ops 映像最深刻的, 是其出离复杂的配置文件; nagios 真的可以说是把配置文件当数据库使了;作为备忘, 本文主要梳理 nagios 配置文件中的各种角色的关系与交互流程, 并就日常工作的经验总结一些 nagios 配置文件的部署及运维实践; nagios 中的角色梳理nagios 的配置文件角色众多, 各角色之间存在依赖关系, 从这个角度上看, nagios 很像是一个 “关系型数据库”;针对我日常工作中遇到的情景, 其中可能涉及到的角色如下: service, 最核心的角色, 标识一个完整的检测服务单元; command, 报警检测命令; contact / contactgroup, 联系人 / 联系组, 当指标异常时的联系对象; host / hostgroup, 主机, 主机组, 报警检测的目标机器; timeperiod, 报警时间段; nagios 各角色之间的关系既然 nagios 的配置文件像一个关系型数据库, 那么一定可以作出它的 实体关系 ER 图, 绘制如下: nagios 的角色关系图1 这是第一类简单的 ER 图, 其中 service 直接关联到单一联系人或单一主机; 除了这种情况外, service 也可以直接关联到联系人组或主机组, 再由组间接关联到具体的人或主机, 如下图所示: nagios 的角色关系图2 nagios command 的参数传递由上面展示的两张图可以发现, service 是所有角色的中心, command 则是在整个流程中穿针引线的关键要素; 除了 service 中的 check_command 之外, host 也存在自己检测主机的 check_command, contact 则需要定义触发报警通知的 service_notification_commands 和 host_notification_commands; 所以说, command 的实现与调用十分关键, 而 command 调用的关键又在于其参数传递;nagios 的参数分为两种类型, 一种是其自己的保留参数(宏定义), 常用的列举如下:1234567891011HOSTNAME # 主机名, 对应 host 角色中的 host_name 域HOSTADDRESS # 主机地址, 对应 host 角色中的 address 域NOTIFICATIONTYPE # 通知类型, 主要有 PROBLEM, RECOVERY 等SERVICESTATE # 服务状态, 主要有 warning, unknown, critical, recovery 等CONTACTNAME # 联系人, 对应 contact 角色中的 contact_name 域CONTACTEMAIL # 联系人的邮件, 对应 contact 角色中的 email 域SERVICEDESC # 服务的描述, 对应 service 角色中的 service_description 域SERVICEOUTPUT # 服务的详细输出 这类宏定义, 在使用时会直接从角色配置项的具体域中直接获取值, 前提条件是配置项对应的域要已经配置了该值;第二种类型是自定义类型, 在使用时是以顺序获取的, 如:1234define command &#123; command_name check_ping command_line $USER1$/check_ping -H $HOSTADDRESS$ -w $ARG1$ -c $ARG2$&#125; 以上 check_ping 命令一共接受了 3 个参数: $HOSTADDRESS$, $ARG1$, $ARG2$, 除了 $HOSTADDRESS$ 是由 host 中的 address 域获得的, 其余两个自定义参数则按顺序填充至最终的命令中; 而调用该命令的服务配置如下:1234define service &#123; ... check_command check_ping!50,10%!100,20%&#125; 可以看到, 分别将各个自定义参数按顺序放在命令的后面, 以 ! 隔开, 即为调用方式, 而对于 $HOSTADDRESS$ 这种宏定义参数, 则不需要主动设置, nagios 自己会带上它; nagios 配置文件部署与运维实践面对 nagios 这种不太友好, 略显复杂的配置, 想完全依托它实现自动化运维确实有些麻烦, 所以在不断的使用经验总结中, 我们渐渐形成了一套自己的使用方式; 另外, 我们还逐步将一些关键逻辑从 nagios 转移到自己开发的旁路系统中, 简化 nagios 的配置内容, 从而突出它的核心功能; 三类报警检测类型首先从实现方式上分类, 我们使用了两大类: 使用插件拓展方式的 check_nrpe 和直接在 nagios server 上执行的本地检测命令;(1) check_nrpe 对我们来说主要是用于非网络型的机器指标检测, 包括 check_load, check_disk, check_procs, check_swap, check_users, 以及戴尔供应商的硬件检测工具 (仅适用于实体机) check_openmanage, check_dell_temperature 等;这类检测只能在 agent 上执行, 并且对于不同的主机环境, 其报警阈值各不相同, 需在 agent 上个性化定制; 所以, 这类指标检测只适用于 check_nrpe 的方式;以下是一个典型的 nrpe 配置文件:12345command[check_zombie_procs]=/home/nrpe/libexec/check_procs -w 5 -c 10 -s Zcommand[check_total_procs]=/home/nrpe/libexec/check_procs -w 150 -c 200command[check_disk]=/home/nrpe/libexec/check_disk -w 15% -c 10% -A -lcommand[check_swap]=/home/nrpe/libexec/check_swap -w 90% -c 80%command[check_load]=/home/nrpe/libexec/check_load -w 12,3.2,8 -c 12,3.6,8 另外除了以上通用的 nrpe 检查项之外, 对于一个标准的生产环境, 还可以定制特定的进程检查项:12345command[check_crond]=/home/nrpe/libexec/check_procs -C crond -c 1:1command[check_collectd]=/home/nrpe/libexec/check_procs -C collectd -c 1:1command[check_ntpd]=/home/nrpe/libexec/check_procs -C ntpd -c 1:1command[check_dnsmasq]=/home/nrpe/libexec/check_dnsmasq.pl -s 127.0.0.1 -H xxx.com -w 250 -c 300command[check_flume-ng]=/home/nrpe/libexec/check_procs -a /home/apache-flume-ng/bin/flume-ng-manage -c 1:1 当然这些都是对辅助系统的检测, 对于生产环境下真正提供业务服务的系统, 则使用其他更灵活的方法监控; (2) 直接在 nagios server 上执行的检测命令, 主要是网络型的机器指标检测, 如 check_ping, check_tcp, check_udp 等, 以及第三方的业务指标检测命令 check_graphite;网络型的检测命令自不必多说, 其本身并不依赖于 agent 机器, 在 nagios server 上执行即可; 而第三方的业务指标检测命令 check_graphite, 主要依赖于 graphite_api 提供的接口获取业务指标, 亦不需要依赖 agent 机器;以下为 check_graphite 命令的两种典型举例, 一正一反:12345678define command &#123; command_name check_graphite command_line /usr/lib64/nagios/plugins/check_graphite --host 10.64.0.49:8888 --metric $ARG1$ --critical $ARG2$ --warning $ARG3$ --name $ARG4$ --duration $ARG5$ --function $ARG6$ 2&gt;&amp;1&#125;define command &#123; command_name check_graphite_invert command_line /usr/lib64/nagios/plugins/check_graphite --invert --host 10.64.0.49:8888 --metric $ARG1$ --critical $ARG2$ --warning $ARG3$ --name $ARG4$ --duration $ARG5$ --function $ARG6$ 2&gt;&amp;1&#125; 典型的 service 调用如下:12345678define service &#123; service_description xxxx use service_template ... check_period name_1_2_3_4_5_6_7_00:00-23:59 contact_groups common-contact check_command check_graphite!'metrics.name.sample'!48!48!'query_time_too_long'!15!'max'&#125; 这里就要提到第一个被我们转移到旁路系统的功能: service 配置文件的自动生成;在 应用中心的角色定位与功能总结 这篇文章里曾提及, 我们将设置报警项的过程留给业务线同学在应用中心的界面上完成; 对于新增的报警项, 我们写了一个 service-generator 系统, 按 appcode 划分, 定时将其刷到 nagios 的不同配置文件中;我们使用 gitlab 管理 nagios 的配置文件, 其配置文件所在 base 路径已经关联到远程仓库; 与此同时, 在 nagios 实例所在主机上我们部署了 config-reload-manager 管理工具: 对于 service-generator 新增的配置内容, config-reload-manager 定时 reload nagios 进程, 如果成功加载, 则将本次新增内容 commit, 如果加载失败, 则单独 checkout 一个临时分支记录问题并报警, 重新 reset 到之前最新的版本, 恢复服务;其实上述逻辑涉及到一个比较共性的问题: 系统动态配置文件的运维经验总结, 详细内容可以参考这篇文章; (3) 第三类检测类型严格上说仍然属于直接在 nagios server 上执行的检测命令, 不过将其单独提出来是因为它的特殊功能: 服务状态检测; 在第一类 check_nrpe 检测中曾提到, 对于生产环境下的服务, 使用其他更灵活的方式监控, 这里指的就是基于端口的服务状态检测, 说的再直白一些就是使用 check_tcp / check_udp 命令检测服务端口的状态, 如果服务挂了, 对应的端口就会被探测到 connection refused 或者 timeout;12345678define service &#123; service_description alive_appcode_xxx_8080 use service_template host_name l-xxx1.yyy.cn2,l-xxx2.yyy.cn2,l-xxx3.yyy.cn2,l-xxx4.yyy.cn2 ... contact_groups common-contact check_command check_tcp!8080&#125; 这类检测依然要依赖应用中心: 在 应用中心的角色定位与功能总结 这篇文章里曾提及, 通过应用的标准化接入流程, 服务发布或启动的时候需要上报本次启动的相关信息给应用中心, 其中包括了服务所在主机地址及端口号; 每当有新服务注册, 我们会通过类似 service-generator 的方式生成对应的检测配置项; 淡化 contacts, 报警通知逻辑外置对于一个报警系统而言, 最核心的功能就是检测异常; 除此之外, nagios 还可以通过 contact 配置通知到负责人, 然而这并不是报警系统的核心; 这里就要提到第二个被我们转移到旁路系统的功能: 报警通知逻辑;一个公司有那么多工程师, 如果完全依靠 nagios 来实现通知, 就得把每个人的信息都配到文件里, 同时还要维护他们的群组关系, 按照 appcode 分类, 这无疑会增加 nagios 的配置量, 为运维带来复杂性; 况且, 通知逻辑并非 nagios 的核心功能, 权衡之下, 我们选择淡化 nagios 的 contact / contactgroup 元素, 让所有 service 的联系人都使用一个泛化的 common-contact, 而这个 common-contact 的通知命令, 会根据报警的内容, 自动选择合适的负责人;1234567891011define contactgroup &#123; contactgroup_name common-contact ... service_notification_commands alert-notify host_notification_commands alert-notify&#125;define command &#123; command_name alert-notify command_line /usr/bin/python /etc/nagios/objects/xxx/alert_notify.py \"$NOTIFICATIONTYPE$\" \"$HOSTNAME$\" \"$HOSTALIAS$\" \"$HOSTADDRESS$\" \"$HOSTSTATE$\" \"$HOSTOUTPUT$\" \"$SERVICEDESC$\" \"$SERVICESTATE$\" \"$LONGDATETIME$\" \"$SERVICEOUTPUT$\" \"$CONTACTEMAIL$\" \"$CONTACTALIAS$\" \"$CONTACTNAME$\" &gt;&gt; /var/log/nagios/alert.log.$(date +%F-%H) 2&gt;&amp;1&#125; 在 alert-notify 脚本中, 会根据报警内容查询应用中心, 选择合适的报警联系人, 合适的报警方式, 通知到位; 如果是 nagios 发送通知, 就只有配置的固定一组人会收到报警, 而改成这种外部的方式, 就具有了相当的灵活性, 甚至我们可以根据报警处理的进度反馈择机作报警升级处理, 比如:(1) 报警方式从微信变成短信, 再变成电话语音报警;(2) 报警联系人按照应用树组织架构, 从直接负责人, 逐步升级到 项目TL, 部门主管, 技术总监, VP, CEO 等; 站内相关文章 应用中心的角色定位与功能总结 系统动态配置文件的运维经验总结 参考链接 nagios 短信报警通知 Nagios搭建与配置详解","categories":[{"name":"alert","slug":"alert","permalink":"http://zshell.cc/categories/alert/"},{"name":"nagios","slug":"alert/nagios","permalink":"http://zshell.cc/categories/alert/nagios/"}],"tags":[{"name":"alert:nagios","slug":"alert-nagios","permalink":"http://zshell.cc/tags/alert-nagios/"},{"name":"devops 实践","slug":"devops-实践","permalink":"http://zshell.cc/tags/devops-实践/"},{"name":"运维自动化","slug":"运维自动化","permalink":"http://zshell.cc/tags/运维自动化/"}]},{"title":"python module 使用总结: MySQLdb","slug":"python-module--python_module_使用总结_MySQLdb","date":"2017-08-01T15:06:08.000Z","updated":"2018-03-24T07:08:03.418Z","comments":true,"path":"2017/08/01/python-module--python_module_使用总结_MySQLdb/","link":"","permalink":"http://zshell.cc/2017/08/01/python-module--python_module_使用总结_MySQLdb/","excerpt":"MySQLdb 模块是 python 与 mysql 交互的较为底层的接口, 不过它依然是在更为底层的 _mysql 模块之上又作了一层包装;_mysql 才是真正的直接面向 mysql 原生 C 接口的简单适配层, 而 MySQLdb 则在 _mysql 之上作了更多的关于类型转换等抽象包装;考虑到 MySQLdb 模块与一些 python ORM 框架的关系, MySQLdb 与 python 的关系可以类比为 jdbc 之于 java;如果是复杂的系统, 我们肯定会选择 ORM 框架, 不过对于一些简单的小工具, 定时小任务等, 本身没什么复杂的数据库操作, 那就用 MySQLdb 最方便了;本文基于 MySQL-python 1.2.5 对 MySQLdb 作一些使用上的总结;","text":"MySQLdb 模块是 python 与 mysql 交互的较为底层的接口, 不过它依然是在更为底层的 _mysql 模块之上又作了一层包装;_mysql 才是真正的直接面向 mysql 原生 C 接口的简单适配层, 而 MySQLdb 则在 _mysql 之上作了更多的关于类型转换等抽象包装;考虑到 MySQLdb 模块与一些 python ORM 框架的关系, MySQLdb 与 python 的关系可以类比为 jdbc 之于 java;如果是复杂的系统, 我们肯定会选择 ORM 框架, 不过对于一些简单的小工具, 定时小任务等, 本身没什么复杂的数据库操作, 那就用 MySQLdb 最方便了;本文基于 MySQL-python 1.2.5 对 MySQLdb 作一些使用上的总结; MySQLdb 的基本操作1234567891011121314151617import MySQLdb# 获得 mysql 的一个连接conn = MySQLdb.connect(host='10.64.0.11', user='xxx', passwd='yyy', db=\"zzz\", port=3306, charset=\"utf8\")try: # cursor 游标, 是 MySQLdb 中与 mysql 增删改查数据交互的对象 cur = conn.cursor() # 数据库操作 cur.execute(\"...sql...\") ... # 提交事务 conn.commit()except Exception, e: # 回滚 conn.rollback()finally: # 关闭连接, 释放资源 conn.close() 以上是一个 MySQLdb 使用的完整流程, 下面是具体的使用细节与注意点总结; MySQLdb cursor.execute / cursor.executemany 方法cursor.execute 方法MySQLdb 执行数据操纵的关键点就在于 cursor.execute 方法, 所有包括增删改查在内皆是以此方法执行的, 以下是该方法的代码:1234567891011121314151617181920212223242526272829303132def execute(self, query, args=None): del self.messages[:] db = self._get_db() if isinstance(query, unicode): query = query.encode(db.unicode_literal.charset) if args is not None: # 针对 args 为 dict 的特殊情况处理 if isinstance(args, dict): query = query % dict((key, db.literal(item)) for key, item in args.iteritems()) # 其余的情况: args 为 tuple 或单个 value else: query = query % tuple([db.literal(item) for item in args]) try: r = None r = self._query(query) except TypeError, m: if m.args[0] in (\"not enough arguments for format string\", \"not all arguments converted\"): self.messages.append((ProgrammingError, m.args[0])) self.errorhandler(self, ProgrammingError, m.args[0]) else: self.messages.append((TypeError, m)) self.errorhandler(self, TypeError, m) except (SystemExit, KeyboardInterrupt): raise except: exc, value, tb = sys.exc_info() del tb self.messages.append((exc, value)) self.errorhandler(self, exc, value) self._executed = query if not self._defer_warnings: self._warning_check() return r 该方法接收一个名为 query 的 sql 字符串, 另外还可选附带参数 args, 所以该方法存在两种主要的用法:1.预先格式化好 sql 字符串, 然后不带参数直接 execute:12sql = \"select * from xxx where update_time = %s\" % datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")cursor.execute(sql) 这种是保守的方法, 参数处理完全由 python 原生的格式化字符串完成, cursor.execute 方法只管执行 sql 就好;这种方法的优点是省事, 坑少;&nbsp;2.将参数传给 execute 方法的 args, 这种使用方法有几个坑, 需要注意一下;该方法有一段注释, 我单独提了出来, 注释中对 args 参数有如下描述:1234567\"\"\" args -- optional sequence or mapping, parameters to use with query. Note: If args is a sequence, then %s must be used as the parameter placeholder in the query. If a mapping is used, %(key)s must be used as the placeholder.\"\"\" (1) 注释中提到的坑, 就是说无论传的参数是一个 list/tuple, 还是 dict, 参数占位符类型都必须是字符串(%s | %(key)s ):12# 不能是 id = %d, 只能是 id = %ssql = 'select * from xxx where id = %s' 因为 execute 方法里处理参数时, 会对参数作 db.literal(item) 处理, 将参数首先转为字符串, 这时占位符如果是 %d 等其他类型, 就报错了; &nbsp;(2) 注释中另一个隐型的坑, 是这个 args 必须是 list / tuple / dict 中的一个, 哪怕只有一个占位数据, 也必须写成 list 或 tuple 类型:12cursor.execute(sql, (2,))cursor.execute(sql, [2]) 如果希望以 tuple 形式表示唯一一个参数, 必须注意加上 逗号, 因为不加逗号就算外面包了括号也会识别为其本身的类型:12345678&gt;&gt;&gt; print type((1))&lt;type 'int'&gt;&gt;&gt;&gt; print type(('1'))&lt;type 'str'&gt;&gt;&gt;&gt; print type((1,))&lt;type 'tuple'&gt;&gt;&gt;&gt; print type(('1',))&lt;type 'tuple'&gt; 其实这个坑是在 MySQL-python 1.2.5 版本中出现的问题; 在 1.2.3 版本中, execute 方法的逻辑是这么写的:12if args is not None: query = query % db.literal(args) 只要 args 非空, 就一律把它 to string; 而至于参数怎么转, 转成什么样, 就看参数自己了;这么做确实灵活了, 但是也可能带来一些不确定性, 1.2.5 的版本将参数限定为 list / tuple / dict, 然后对集合内的每个元素再针对性 to string, 一定程度上控制了参数的规范性;&nbsp; cursor.executemany 方法executemany 方法是 execute 方法的批量化, 这个方法的有效使用范围其实很狭窄, 仅针对 insert 操作有性能提升, 其余操作在性能上均与 execute 无异;下面是该方法的代码:1234567891011121314151617181920212223242526272829303132333435363738394041del self.messages[:]db = self._get_db()if not args: returnif isinstance(query, unicode): query = query.encode(db.unicode_literal.charset)# 正则匹配 insert 操作m = insert_values.search(query)# 不是 insert 操作, 那就 for 循环挨个执行而已if not m: r = 0 for a in args: r = r + self.execute(query, a) return rp = m.start(1)e = m.end(1)qv = m.group(1)# 下面是针对 insert 的处理try: q = [] for a in args: if isinstance(a, dict): q.append(qv % dict((key, db.literal(item)) for key, item in a.iteritems())) else: q.append(qv % tuple([db.literal(item) for item in a]))except TypeError, msg: if msg.args[0] in (\"not enough arguments for format string\", \"not all arguments converted\"): self.errorhandler(self, ProgrammingError, msg.args[0]) else: self.errorhandler(self, TypeError, msg)except (SystemExit, KeyboardInterrupt): raiseexcept: exc, value, tb = sys.exc_info() del tb self.errorhandler(self, exc, value)# 批量化执行, 提高处理性能r = self._query('\\n'.join([query[:p], ',\\n'.join(q), query[e:]]))if not self._defer_warnings: self._warning_check()return r 从代码里可以看到, 方法先对传入的 sql 语句作一次匹配, 判断其是否是 insert 操作, 其中 insert_values 是一个 regex, 专门匹配 insert 语句:12restr = r\"\\svalues\\s*(\\([^()']*(?:(?:(?:\\(.*\\))|'[^\\\\']*(?:\\\\.[^\\\\']*)*')[^()']*)*\\))\"insert_values = re.compile(restr, re.S | re.I | re.X) 针对 insert 语句, 其最后的执行是批量的, 以提高执行效率:1r = self._query('\\n'.join([query[:p], ',\\n'.join(q), query[e:]])) 但是而其他的语句, 却只能在一个 for 循环里, 挨个执行 execute 方法, 这就没什么优势了;不过这个方法还有一个大坑: 对于 update 和 delete 操作, 使用 executemany 至少不会比 execute 差, 但是对于 query, 它批量执行完一堆 query 操作后去 fetch 结果集, 只能拿到最后执行的 query 的结果, 前面的都被覆盖了; 所以, query 操作不能使用 executemany 方法;&nbsp;在使用方面, executemany 的坑和 execute 是差不多的, 下面是一个例子:12# executemany 传入的 args 可以是 list 也可以是 tuplecur.executemany('select * from xxx where yyy = %s', [(1,), (2,)]) MySQLdb 的 query 结果集操作MySQLdb 的 query 操作, 主要有以下三种结果集的获取方法:12345678910111213141516171819202122232425cursor.execute(\"...sql...\")# 获得所有的 tuple 结果集的一个 list@return list[tuple(elem1, elem2, elem3 ...)]tuple_data_list = cursor.fetchall()for tuple_data in tuple_data_list: xxx = tuple_data[0] yyy = tuple_data[1] ... # 采用迭代器的方式, 返回当前游标所对应的 tuple 结果集, 迭代到最后方法返回 None@return tuple(elem1, elem2, elem3 ...)tuple_data = cursor.fetchone()while tuple_data: # deal with tuple_data ... tuple_data = cursor.fetchone() # 折中的一种方法, 指定返回 size 个 tuple 结果集 组成一个 list;# 若 指定 size 小于 总的结果集数量, 则返回全部数据集;@return list[tuple(elem1, elem2, elem3 ...)]tuple_data_list = cursor.fetchmany(size)... MySQLdb 的事务操作MySQLdb 默认不会自动 commit, 所有的增删改操作都必须手动 commit 才能真正写回数据库;12345678910111213conn = MySQLdb.connect(host='10.64.0.11', user='xxx', passwd='yyy', db=\"zzz\", port=3306, charset=\"utf8\")SQL = 'update xxx set yyy = zzz'cur = conn.cursor()try: cur.execute(SQL,(2,)) # 手动 commit 提交事务 conn.commit()except Exception, e: # 手动回滚 conn.rollback()finally: cur.close() conn.close() 参考链接 MySQLdb的安装与使用","categories":[{"name":"python","slug":"python","permalink":"http://zshell.cc/categories/python/"},{"name":"module","slug":"python/module","permalink":"http://zshell.cc/categories/python/module/"}],"tags":[{"name":"python","slug":"python","permalink":"http://zshell.cc/tags/python/"},{"name":"python:module","slug":"python-module","permalink":"http://zshell.cc/tags/python-module/"}]},{"title":"jcmd: jvm 管理的另类工具","slug":"jvm-tools--jcmd_jvm管理的另类工具","date":"2017-06-25T11:13:05.000Z","updated":"2018-05-20T11:14:11.159Z","comments":true,"path":"2017/06/25/jvm-tools--jcmd_jvm管理的另类工具/","link":"","permalink":"http://zshell.cc/2017/06/25/jvm-tools--jcmd_jvm管理的另类工具/","excerpt":"曾经 oracle 向我们提供了一套 jvm 管理与诊断问题的 “工具全家桶”: jps, jstack, jmap, jstat, jhat, jinfo 等等, 我们针对不同的情景使用不同的工具, 解决特定的问题;现在, oracle 在 jdk7 之后又为我们带来了一个全能的工具 jcmd; 它最重要的功能是启动 java flight recorder, 不过 oracle 在设计该命令的时候, “不小心” 为它附加上了一些其他功能, 从而将原本平静的水面搅起了波澜;","text":"曾经 oracle 向我们提供了一套 jvm 管理与诊断问题的 “工具全家桶”: jps, jstack, jmap, jstat, jhat, jinfo 等等, 我们针对不同的情景使用不同的工具, 解决特定的问题;现在, oracle 在 jdk7 之后又为我们带来了一个全能的工具 jcmd; 它最重要的功能是启动 java flight recorder, 不过 oracle 在设计该命令的时候, “不小心” 为它附加上了一些其他功能, 从而将原本平静的水面搅起了波澜; jcmd 工具的定位jcmd 是 jdk7 之后新增的工具, 它是 java flight recorder 的唯一启动方式, 详细的内容请见 java flight recorder 的使用; 不过, oracle 顺手又为其附带了一些 “便捷” 小工具: 列举 jvm 进程 (对标 jps) dump 栈信息 (对标 jstack) dump 堆信息 (对标 jmap -dump) 统计类信息 (对标 jmap -histo) 获取系统信息 (对标 jinfo) 这样一下子就有意思了, jcmd 似乎有了想要取代其他命令的野心; 下面来具体介绍一下 jcmd 都能顺手做些什么事情; jps 类似功能jcmd 命令不带任何选项或者使用 -l 选项, 都可以打印当前用户下运行的虚拟机进程;1234# jpssudo -u xxx jps -l# jcmdsudo -u xxx jcmd [-l] 查看 jcmd 对指定虚拟机能做的事情jcmd 确实神通广大, 但是再厉害的大夫也得病人配合工作才行, 比如在低版本 jre 上跑的程序肯定无法使用 flight recorder 抓 dump;当使用 jcmd 拿到了目标 vmid 后, 使用如下命令可以查看 jcmd 对目标 jvm 能够使用的功能:1sudo -u xxx jcmd &#123;vmid&#125; help 输出可以使用的功能列举如下:1234567891011121314151617181920212223242526272829303132333435# flight recorder 相关功能JFR.stopJFR.startJFR.dumpJFR.check# jmx 相关功能ManagementAgent.stopManagementAgent.start_localManagementAgent.start# jstack 相关功能Thread.print# jmap 相关功能GC.class_statsGC.class_histogramGC.heap_dump# jinfo 相关功能VM.flagsVM.system_propertiesVM.command_lineVM.version# gc 相关GC.run_finalization # System.runFinalization()GC.run # System.gc()GC.rotate_log # 切割 gc log# 其他VM.native_memoryVM.check_commercial_featuresVM.unlock_commercial_featuresVM.uptime jstack 类似功能1sudo -u xxx jcmd &#123;vmid&#125; Thread.print 以上命令输出的内容与以下使用 jstack 命令的输出一致:1sudo -u xxx jstack -l &#123;vmid&#125; jmap 类似功能与 jmap 相关的功能主要是以下四类:(1) 堆区对象的总体统计12# jmap 的实现sudo -u xxx jmap -heap &#123;vmid&#125; jcmd 没有提供与 jmap -heap 类似的功能; (2) 堆区对象的详细直方图统计1234# jcmd 的实现sudo -u xxx jcmd &#123;vmid&#125; GC.class_histogram# jmap 的实现sudo -u xxx jmap -histo[:live] &#123;vmid&#125; (3) metaspace 的信息统计1234# jcmd 的实现sudo -u xxx jcmd &#123;vmid&#125; GC.class_stats# jmap 的实现sudo -u xxx jmap -clstats &#123;vmid&#125; 虽然都是关于 jdk8 metaspace 的信息统计, 不过 jcmd GC.class_stats 与 jmap -clstats 的输出内容没什么关联;另外, 使用 jcmd GC.class_stats 功能, 需要开启 jvm 选项 UnlockDiagnosticVMOptions; (4) 堆区对象的 dump1234# jcmd 的实现sudo -u xxx jcmd &#123;vmid&#125; GC.heap_dump &#123;file_path&#125;# jmap 的实现sudo -u xxx jmap -dump[:live],format=b,file=&#123;file_path&#125; &#123;vmid&#125; jinfo 类似功能与 jinfo 相关的功能主要是以下两类:(1) 打印 jvm 的系统信息, 包括系统参数, 版本等12345# jcmd 的实现sudo -u xxx jcmd &#123;vmid&#125; VM.system_propertiessudo -u xxx jcmd &#123;vmid&#125; VM.version# jmap 的实现sudo -u xxx jinfo -sysprops &#123;vmid&#125; (2) 打印 jvm 的选项1234# jcmd 的实现sudo -u xxx jcmd &#123;vmid&#125; VM.command_line# jmap 的实现sudo -u xxx jinfo -flags &#123;vmid&#125; (3) 修改 jvm 的选项123456# jcmd 的部分实现sudo -u xxx jcmd &#123;vmid&#125; VM.unlock_commercial_featuressudo -u xxx jcmd &#123;vmid&#125; VM.check_commercial_features# jmap 的实现sudo -u xxx jinfo -flag [+|-]&#123;option_name&#125; &#123;vmid&#125;sudo -u xxx jinfo -flag &#123;option_name&#125;=&#123;value&#125; &#123;vmid&#125; 关于修改 jvm 选项, 只能说 jcmd 几乎是没有相关的功能, 其只能操控与 flight recorder 配套的 UnlockCommercialFeatures 选项而已; jcmd 使用总结往不好听的讲, 除了 java flight recorder 之外, jcmd 其余的功能只能说是 “鸡肋”: 只有 jps, jstack 可以算完全覆盖了其相关功能, jmap 勉强可以算覆盖了其相关功能;除此之外, jinfo 的部分功能没有实现, jstat 的所有功能都没有实现; 而且 jcmd 的选项名字一般都比较长, 不容易记住, 必须依赖 jcmd {vmid} help 打印相关内容, 给使用带来了不便;总体来说, 除了 java flight recorder 必须要使用 jcmd 之外, 其余的功能暂时还是建议使用传统的工具来解决问题; jcmd 的野心还得继续培养, 等以后 oracle 发布新版本的时候再继续观察吧; 站内相关文章 java flight recorder 的使用 参考链接 jcmd命令详解","categories":[{"name":"jvm","slug":"jvm","permalink":"http://zshell.cc/categories/jvm/"},{"name":"tools","slug":"jvm/tools","permalink":"http://zshell.cc/categories/jvm/tools/"}],"tags":[{"name":"jvm:tools","slug":"jvm-tools","permalink":"http://zshell.cc/tags/jvm-tools/"}]},{"title":"saltstack cheat sheet","slug":"saltstack--saltstack_cheat_sheet","date":"2017-05-13T13:42:21.000Z","updated":"2018-01-27T14:53:07.577Z","comments":true,"path":"2017/05/13/saltstack--saltstack_cheat_sheet/","link":"","permalink":"http://zshell.cc/2017/05/13/saltstack--saltstack_cheat_sheet/","excerpt":"本文主要整理日常 saltstack 使用时的最常用的一些命令,以供快速查阅;","text":"本文主要整理日常 saltstack 使用时的最常用的一些命令,以供快速查阅; 自由度最大的模块: cmd 模块适用于登录 salt master 机器, 人工操作时执行;123456# cmd.run: 在 minions 上执行任意命令sudo salt * cmd.run \"ls -l /etc/localtime\"sudo salt * cmd.run uptime# cmd.script: 在 master 上下发任意脚本至 minions 执行sudo salt * cmd.script salt://minion_exeute.sh \"args1 args2\" 控制 minions 的定时任务执行情况: cron 模块123456# 查看指定用户的 cron 内容sudo salt * cron.raw_cron root# 为指定用户添加指定任务sudo salt * cron.set_job root '*' '*' '*' '*' '*' /home/minion_execute.sh 1&gt;/dev/null# 为指定用户删除指定任务sudo salt * cron.rm_job root '*' '*' '*' '*' '*' /home/minion_execute.sh 1&gt;/dev/null master 与 minions 的文件传输: cp 模块1234567# 推送文件到 minions 指定路径 (只能推送文件, 不能推送目录)sudo salt * cp.get_file salt://target_file /minion_path# 推送目录到 minions 指定路径suod salt * cp.get_dir salt://target_dir /minion_path# 下载指定 url 的内容到 minions 指定路径 (不限于本地路径, 更加广泛)sudo salt * cp.get_url salt://target_file /minion_pathsudo salt * cp.get_url https://d3kbcqa49mib13.cloudfront.net/spark-2.2.0-bin-hadoop2.7.tgz /minion_path 服务启停控制: systemd 模块salt.modules.systemd 模块是以 systemd 与 systemctl 为基础的, 尽管其命令多以 serice 开头, 不过该模块和 sysvinit 的 service 命令应该没什么关系;12345678# 分别对应了 systemctl [enable, disable, start, stop, status, restart] httpd.servicesudo salt * service.enable httpdsudo salt * service.disable httpdsudo salt * service.start httpdsudo salt * service.stop httpdsudo salt * service.status httpdsudo salt * service.restart httpd 远程文件控制相关: file 模块12345678910111213# 创建文件sudo salt * file.touch /opt/rsync_passwd# 创建目录sudo salt * file.mkdir /opt/rsync# 删除指定文件sudo salt * file.remove /opt/rsync_passwd# 删除目录sudo salt * file.rmdir /opt/rsync# sudo chown root:root /opt/rsync_passwdsudo salt * file.chown /opt/rsync_passwd root root# sudo chmod 600 /etc/rsync_passwdsudo salt * file.set_mode /etc/rsync_passwd 600 salt 常用的状态检测包括:master 与 minions 之间的连通性 check_ping 检查;minions salt version, dependency version, system version 检查;minions network ping 外网检查;磁盘容量 check_disk 检查;等等;12345678# 测试 salt 主从连通性sudo salt * test.ping# 打印 salt 的版本以及 salt 依赖的第三方组件的版本sudo salt * test.versions_report# 测试 minions 的网络 pingsudo salt * network.ping www.qunar.com# 查看 minions 的磁盘使用情况sudo salt * disk.usage 参考链接 服务自动化部署平台之Saltstack总结 Saltstack系列3: Saltstack常用模块及API SALT.MODULES.FILE","categories":[{"name":"saltstack","slug":"saltstack","permalink":"http://zshell.cc/categories/saltstack/"}],"tags":[{"name":"运维自动化","slug":"运维自动化","permalink":"http://zshell.cc/tags/运维自动化/"},{"name":"cheat sheet","slug":"cheat-sheet","permalink":"http://zshell.cc/tags/cheat-sheet/"},{"name":"saltstack","slug":"saltstack","permalink":"http://zshell.cc/tags/saltstack/"}]},{"title":"du / df 使用及其区别","slug":"linux-disk--du_df使用及其区别","date":"2017-04-07T14:58:04.000Z","updated":"2018-04-06T13:22:05.098Z","comments":true,"path":"2017/04/07/linux-disk--du_df使用及其区别/","link":"","permalink":"http://zshell.cc/2017/04/07/linux-disk--du_df使用及其区别/","excerpt":"本文主要是整理 磁盘使用量 相关的命令, 如 du, df 等;接着, 一般性得总结这两个命令在实际工作中的应用;然后再以 du, df 命令的区别为例, 讨论命令背后的逻辑, 工作中存在的问题, 最后引申出问题解决的工具: lsof;","text":"本文主要是整理 磁盘使用量 相关的命令, 如 du, df 等;接着, 一般性得总结这两个命令在实际工作中的应用;然后再以 du, df 命令的区别为例, 讨论命令背后的逻辑, 工作中存在的问题, 最后引申出问题解决的工具: lsof; du命令 estimate disk file space usage. — man du du 的常用选项123456789101112# 不加任何选项, 默认是 列举指定路径下, 每一个目录(递归所有的子目录)的大小sudo du /target_path# 列举指定路径下所有的文件(包括目录与文件)的大小sudo du -a /target_path# 以 human-readable 的形式, 列举目标路径的文件磁盘占用总大小(将该路径下所有子文件大小求和)sudo du -s /target_path# 以指定路径下所有的子一级路径为 target, 以 human-readable 的方式列举其中每一个下的所有子文件大小之和# (诊断 磁盘满问题 最常用的方式)sudo du -sh /target_path/*# 除了其余选项该有的输出之外, 最后一行另附一个给定 target_path 下的 total 总和# 理论上这与目标路径不含通配符的 -sh 输出结果是相同的sudo du -c /target_path df 命令 file system disk space usage. — man df df 的常用选项123456789101112# 显示给定的路径所挂载的磁盘分区的大小及使用量等df /target_path# 以 MB 最小单位显示大小及使用量df --block-size=1m /target_pathdf -B 1m /target_path# 以 human-readable 的方式显示 当前挂载的所有可用健康的文件系统 的大小, 使用量等情况df -h # 1024df -H # 1000# 显示所有的文件系统, 包括 伪文件系统, 重复的, 不可访问的文件系统 (pseudo, duplicate, inaccessible)df -a# 过滤 nfs 远程文件系统后的本地文件系统df -l &nbsp;一般性总结:df 命令主要关心的是磁盘分区的 size, 而不是具体某文件的占用大小;所以 df 命令的主要运用场景是: df -h, 判断所挂载的每个分区的使用率, 是不是满了;作为先决判断依据, 如果发现磁盘满了, 再接着使用 du -sh 等命令进一步排查;&nbsp; du 与 df 命令的区别df 命令与 du 命令的工作原理df 命令使用 系统调用 statfs, 获取磁盘分区的超级块 (super block) 使用情况;du 命令使用 系统调用 fstat, 获取待统计文件的大小; df 命令与 du 命令可接受范围内不一致[问题场景]: du -s 与 df 核算精确结果总有差异;&nbsp;[原因]: du -s 命令通过将指定文件系统中所有的目录, 符号链接和文件使用的块数累加得到该文件系统使用的总块数, 这是上层用户级的数据;df 命令通过查看文件系统磁盘块分配图得出总块数与剩余块数, 这是直接从底层获取的数据;所以, 一些元数据信息(inode, super blocks 等)不会被上层的 du 命令计入在内, 而 df 命令由于直接获取的底层超级块的信息, 则会将其计入在内;&nbsp;[结论]: 这种差异属于系统性的差异, 是由命令的特点决定的, 无法改变; df 命令与 du 命令显著不一致[问题场景]: 当一个被某进程持有其句柄的文件被删除后, 进程不释放句柄, du 将不会再统计该文件, 而 df 的使用量仍会将其计入在内;&nbsp;[原因]: 当文件句柄被进程持有, 尽管文件被删除, 目录项已经不存在该文件路径了, 但只要句柄不释放, 文件在磁盘上就不会真正删除该文件;这样一来, 目录项不存在该文件了, du 命令就不会统计到该文件, 但文件没真正删除, 磁盘分区 super block 的信息就不会改变, df 命令仍会将其计入使用量;&nbsp;[结论]: 这种差异属于第三方因素干扰导致的差异, 且差异十分显著, 需要通过下一节所讨论的方式加以解决; 问题解决方案磁盘满了, 但是有进程持有大文件的句柄, 无法真正从磁盘删除掉; 对于这类问题, 有如下两种解决方案:1.配合使用 lsof 找出相关的 幽灵文件 的句柄持有情况(command 与 pid):1234&gt; sudo lsof | grep deletednginx 4804 nobody 59u REG 253,1 110116 243425480 /usr/local/openresty/nginx/client_body_temp/0068359496 (deleted)nginx 4819 nobody 51u REG 253,1 115876 243425480 /usr/local/openresty/nginx/client_body_temp/0068359498 (deleted)... 然后 kill 掉进程 (或 restart 进程), 即可释放文件句柄;当然, 本文是以 nginx 举例, 但实际上 nginx 对于日志文件的文件句柄释放, 有自己专有的方法, 具体内容请见本站另外两篇文章: linux signals 总体认识#其他信号 和 nginx signals 处理;另外, 磁盘满的问题, 不能总是靠人肉登机器去解决, 我们需要一些自动化的方案来将我们从这种低级的操作中解放出来;所以, 对于所有机器上都会遇到的日志文件不断累积占满磁盘的问题, 这篇文章介绍了解决方案: logrotate 配置与运维;&nbsp;2.如果进程很重要, 不能容忍任何时间范围内的服务不可用 (其实理论上这种情况属于单点瓶颈, 未能做到高可用), 则可以采用如下方式:12# 将文件写空sudo echo &gt; file_path 将文件内容间接删除, 这样即便句柄未释放, 但文件本身已经没有内容, 也就不再占用空间了; 站内相关文章 logrotate 配置与运维 linux signals 总体认识#其他信号 nginx signals 处理 参考链接 df和du显示的磁盘空间使用情况不一致的原因及处理 linux lsof 详解","categories":[{"name":"linux","slug":"linux","permalink":"http://zshell.cc/categories/linux/"},{"name":"disk","slug":"linux/disk","permalink":"http://zshell.cc/categories/linux/disk/"}],"tags":[{"name":"linux:disk","slug":"linux-disk","permalink":"http://zshell.cc/tags/linux-disk/"}]},{"title":"linux signals 总体认识","slug":"linux-process--linux_signals总体认识","date":"2017-04-05T15:24:22.000Z","updated":"2018-01-20T12:10:14.216Z","comments":true,"path":"2017/04/05/linux-process--linux_signals总体认识/","link":"","permalink":"http://zshell.cc/2017/04/05/linux-process--linux_signals总体认识/","excerpt":"linux 的信号系统其实是一个非常重要的概念, 进程间通信的常用方法之一;不过长期以来, 我们对 linux 信号的直观认识, 只有 kill (SIGTERM), ctrl + c (SIGINT) 和 kill -9 等进程终止信号; 而 linux 的信号系统中存在 64 种各司其职的信号, 适用于各种各样的场景; 很多信号在实际工作中有着妙用;本文正是想对 linux 世界中林林总总的 signals 作一次梳理, 总结一些日常工作中频繁使用以及不太接触但十分有用的信号;","text":"linux 的信号系统其实是一个非常重要的概念, 进程间通信的常用方法之一;不过长期以来, 我们对 linux 信号的直观认识, 只有 kill (SIGTERM), ctrl + c (SIGINT) 和 kill -9 等进程终止信号; 而 linux 的信号系统中存在 64 种各司其职的信号, 适用于各种各样的场景; 很多信号在实际工作中有着妙用;本文正是想对 linux 世界中林林总总的 signals 作一次梳理, 总结一些日常工作中频繁使用以及不太接触但十分有用的信号; linux signals 总览linux siginal 可分为如下几大类: 系统错误信号 进程终止信号 作业控制信号 AIO 信号 定时器信号 操作错误信号 其他信号 &nbsp;linux signals 的产生源一般分为三类: 硬件方式(除数为 0, 内存非法访问等), IO 方式(键盘事件), 以及软件方式: kill 命令, alarm 定时器等;其中我们最熟悉的莫不过 kill 命令了, 详情请见: kill 命令族及其选项; &nbsp;使用 kill -l 查看所有信号分布:1234567891011121314&gt; kill -l 1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP 6) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL 10) SIGUSR111) SIGSEGV 12) SIGUSR2 13) SIGPIPE 14) SIGALRM 15) SIGTERM16) SIGSTKFLT 17) SIGCHLD 18) SIGCONT 19) SIGSTOP 20) SIGTSTP21) SIGTTIN 22) SIGTTOU 23) SIGURG 24) SIGXCPU 25) SIGXFSZ26) SIGVTALRM 27) SIGPROF 28) SIGWINCH 29) SIGIO 30) SIGPWR31) SIGSYS 34) SIGRTMIN 35) SIGRTMIN+1 36) SIGRTMIN+2 37) SIGRTMIN+338) SIGRTMIN+4 39) SIGRTMIN+5 40) SIGRTMIN+6 41) SIGRTMIN+7 42) SIGRTMIN+843) SIGRTMIN+9 44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+1348) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-1253) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9 56) SIGRTMAX-8 57) SIGRTMAX-758) SIGRTMAX-6 59) SIGRTMAX-5 60) SIGRTMAX-4 61) SIGRTMAX-3 62) SIGRTMAX-263) SIGRTMAX-1 64) SIGRTMAX 各类别信号整理进程终止信号进程终止信号是我们日常操作中最常用的一类信号;进程终止信号共有五个, 其中除了 SIGKILL 之外, 其他信号都是 可阻塞, 可忽略, 可处理的;12345678910111213# terminate, kill 不加任何选项的默认信号, 默认处理是终止进程;SIGTERM# interrupt, ctrl + c 发出的信号, 默认处理是终止进程;SIGINT# quit, ctrl + / 发出的信号, 与 SIGINT 类似, 不过其默认处理相比 SIGINT 还增加了一项:# 1. 终止进程; 2. 产生进程 core dump 文件;SIGQUIT# kill, 不可阻塞, 不可忽略, 最强力的终止信号, 通常会导致进程立即终止, 其占有的资源无法释放清理# 一般需要在 SIGTERM/SIGINT/SIGQUIT 等信号无法响应之后, 才最后使用SIGKILL# hang up, 通常在用户退出终端断开 sessiion 时由系统发出该信号给 session# session 接收该信号并将其发送给子进程SIGHUP 另外一篇详细梳理与 SIGHUP 相关知识点的链接: SIGHUP 相关全梳理;该文章主要涉及 SIGHUP 信号发生的条件, 传导, 与 SIGHUP 相关的 nohup, &amp;, shopt huponexit, disown 等概念, 并包括一些 SIGHUP 的自定义应用; 任务控制信号其他信号其他信号是指未在上述分类中的一些小众信号, 这些信号本身并未有太多关联, 不能用一个类别去统一描述它们;&nbsp;(1) 用户自定义信号: SIGUSR1 / SIGUSR2这两个信号, linux 保证系统自身不会向进程发送, 完全由使用者自己定义该信号的语义以及处理逻辑;SIGUSR1 与 SIGUSR2, 在系统层面完全没有区别, 如果可以, linux 其实能再定义一个 SIGUSR3; 所以用户自定义信号的预留数量, 本身是一个模糊的界定;以下是 SIGUSR1 / SIGUSR2 的具体使用场景:1234# 通知 nginx 关闭当前句柄, 重新打开日志文件, 用于 logrotate 切割日志kill -USR1 `cat /var/run/nginx.pid`# 通知 nginx 平滑升级 二进制可执行程序kill -s SIGUSR2 `cat /var/run/nginx.pid` &nbsp;(2) SIGWINCH (winch 译作: 吊车, 摇柄), 默认处理是忽略该信号;以下是 SIGWINCH 的具体使用场景:12# 通知 nginx worker process 不再接受新 request, 并从容关闭kill -WINCH `cat /var/run/nginx.pid` 当然, 通知 worker process 不再接受新请求, nginx 并不需要使用者直接在 linux signals 层面直接处理, nginx 本身提供了平滑重启命令 sbin/nginx -c conf/nginx.conf -s reload, SIGWINCH 信号的发送封装在了该命令里;&nbsp;关于 nginx 与 linux signals 的关系, 在本站另一篇文章中有详细介绍: nginx signals 处理; 站内相关文章 kill 命令族及其选项 SIGHUP 相关全梳理 nginx signals 处理 参考链接 24.2.2 Termination Signals 24.2.5 Job Control Signals 24.2.7 Miscellaneous Signals Difference between SIGUSR1 and SIGUSR2 linux kill 命令 以及 USR1 信号 解释 Linux 信号入门详解 文章3: Nginx中与信号有关的内容","categories":[{"name":"linux","slug":"linux","permalink":"http://zshell.cc/categories/linux/"},{"name":"process","slug":"linux/process","permalink":"http://zshell.cc/categories/linux/process/"}],"tags":[{"name":"linux:process","slug":"linux-process","permalink":"http://zshell.cc/tags/linux-process/"}]},{"title":"top 命令与操作及其参数指标总结","slug":"linux-process--top_命令与操作及其参数指标总结","date":"2017-03-16T10:59:15.000Z","updated":"2018-06-14T14:20:21.164Z","comments":true,"path":"2017/03/16/linux-process--top_命令与操作及其参数指标总结/","link":"","permalink":"http://zshell.cc/2017/03/16/linux-process--top_命令与操作及其参数指标总结/","excerpt":"排查系统性能问题时, 最尴尬的事情莫过于敲下 top 命令后, 看着不断跳动的界面, 愣是不知道接下来要怎么操作, 最后无奈得按下了一个 q;所以我专门写作本文, 系统性得整理一下 top 命令所展示的内容与结构, 常见操作快捷键与技巧; 虽然在 top 界面里按 h 便能进入帮助界面, 但那种操作排版比较密集, 信息量太大, 没有直观性;当然, 即使是这篇文章的内容, 我最好也熟记于心, 否则排查问题的时候还要查操作笔记, 也是件挺尴尬的事情;","text":"排查系统性能问题时, 最尴尬的事情莫过于敲下 top 命令后, 看着不断跳动的界面, 愣是不知道接下来要怎么操作, 最后无奈得按下了一个 q;所以我专门写作本文, 系统性得整理一下 top 命令所展示的内容与结构, 常见操作快捷键与技巧; 虽然在 top 界面里按 h 便能进入帮助界面, 但那种操作排版比较密集, 信息量太大, 没有直观性;当然, 即使是这篇文章的内容, 我最好也熟记于心, 否则排查问题的时候还要查操作笔记, 也是件挺尴尬的事情; top 命令的选项top 命令有丰富的选项可以使用, 常用的如以下几种:1234567# -u user, 指定展示的用户# -d delay, 指定刷新频率top -u nginx -d 1# -n iteration, 指定刷新多少次之后自动退出 top 命令# -p pid, 指定进程 idtop -n 20 -p &#123;pid1&#125; &#123;pid2&#125; ... 全局系统信息top 命令的界面被分为泾渭分明的两部分, 上半部分是全局类的信息, 展示 load, cpu, 内存, 进程数目统计等信息, 本节主要介绍的就是上半部分: 全局系统信息;12345top - 13:37:53 up 12 days, 23:30, 1 user, load average: 1.03, 0.80, 0.74Tasks: 262 total, 1 running, 259 sleeping, 0 stopped, 2 zombie%Cpu(s): 6.3 us, 1.9 sy, 0.0 ni, 88.4 id, 3.4 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 8062940 total, 2259668 free, 3244360 used, 2558912 buff/cacheKiB Swap: 5999612 total, 4462904 free, 1536708 used. 3654256 avail Mem 第一行是 uptime 信息; 第二行和第三行是 cpu 及进程信息; 第四行和第五行是 free 信息; cpu 全局统计信息全局的 cpu 统计信息, 主要存在于 top 命令的第三行:123456789# us user time# sy system time# ni niceness process time# id idle time# wa wait time# hi hardware interrupt time# si software interrupt time# st stole time, used in virtualization%Cpu(s): 5.8 us, 1.0 sy, 0.0 ni, 90.4 id, 2.8 wa, 0.0 hi, 0.0 si, 0.0 st 其中有几个比较重要的指标: user time 时间占比大, 说明用户空间内的 cpu 计算比较多, 这属于最常见的状态; system time 时间占比大, 说明 system call 系统调用比较多, 计算多在内核空间发生;这往往不是一个好的兆头, 如果伴随着系统的性能异常, 需要使用 strace 等命令追踪系统调用的状态;如果一个正常情况下 system time 很少的进程, 突然莫名其妙得 user time 与 system time 的差距达到了量级, 那么有相当的概率, 系统内核发生了性能问题, 比如进程上下文切换 (context switch) 频繁以及缺页 (page fault);如果一个进程每次启动都会造成很高的 system time, 那么很可能是进程内部的逻辑在执行某些耗时的 system call, 这一点在 火丁笔记的总结 里十分有代表性; idle time 时间占比很大, 说明 cpu 很闲, 时间多消耗在了闲置进程上; wait time 时间占比很大, 这十有八九是 cpu 等待 IO 设备的时间过长, 比较常见的是磁盘 IO 出现了吞吐瓶颈, 导致 cpu wait; 当然也有可能是网络适配器的带宽被打满了; 除此之外, 其余的几个指标, nice, hardware interrupt, software interrupt, stole, 相对来说要次重要一些, 对系统的影响有限; 全局系统信息 快捷键 按小写 l (字母) 可以显示/隐藏 uptime 信息; 连续按 t 可以切换四种(包括隐藏) cpu 信息的显示方式; 按小写 1 (数字) 可以详细显示 cpu 的每一个 core 的状态统计信息; 连续按 m 可以切换四种(包括隐藏) free 信息的显示方式; 连续按 E 可以切换 KB, MB, GB, TB, PB, EB 六种 free 信息显示的单位; 进程详细信息top 命令的界面被分为泾渭分明的两部分, 下半部分是进程的详细信息, 展示特定进程的 cpu, 内存, 命令等信息, 本节主要介绍的就是下半部分: 进程详细信息;123456PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND1 root 20 0 44752 6880 3504 S 0.0 0.2 2:29.89 systemd2 root 20 0 0 0 0 S 0.0 0.0 0:00.20 kthreadd3 root 20 0 0 0 0 S 0.0 0.0 0:06.73 ksoftirqd/05 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0H7 root rt 0 0 0 0 S 0.0 0.0 0:00.36 migration/0 第一行的字段含义123456789PR: priorityNI: niceVIRT: virtual mem, 虚拟内存RES: resident mem, 常驻内存SHR: shared mem, 共享内存S: state: R(running), S(sleep), Z(zombie), T(terminate)%CPU: cpu 综合使用量%MEM: 内存 综合使用量TIME+: 进程的 cpu 时间 其中:PR 为 rt 代表进程运行在实时态;VIRT = RES + SWAP;RES = CODE + DATA = SHR + 程序自身所占的物理内存; 进程详细信息 快捷键 V 以树形结构显示各进程; c 详细/简略 显示 COMMAND 列的信息(带命令参数与否); enter/space 立即刷新指标; e 连续敲击 可以切换 KB, MB, GB, TB, PB 五种内存显示(VIRT, RES, SHR)的单位; d/s 改变 top 命令刷新指标的频率, 会出现交互提示, 输入指定的时间; 默认是 3s; M 以内存使用率从大到小排序; P 以 CPU 使用率从大到小排序; k kill 掉指定的进程, 会出现交互提示, 先输入 pid, 再输入 signal id; 注意, 第 8 条 kill 指定进程, 一定要以启动进程的用户执行 top 命令才有权限 kill 它; 或者更统一的, 直接用 sudo 执行 top 命令, 就有权限 kill 指定进程了; 参考链接 User space 与 Kernel space 你不一定懂的cpu显示信息 TOP命令详解 程序如何影响VIRT (虚存) 和 RES (实存/常驻内存) 火丁笔记 tag: strace","categories":[{"name":"linux","slug":"linux","permalink":"http://zshell.cc/categories/linux/"},{"name":"perf","slug":"linux/perf","permalink":"http://zshell.cc/categories/linux/perf/"}],"tags":[{"name":"linux:perf","slug":"linux-perf","permalink":"http://zshell.cc/tags/linux-perf/"},{"name":"系统性能诊断","slug":"系统性能诊断","permalink":"http://zshell.cc/tags/系统性能诊断/"}]},{"title":"python 模块导入: 相关基础知识梳理","slug":"python--python模块导入_相关基础知识梳理","date":"2017-03-12T13:35:04.000Z","updated":"2018-02-25T01:47:57.445Z","comments":true,"path":"2017/03/12/python--python模块导入_相关基础知识梳理/","link":"","permalink":"http://zshell.cc/2017/03/12/python--python模块导入_相关基础知识梳理/","excerpt":"python 有一个关键字和 java 一样: import, 其功能也类似: 在代码中引入其他的依赖(模块)以使用;不过, 不像 java 那么单纯, python 还要区分为 import module 和 import names 两大类; 作为一个 python 新手, 这些使用上的区别有时会令人感到迷惑;python 包和 java 包在概念上也有类似之处, 不过 python 的 __init__.py 规范更讲究一些, java 的 package-info.java 重要性没有那么强, python 初学者在此也很容易栽跟头;在使用了一段时间的 python 之后, 我突然发现, 关于模块引入相关的知识, 我还从来没有过一个系统性的整理; 故作此文以备将来查阅;","text":"python 有一个关键字和 java 一样: import, 其功能也类似: 在代码中引入其他的依赖(模块)以使用;不过, 不像 java 那么单纯, python 还要区分为 import module 和 import names 两大类; 作为一个 python 新手, 这些使用上的区别有时会令人感到迷惑;python 包和 java 包在概念上也有类似之处, 不过 python 的 __init__.py 规范更讲究一些, java 的 package-info.java 重要性没有那么强, python 初学者在此也很容易栽跟头;在使用了一段时间的 python 之后, 我突然发现, 关于模块引入相关的知识, 我还从来没有过一个系统性的整理; 故作此文以备将来查阅; 下面所示的是一个 python 工程结构, 包括了一个父 package 和其下的子 package , 结构比较完整; 本文将以此工程结构为例, 展开内容;123456789101112131415MyPackage ├── connections.py ├── constants │ ├── CLIENT.py │ ├── CR.py │ ├── ER.py │ ├── FIELD_TYPE.py │ ├── FLAG.py │ ├── __init__.py │ ├── REFRESH.py ├── converters.py ├── cursors.py ├── __init__.py ├── release.py ├── times.py 其中, 假设 connections.py 中定义了 Connection 类:12345# connections.pyimport _mysqlclass Connection(_mysql.connection): def __init__(self, *args, **kwargs): ... 下面开始本文的内容; 基础预备知识对象的 __name__ 字段所有 python 程序的执行必须要有一个入口, 而我们经常见到的入口会有这么一行代码:1if __name__ == '__main__': 这里面涉及到了一个模块的属性: __name__:当一个模块以主模块被执行时, 该模块的 __name__ 就被解释器设定为 ‘__main__’;当一个模块被其他模块引入时, 该模块的 __name__ 就被解释器设定为 ‘该模块的文件名’; 内建方法: dir()python 中有一个全局内建方法 dir(p_object=None) 可以返回目标作用域里所有的成员 (names);当方法参数 p_object 为 None 时, 默认返回当前作用域内的所有成员:1234# 在 python shell 里执行, 作用域为主模块, 展示模块属性&gt;&gt;&gt; import MyPackage&gt;&gt;&gt; dir()['MyPackage', '__builtins__', '__doc__', '__name__', '__package__'] 123456789# 在方法内部执行, 作用域为方法内, 展示方法的字段def print_dir(num=1, str=None): print dir() if __name__ == '__main__': print_dir()output:['num', 'str'] 如果指定了目标作用域(对象), 则无论在哪里指定 dir () 方法, 都只打印指定目标的成员;1234567891011from MyPackage.connections import Connection# 指定作用域def print_dir(obj=None): print dir(obj)if __name__ == '__main__': conn = Connection() print_dir(conn)output:['__doc__', '__init__', '__module__'] import 的规则语法python 导入其他模块分为两种: import module/package 与 import names (包括变量, 函数, 类等);import module/package 的语法如下:12import MyPackageimport MyPackage.connections import names 的语法如下:123456# 引入类from MyPackage.connections import Connection# 引入方法from MyPackage.connections import numeric_part# 引入 __all__ 指定的所有 namesfrom MyPackage import * 对于不同的 package, 不同的 __init__.py 文件, 这些 import 语句所产生的效果都不尽相同, 详细的区别将在下一节描述; __init__.py 文件的功能对于 python 的每一个包来说, __init__.py 是必须的, 它控制着包的导入行为, 并可以表达非常丰富的信息; 如果没有 __init__.py 文件, 那这个包只能算是一个普通目录, 目录下的任何 python 文件都不能作为模块被导入;以下是几种常见的 __init__.py 文件的内容: __init__.py 文件内容为空__init__.py 文件必须有, 但可以是空文件, 这将是最简单的形式, 当然其所提供的功能也最简单: 标识这是一个 python 包, 仅此而已;如果将该包作为一个模块导入, 其实是等于什么都没导入:12345&gt;&gt;&gt; import MyPackage&gt;&gt;&gt; dir()['MyPackage', '__builtins__', '__doc__', '__name__', '__package__']&gt;&gt;&gt; dir(MyPackage)['__builtins__', '__doc__', '__file__', '__name__', '__package__', '__path__'] 通过 dir() 内建方法可以发现, 无论是当前主模块, 还是 MyPackage 包, 除了一些保留 names, 不再有其他任何自定义符号, 这时将无法直接使用 MyPackage 下的任何模块:12345# 直接 使用 connections.py 下的 Connection 类&gt;&gt;&gt; conn = MyPackage.connections.Connection()Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;NameError: name 'MyPackage' is not defined 不过, 既然 __init__.py 已经标识了这是一个 python 包, 所以对于包下所有其他的模块文件, 我们可以主动引入它们, 这算是空 __init__.py 的唯一作用:123456# 主动引入模块&gt;&gt;&gt; import MyPackage.connections&gt;&gt;&gt; dir(MyPackage)['__builtins__', '__doc__', '__file__', '__name__', '__package__', '__path__', 'connections']&gt;&gt;&gt; dir(MyPackage.connections)['Connection', '__builtins__', '__doc__', '__file__', '__name__', '__package__', 'numeric_part'] 这时可以发现, dir(MyPackage) 列表里有了 connections 模块, dir(MyPackage.connections) 列表里有了 Connection 类; 这时带着 python 路径, 就可以使用 target name 了:1&gt;&gt;&gt; conn = MyPackage.connections.Connection() 另外, 如果使用 from … import … 主动引入目标符号:123&gt;&gt;&gt; from MyPackage.connections import Connection&gt;&gt;&gt; dir()['Connection', '__builtins__', '__doc__', '__name__', '__package__'] 便可以直接将目标符号引入当前作用域, 不需要使用模块路径, 就可以直接使用:1&gt;&gt;&gt; conn = Connection() 在 __init__.py 中 import 其他模块__init__.py 中自己主动 import 第三方模块是一种常见的操作:12# __init__.pyimport connections 12345&gt;&gt;&gt; import MyPackage&gt;&gt;&gt; dir(MyPackage)['__builtins__', '__doc__', '__file__', '__name__', '__package__', '__path__', 'connections']# 路径是 MyPackage.connections&gt;&gt;&gt; conn = MyPackage.connections.Connection() 或者使用 from … import … 语法:12# __init__.pyfrom connections import Connection 12345&gt;&gt;&gt; import MyPackage&gt;&gt;&gt; dir(MyPackage)['Connection', '__builtins__', '__doc__', '__file__', '__name__', '__package__', '__path__', 'connections']# 路径是 MyPackage&gt;&gt;&gt; conn = MyPackage.Connection() 对于以上两种 import 方式, 结合 dir() 内建方法的展示, 可以发现在具体使用目标符号时所带路径的区别; __init__.py 中的保留字段(1) __all__ 字段:如果在代码中使用了如下的引用方式:1from MyPackage import * 解释器便会试图去指定的模块中寻找 __all__ 字段, 将该列表中列举的所有 names 全部引入:12345678910__all__ = [ 'BINARY', 'Binary', 'Connect', 'Connection', 'DATE', 'Date', 'Time', 'Timestamp', 'DateFromTicks', 'TimeFromTicks', 'TimestampFromTicks', 'DataError', 'DatabaseError', 'Error', 'FIELD_TYPE', 'IntegrityError', 'InterfaceError', 'InternalError', 'MySQLError', 'NULL', 'NUMBER', 'NotSupportedError', 'DBAPISet', 'OperationalError', 'ProgrammingError', 'ROWID', 'STRING', 'TIME', 'TIMESTAMP', 'Warning', 'apilevel', 'connect', 'connections', 'constants', 'converters', 'cursors', 'debug', 'escape', 'escape_dict', 'escape_sequence', 'escape_string', 'get_client_info', 'paramstyle', 'string_literal', 'threadsafety', 'version_info'] 不过, 这种情况下不能完全清楚引入了什么 names, 有可能覆盖自己定义的 names, 最好谨慎使用;(2) 其他信息, 如版本, 作者:12345# 作者__author__ = \"Andy Dustman &lt;farcepest@gmail.com&gt;\"# 版本信息version_info = (1,2,5,'final',1)__version__ = \"1.2.5\" 在 __init__.py 中定义方法/类__init__.py 也是 python 源文件, 在其中亦可以定义方法, 类, 或者执行代码段:123456# MyPackage: __init__.pydef test_DBAPISet_set_equality(): assert STRING == STRING def Binary(x): return str(x) 此时, import 了 MyPackage 之后, 便可以正常使用定义的内容; python 的工作/搜索路径当导入一个 python 模块时, 解释器的查找路径如下: 在当前的包中查找; 在 __buildin__ 模块中查找; 在 sys.path 给定的路径中中查找; 其中, 第一点自不必说;关于 __buildin__ 模块, 更多的信息请参见另一篇文章: python module 使用总结: __buildin__; 上文描述的 dir() 方法其实就是 __buildin__ 模块中的内建方法, 不需要额外引入其他模块便能直接使用;而关于 sys.path, 其初始构成内容又包含了以下几处地方: 程序的主目录; PYTHONPATH 中定义的路径; 标准链接库, 例如: /usr/lib/python2.7, /usr/local/lib/python2.7 等; 123&gt;&gt;&gt; import sys&gt;&gt;&gt; sys.path['', '/usr/lib64/python27.zip', '/usr/lib64/python2.7', '/usr/lib/python2.7/plat-linux2', '/usr/lib/python2.7/lib-tk', '/usr/lib/python2.7/lib-old', '/usr/lib/python2.7/lib-dynload', '/usr/lib/python2.7/site-packages', '/usr/lib/python2.7/site-packages'] 如上所述, 从运行主模块的角度考虑: 如果引入的模块是第三方模块, 那么大部分情况下, 所需要的模块在标准链接库 dist-packages 中都有, python 能够成功引到; 如果引入的模块是自己的子模块, 由于子模块一定在主模块的子目录下, 所以 python 也能成功引到; 如果引入的模块是自己的父模块或者兄弟模块, 这时 python 能否成功引到, 就得分情况了: 如果工程在自己创建的目录中运行, 引入父模块或者兄弟模块, 在默认的搜索路径里是找不到的;这时要想成功引到目标模块, 有两种办法:(1) 向 sys.path 中拓展添加目标路径:12import syssys.path.append(os.path.abspath('xxx/yyy/zzz')) (2) 使用 PYTHONPATH, 向其中添加目标路径:123# /etc/profileexport PATH=$&#123;PATH&#125;:$&#123;target_path&#125;export PYTHONPATH=$&#123;PYTHONPATH&#125;:$&#123;target_path&#125; 至于这两种方法的好坏, 就是仁者见仁, 智者见智的问题了;使用 sys.path.append, 比较灵活, 每个模块都可以自己定义, 但缺点是需要多添加两行代码, 比较繁琐;使用 PYTHONPATH, 优点是不需要在自己的模块中添加额外的代码, 但是如果自己创建的工程路径比较零散, PYTHONPATH 就需要不停地补充新路径;不过, 如果有诸如公司规范之类的, 将 python 项目都部署在约定的公共目录下, 那么 PYTHONPATH 只需要添加这一个公共路径即可, 这样问题便简单了;&nbsp;至此, 关于 python 模块导入的基础性问题就讲完了;最后要说的是, 其实本文最开始所列出的那个自定义模块 MyPackage, 其原型是 MySQLdb; 站内相关文章 python module 使用总结: __buildin__ 参考链接 Python 中 if __name__ == ‘__main__’ 理解 Python 中的包 ImportError python import 工程内模块显示错误 Python模块包中__init__.py文件的作用 Be Pythonic: __init__.py Python类、模块、包的区别 Python环境变量PYTHONPATH设置","categories":[{"name":"python","slug":"python","permalink":"http://zshell.cc/categories/python/"}],"tags":[{"name":"python:module","slug":"python-module","permalink":"http://zshell.cc/tags/python-module/"}]},{"title":"http status code 典型问题总结","slug":"web--http_status_code_典型问题总结","date":"2017-03-06T15:27:25.000Z","updated":"2018-06-14T11:16:50.931Z","comments":true,"path":"2017/03/06/web--http_status_code_典型问题总结/","link":"","permalink":"http://zshell.cc/2017/03/06/web--http_status_code_典型问题总结/","excerpt":"本人根据自身的工作经历, 以一个 java dev 的视角, 总结了一些 http status code 的常见问题, 原因及解决办法;这些问题涉及到的系统或技术栈包括了 nginx, tomcat, spring(springMVC), elasticsearch 等等;","text":"本人根据自身的工作经历, 以一个 java dev 的视角, 总结了一些 http status code 的常见问题, 原因及解决办法;这些问题涉及到的系统或技术栈包括了 nginx, tomcat, spring(springMVC), elasticsearch 等等; 由于 http status code 众多, 而本人经验有限, 故不可能将所有问题覆盖全面; 另外, RFC 标准里定义的各种 status code 规范, 未必在各种主流的 web 容器内作具体实现;所以本文先将各种见过的没见过的 status code 列下来, 然后查漏补缺, 以后如果遇到相关问题, 就及时更新本文, 记录下来, 而没遇到过的 status code, 暂且先放着占个坑位吧; 3XX 重定向系列301 Moved Permanently302 Found303 See Other304 Not Modified304 未修改 发生的过程一般如下: 某个 response header 中携带了一个头: last-modified, 其值为该请求内容最后更新的时间; 当客户端再次请求同样的资源时, 将从上次请求的缓存中查询 last-modified 的值, 并在当前的 request header 中附加一个 if-modified-since 头, value 同 last-modified; 当 server 端发现 request header 中携带了 if-modified-since, 会判断其值是否与当前请求资源的修改时间比落后, 如果是则返回该资源的最新内容, 并将 last-modified 更新为当前时间, status code 为 200; 若不落后, 就会返回 304, 告知客户端原缓存资源可以继续使用; 正常情况下如果是在 chrome 里访问发生了 304, 那么 ctrl + F5 强刷页面可以让 request header 中不带上 if-modified-since, 从而避免了返回 304;还有一种特殊的情况也会遇到 304: http get 方法在 body 中携带数据;野路子走多了就成了正道, 理论上 get 方法在 body 携带数据是符合 RFC 标准的, 但多半会被 server 端半路截断, 不分青红皂白就认为你请求了相同的内容, 直接返回 304;所以为了避免此类问题, 凡是需要携带数据的访问: 要么用 post, 要么 get 时将 data 追加在 url 后面;&nbsp; 307 Temporary Redirect4XX 客户端错误系列4XX 为客户端请求错误相关的 status code;以下为各种 4XX status code 的含义以及可能的对应于常用 web server tomcat 或常用 web 框架 springMVC, 返回此 code 的原因;其中, tomcat 的版本为 7.0.47.0, springMVC 的版本为 4.1.8.RELEASE;另外, 本节内容也包含一些非标准的 nginx 自定义 error code, 我会单独注明;&nbsp; 400 Bad Request对一般的 sprinMVC 工程来说, 400 是请求参数错误, 参数个数与接口不匹配或者参数名与 api 要求不符;&nbsp; 401 Unauthorized请求未认证, 如果服务端需要用户密码认证而 request 未携带相关 header 则会返回此 code;如果是 chrome 收到 401, 便会弹出内置的登陆框, 让用户输入用户密码;如果需要手动发送 http 请求作认证, 需加入如下header:12# base64_encoded_content 是 username=password 被 BASE64 编码后的序列Authorization: Basic base64_encoded_content 其中有两个注意点: Authentication header 的 value 必须是以 Basic 为前缀, 空一格后跟着 BASE64 编码的内容; BASE64 编码的内容是 username=password, 其中间的 = 不能少; 最方便的生成该编码的方法就是使用 chrome 或者 postman 自动生成, 然后查看 code 即可; &nbsp; 403 Forbidden禁止访问(非法访问), 一般请求认证失败后返回此 code;&nbsp; 404 Not Found找不到资源, 一般在 springMVC 工程里, 这种错误遇到的常见的情况是请求静态资源 (例如 healthcheck.html) 发生 404;通常这种错误的原因是 springMVC 的 DispatcherServlet 拦截了所有的请求, 但是对静态资源的请求却又找不到路由处理器, 从而报出 404;解决的方案主要有三种:(1) web.xml 里配置 tomcat 的 default servlet:1234&lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;*.html&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 另外, 除了 *.html 之外, 其他静态资源亦可一并配置:123456789101112&lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;*.js&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;*.css&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;*.jpg&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 此配置需放在 DispatcherServlet 前面从而在 springMVC 之前被拦截; (2) 在 mvc-context.xml 中配置 mvc namespace 下的 default-servlet-handler 标签:1&lt;mvc:default-servlet-handler/&gt; (3) 在 mvc-context.xml 中配置 mvc namespace 下的 resources 标签:1&lt;mvc:resources mapping=\"/**\" location=\"/\"/&gt; &nbsp; 405 Method Not Supported&nbsp; 406 Not Acceptable服务器端无法提供客户端在 Accept header 中给出的媒体类型; 在springMVC 工程里, 这种比较常见的情况, 一般和 json 有关, 往往还需要前端 (比如 ajax) 配合; 因为, 普通的请求, request 报文里一般不会指明 Accept header, 那么无论后端返回什么, 哪怕是报错也好, 都不至于造成 406; 而对于如下 ajax 请求:12345678$.ajaxFileUpload(&#123; data: fetch_form_data('form_id'), url: '/xxx/yyy/zzz' type: 'post', dataType: 'json', // 指定了 Accept header 为 application/json success: function(data) &#123; ... &#125;, error: function(data, status, e) &#123; ... &#125;&#125;); 可以看到, 该 ajax 请求指定了 dataType 为 json, 这会在该 ajax 构造的 request 中追加 Accept header, value 为 application/json, 这就要求服务器端必须返回 json 类型的数据;然后在后端 springMVC 工程里, 有如下几种情况可能会造成 web server 认为无法提供客户端指定的媒体类型:(1) Controller 里的方法上没加 @ResponseBody 注解, 导致 springMVC 未能根据方法返回值正确推断媒体类型:123456@RequestMapping(value = \"/xxx\", method = RequestMethod.POST)@ResponseBody // 该注解使得 springMVC 框架认为该请求需要转化为 json (should be bound to the web response body)public WebResponse handleRequest(@RequestParam(\"xxx\") String xxx) &#123; ...... return WebResponse.success(instance);&#125; 或者更干脆的, 可以对该 Controller 直接使用 @RestController 注解, 相当于让所有的方法都被自动加上了 @ResponseBody:12345678910/** * A convenience annotation that is itself annotated with &#123;@link Controller @Controller&#125; * and &#123;@link ResponseBody @ResponseBody&#125;. */@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Controller@ResponseBodypublic @interface RestController &#123; ... &#125; (2) mvc-context.xml 中, 没有注册 “注解驱动”:1&lt;mvc:annotation-driven/&gt; 这个注解驱动的功能是如此之强大以至于在一般的 springMVC 项目中都不会落下它, 顶多就是覆盖其中部分设置以作微调 (详细的内容请参考: &lt;mvc:annotation-driven/&gt; 所做事情的详细梳理);当然, 如果不想被 &lt;mvc:annotation-driven/&gt; 支配而又要避免 406 错误, 就需要主动注入 RequestMappingHandlerAdapter, 而这是一个十分复杂的 bean, 所以并不建议这么搞;(3) 如果第一点和第二点都没有问题却依然报 406 的话, 那么极有可能是 jackson 相关依赖的版本兼容性问题; 在默认的负责读写 json 的 MappingJackson2HttpMessageConverter 中 (v4.1.8.RELEASE), 有这么一句注释: Compatible with Jackson 2.1 and higher. 而我在更高的 spring 版本里(比如 master), jackson 的最低兼容版本已经到了 2.9; 可见, 如果项目里的 jackson 版本不能与 spring 保持同步, 便极有可能导致序列化/反序列化失败, 进而导致 406 错误;&nbsp; 407 Proxy Authentication Required408 Request Timeout409 Confilct410 Gone411 Length Required412 Precondition Failed413 Entity Too Large414 Request-URI Too Long415 Not supported media type416 Requested Range Not Satisfiable417 Expectation Failed428 Precondition Required429 Too Many Requests431 Request Header Fields Too Large&nbsp; 499 client has closed connection (nginx 自定义 code)当客户端访问 nginx 代理的域名, 如果其设置的 timeout 时间比较短, 小于 nginx 在该域名的 server 作用域下设置的 proxy_xxx_timeout 值, 便有可能在长时间等待后主动 timeout, 断开与 nginx 的 tcp 连接;当 nginx 检测到客户端主动断开 tcp 连接后, 便会在日志里面记录 499 status code;如果客户端设置的 timeout 时间足够长, 那么应该在 nginx 设置的 proxy_xxx_timeout 时间之后, 返给客户端 504 (Gateway Timeout);另外, 499 还有一种情况是客户端故意将 timeout 设置的很短, 频繁访问以消耗服务器资源; 5xx 服务端系列500 Internal Server Error501 Implemented502 Bad Gateway503 Service Unavailable504 Gateway Timeout505 HTTP Version Not Supported511 Network Authentication Required站内相关文章 &lt;mvc:annotation-driven/&gt; 所做事情的详细梳理 参考链接 http 状态码 记一次Content-Length引发的血案 哪些情况下会使Nginx返回HTTP CODE 499","categories":[{"name":"web","slug":"web","permalink":"http://zshell.cc/categories/web/"}],"tags":[{"name":"http","slug":"http","permalink":"http://zshell.cc/tags/http/"},{"name":"tomcat","slug":"tomcat","permalink":"http://zshell.cc/tags/tomcat/"},{"name":"spring","slug":"spring","permalink":"http://zshell.cc/tags/spring/"},{"name":"spring-mvc","slug":"spring-mvc","permalink":"http://zshell.cc/tags/spring-mvc/"}]},{"title":"jackson 注解 cheat sheet","slug":"ser_deser-jackson--jackson注解cheat_sheet","date":"2017-02-15T10:13:20.000Z","updated":"2018-09-09T12:35:05.396Z","comments":true,"path":"2017/02/15/ser_deser-jackson--jackson注解cheat_sheet/","link":"","permalink":"http://zshell.cc/2017/02/15/ser_deser-jackson--jackson注解cheat_sheet/","excerpt":"本文是 JsonUtil 类 cheat sheet 的姊妹篇;JsonUtil 类 cheat sheet 侧重于代码层面对 jackson API 的使用, 是一个 “宏观” 的行为: 其设置对全局皆有效; 而本文则着重讨论 javabean 各成员上 jackson 注解的使用, 是一个 “微观” 的行为: 通过注解的约定, 可以精细化控制具体的类, 字段及方法 的序列化 / 反序列化行为, 使 jackson 能够定制化得处理各个 javabean;","text":"本文是 JsonUtil 类 cheat sheet 的姊妹篇;JsonUtil 类 cheat sheet 侧重于代码层面对 jackson API 的使用, 是一个 “宏观” 的行为: 其设置对全局皆有效; 而本文则着重讨论 javabean 各成员上 jackson 注解的使用, 是一个 “微观” 的行为: 通过注解的约定, 可以精细化控制具体的类, 字段及方法 的序列化 / 反序列化行为, 使 jackson 能够定制化得处理各个 javabean; 字段是否参与序列化控制字段是否参与序列化是精细化管理 jackson 行为的典型案例:1234567891011121314151617181920public class Bean &#123; // 总是序列化, 默认情况 @JsonInclude(JsonInclude.Include.ALWAYS) private String str1; // 只有不为 null 时才参与序列化 @JsonInclude(JsonInclude.Include.NON_NULL) private String str2; /** * 只有不为 \"空\" 时才参与序列化: * 1. 满足 NON_NULL 与 NON_ABSENT (guava Optional) * 2. Collection size 不为 0 * 3. String != \"\" * 4. Integer != 0 * 5. Boolean != false */ @JsonInclude(JsonInclude.Include.NON_EMPTY) private String str3;&#125; 反序列化相关注解jackson 在序列化时使用反射, 故而其对目标类的构造器情况完全没有要求; 然而在反序列化时, jackson 默认使用无参构造器创建实例, 如果对象没有无参构造器, 也没有任何注解提示 jackson, 则会反序列化失败:12Caused by: com.fasterxml.jackson.databind.exc.InvalidDefinitionException: Cannot construct instance of `xxx` (no Creators, like default construct, exist): cannot deserialize from Object value (no delegate- or property-based Creator) 如果想提示 jackson 使用有参构造器, 需要注解如下:1234@JsonCreatorpublic Bean(String str) &#123; this.str = str;&#125; 不过, 在大部分场景下, 光靠一个 @JsonCreator 注解是不够的, 只要构造器含有多于一个的参数, jackson 便会报如下异常:12Caused by: com.fasterxml.jackson.databind.exc.InvalidDefinitionException: Argument #0 of constructor [constructor for xxx, annotations: &#123;interface com.fasterxml.jackson.annotation.JsonCreator=@com.fasterxml.jackson.annotation.JsonCreator(mode=DEFAULT)&#125;] has no property name annotation; must have name when multiple-parameter constructor annotated as Creator 此时需要另一个注解 @JsonProperty 放置在构造器的每一个参数上:123456@JsonCreatorpublic Bean(@JsonProperty(\"str1\") String str1, @JsonProperty(\"str2\") String str2) &#123; this.str1 = str1; this.str2 = str2;&#125; 其实, @JsonProperty 的使用是独立于 @JsonCreator 的, 其还可以作用于成员字段或成员方法上, 不过作用却是一致的, 均是用于反序列化时作为 json 字段与类成员字段的映射;当然其中也有一个细微差别, 作用于字段或方法上的 @JsonProperty 的 value 是可以为空的: @JsonProperty 的 value 如果为空, 则 jackson 会寻找 json 字符串中与该字段名一致的 key; 如果 value 非空, 则 jackson 会寻找 json 字符串中与该 value 一致的 key;而对于构造器方法, @JsonProperty 的 value 是不可以为空的, 毕竟构造器方法的参数名是可以与成员字段名不一样的; 多态反序列化有些特殊的场景下, 一串 json 可能对应于继承一个父类的多个子类, 然而究竟对应于哪个子类, 却无法在代码中提前确定下来, 只能以父类型作为 valueType 参与反序列化, 这种时候就需要使用 jackson 的多态反序列化功能:1234567891011121314151617@JsonTypeInfo(use = JsonTypeInfo.Id.CLASS, include = JsonTypeInfo.As.PROPERTY, property = \"@class\")@JsonSubTypes(&#123;@JsonSubTypes.Type(value = Child1.class, name = \"Child1\"), @JsonSubTypes.Type(value = Child2.class, name = \"Child2\")&#125;)class Parent &#123; public String name; protected Parent() &#123;&#125;&#125;class Child1 extends Parent &#123; public double param1; public Child1() &#123;&#125;&#125;class Child2 extends Parent &#123; boolean param1; public int param2; public Child2() &#123;&#125;&#125; 对于以上配置, 以子类 Child1 为例, 相应的 json 字符串内容如下:123456jsonStr = &#123; // 指定子类类型为 Child1.class \"@class\": \"Child1\", \"name\": \"child1\", \"param1\": 3.14&#125; 要让 jackson 识别传入的 json 串究竟表示哪一个子类, json 中就必须要存在父类中定义 @JsonTypeInfo 时约定的 property name, 以上例子中的 property 是 “@class”; 另外, property “@class” 对应的值也必须是父类中定义 @JsonSubTypes 时约定的几个 name, jackson 以此确定究竟反序列化为哪个子类, 以上例子中, “Child1” 对应于 Child1.class, “Child2” 对应于 Child2.class;现在, 使用以下代码便可以让 jackson 将刚才定义的 jsonStr 串反序列化为一个 Child1 实例, 而代码中我们仅仅需要指定 valueType 为 Parent.class:1objectMapper.readValue(jsonStr, Parent.class); 循环依赖的解除 (字段的排除)有时候会遇到蛋疼的问题: 两个类互相引用, 这时 jackson 会判定其发生循环依赖, 无法序列化; 对这种情况我们就需要手动解开循环依赖, 比较典型的方法是忽略涉及循环依赖的字段, 不过这样可能造成信息丢失:123456789101112131415161718192021public class Bean &#123; // str1 序列化时会被忽略, 但反序列化时不会被忽略 @JsonBackReference @JsonManagedReference private String str1; // str2 序列化与反序列化时都会被忽略, @JsonBackReference 单独使用效果同 @JsonIgnore @JsonBackReference private String str2; // str3 序列化与反序列化时都会被忽略 @JsonIgnore private String str3; // 对于str4, 只有序列化时会被忽略, 反序列化时不会被忽略(单独作用于 getter, 不作用于 setter) private String str4; @JsonIgnore public String getStr4() &#123; return str4; &#125; public void setStr4(String str) &#123; this.str4 = str; &#125;&#125; 站内相关文章 JsonUtil 类 cheat sheet 参考链接 jackson annotations 注解详解","categories":[{"name":"ser/dser","slug":"ser-dser","permalink":"http://zshell.cc/categories/ser-dser/"},{"name":"jackson","slug":"ser-dser/jackson","permalink":"http://zshell.cc/categories/ser-dser/jackson/"}],"tags":[{"name":"cheat sheet","slug":"cheat-sheet","permalink":"http://zshell.cc/tags/cheat-sheet/"},{"name":"jackson","slug":"jackson","permalink":"http://zshell.cc/tags/jackson/"},{"name":"json","slug":"json","permalink":"http://zshell.cc/tags/json/"}]},{"title":"jackson 常用配置选项梳理","slug":"ser_deser-jackson--jackson_常用配置选项梳理","date":"2017-01-21T07:51:40.000Z","updated":"2018-05-01T08:05:10.186Z","comments":true,"path":"2017/01/21/ser_deser-jackson--jackson_常用配置选项梳理/","link":"","permalink":"http://zshell.cc/2017/01/21/ser_deser-jackson--jackson_常用配置选项梳理/","excerpt":"jackson 有各种各样的配置选项 (Feature), 涵盖了包括 json 语法解析, 语句生成, 序列化 / 反序列化特征, 字段类型处理 等不同层面, 对初学者而言, 很容易造成困惑;本文基于 jackson 2.8.x, 着手整理常用的 jackson 配置选项, 并给出一个便捷的工具类, 以友好的方式整合 jackson 的常用配置项;","text":"jackson 有各种各样的配置选项 (Feature), 涵盖了包括 json 语法解析, 语句生成, 序列化 / 反序列化特征, 字段类型处理 等不同层面, 对初学者而言, 很容易造成困惑;本文基于 jackson 2.8.x, 着手整理常用的 jackson 配置选项, 并给出一个便捷的工具类, 以友好的方式整合 jackson 的常用配置项; 配置选项分类jackson 的配置选项丰富得可以让开发者自定义从 json 语句到 javabean 的方方面面, 总体来说有如下几类:json 语句的生成与解析1234// json 语句生成的选项JsonGenerator.Feature// json 语法解析的选项JsonParser.Feature javabean 的序列化与反序列化1234// javabean 序列化选项SerializationFeature// javabean 反序列化选项DeserializationFeature javabean 字段12// javabean 字段是否参与序列化JsonInclude.Include 上述各 Feature 或 Include 都是以枚举 (enum) 的形式定义的, 他们分布在 jackson 的如下包中: JsonGenerator.Feature: jackson-core JsonParser.Feature: jackson-core SerializationFeature: jackson-databind DeserializationFeature: jackson-databind JsonInclude.Include: jackson-annotations 这样的归类与它们的功能有关:JsonGenerator 与 JsonParser 主管 json 的生成与解析, 当属 jackson 的核心功能, 所以归于 jackson-core 包中;SerializationFeature 与 DeserializationFeature 主管 javabean 的序列化与反序列化, 属于数据实体绑定范畴, 所以归于 jackson-databind 包中;JsonInclude.Include 比较特别, 它理应主管字段是否参与序列化, 是 javabean 序列化的控制细节, 但是它的外部类 JsonInclude 本身是一个注解, 故其被归于 jackson-annotations 包中;&nbsp;下面将分别总结各类 Feature 中具体的常用选项; 有一点要说的是, 以下选项有些本身就是默认设置, 这里只是拿出来总结一下, 我们需要了解这些设置的存在; 另外, 某些设置可能只针对普遍的情况, 在特殊场景下并不适用 (比如容错性, 在某些严格的环境下就是需要 fast fail, 不需要容错); JsonGenerator.Feature其实, JsonGenerator.Feature 是一个比较底层的设置, 在源码注释中被称为 Low-level I/O / content features;关于 json 的生成的配置项, 主要是三个方面:(1) 统一字段的 json 规范形式, 如对引号的要求;12// 必须以 \"双引号\" 的形式包装字段objectMapper.configure(JsonGenerator.Feature.QUOTE_FIELD_NAMES, true); (2) 加强 json 生成的容错性, 如 JsonToken (大括号与中括号) 的匹配;12// 允许 json 生成器自动补全未匹配的括号objectMapper.configure(JsonGenerator.Feature.AUTO_CLOSE_JSON_CONTENT, true); (3) 第三个可能比较少见, 因为大部分业务场景下, 我们只是使用 objectMapper.writeValueAsString 方法, 得到其返回的 json 字符串以作他用; 而如果使用 objectMapper.writeValue 方法, 则可能涉及到写入流的问题:12// 允许 json 生成器在写入完成后自动关闭写入的流objectMapper.configure(JsonGenerator.Feature.AUTO_CLOSE_TARGET, false); 这个选项默认是开启的, 那么会导致一个问题: 当你希望在往目标输出流里输出 json 之后再输出一些其他内容便会失败, 因为 jackson 已经自动帮你关闭该输出流了; 所以有些时候, 这个选项要设置成 false; JsonParser.FeatureJsonParser 的配置项, 主要是加强 json 解析的容错性, 并主要体现在三方面:(1) 降低字段的 json 规范形式, 如对引号的要求; 可以发现, 当自己生成 json 时, 我们要求严格规范引号的书写, 而当解析别人的 json 时, 却需要放宽规范与形式, 增强容错;123456// 允许 json 存在没用引号括起来的 fieldobjectMapper.configure(JsonParser.Feature.ALLOW_UNQUOTED_FIELD_NAMES, true);// 允许 json 存在使用单引号括起来的 fieldobjectMapper.configure(JsonParser.Feature.ALLOW_SINGLE_QUOTES, true);// 允许 json 存在没用引号括起来的 ascii 控制字符objectMapper.configure(JsonParser.Feature.ALLOW_UNQUOTED_CONTROL_CHARS, true); (2) 扩大数值字段的表现形式, 如前导 0, 无限大等;1234// 允许 json number 类型的数存在前导 0 (like: 0001)objectMapper.configure(JsonParser.Feature.ALLOW_NUMERIC_LEADING_ZEROS, true);// 允许 json 存在 NaN, INF, -INF 作为 number 类型objectMapper.configure(JsonParser.Feature.ALLOW_NON_NUMERIC_NUMBERS, true); (3) 允许出现注释;12// 允许 json 存在形如 // 或 /**/ 的注释objectMapper.configure(JsonParser.Feature.ALLOW_COMMENTS, true); SerializationFeatureSerializationFeature 的配置项, 主要是针对 javabean 字段序列化作规范与统一;比如:(1) 输出压缩的 json, 而不要缩进格式化, 浪费流量;(2) 统一时间类型的输出为 timestamp, 消除歧义, 方便转换;(3) 将空的集合类型以空的形式参与序列化, 而不是不展示它们, 从而始终能得到完整的数据结果;123456// 序列化时, 禁止自动缩进 (格式化) 输出的 json (压缩输出)objectMapper.configure(SerializationFeature.INDENT_OUTPUT, false);// 序列化时, 将各种时间日期类型统一序列化为 timestamp 而不是其字符串表示objectMapper.configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, true);// 序列化时, map, list 中的 null 值也要参与序列化objectMapper.configure(SerializationFeature.WRITE_NULL_MAP_VALUES, true); 另外也有一些容错方面的设置:12// 序列化时, 对于没有任何 public methods / properties 的类, 序列化不报错objectMapper.configure(SerializationFeature.FAIL_ON_EMPTY_BEANS, false); DeserializationFeature反序列化时配置项, 主要是考虑到容错性, 针对陌生的字段作忽略处理, 从而提高版本之间的兼容性(比如升级某个 api 版本增加字段后, 所有调用方并不需要保持同步升级, 反序列化时对新字段暂时忽略即可);12// 忽略未知的字段objectMapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false); JsonInclude.Include这与 SerializationFeature.WRITE_NULL_MAP_VALUES 有些相似: 就是针对所有的元素, 不管是不是 null, 都要参与序列化, 要展示所有元素的情况, 而不是对空值就忽略不展示了, 那会诱导发生潜在的 bug; 这算是对字段序列化作的规范统一;123// 所有实例中的 空字段, null 字段, 都要参与序列化objectMapper.setSerializationInclusion(JsonInclude.Include.NON_EMPTY);objectMapper.setSerializationInclusion(JsonInclude.Include.NON_NULL); jackson 选项控制的良好实践公司的基础公共服务 api 中, 有一组关于 jackson 的良好封装, 旨在以更便捷友好的方式设置 jackson 配置选项, 当时该组件的作者是基础架构部的 杨淼; 不过, 该组件源代码维护在 qunar 的私有 gitlab 仓库中, 并不对外开源; 出于与公司的保密协议, 我只能将我一个使用 scala 开发的个人项目中针对此重新编写的代码拿出来与大家分享: 便捷设置 jackson 配置选项的案例;这个案例中, 有两点值得分享:(1) 利用重载方法统一选项设置入口关于 ObjectMapper 设置选项的 configure 方法, 我们可以发现, 它有很多重载方法:12345public ObjectMapper configure(MapperFeature f, boolean state);public ObjectMapper configure(JsonGenerator.Feature f, boolean state);public ObjectMapper configure(JsonParser.Feature f, boolean state);public ObjectMapper configure(SerializationFeature f, boolean state);public ObjectMapper configure(DeserializationFeature f, boolean state); 以上五个重载方法已经涵盖了上一节中提到的五种 Feature 中的四种; 最后还有一个关于 JsonInclude.Include 的设置方法如下:12// 针对 JsonInclude.Includepublic ObjectMapper setSerializationInclusion(JsonInclude.Include incl); 所以, 在我分享的例子中, 便抽出了一个统一设置各个 Feature 的方法:1234567891011private def configure(mapper: ObjectMapper, feature: AnyRef, state: Boolean) &#123; feature match &#123; case feature: SerializationFeature =&gt; mapper.configure(feature.asInstanceOf[SerializationFeature], state) case feature: DeserializationFeature =&gt; mapper.configure(feature.asInstanceOf[DeserializationFeature], state) case feature: JsonParser.Feature =&gt; mapper.configure(feature.asInstanceOf[JsonParser.Feature], state) case feature: JsonGenerator.Feature =&gt; mapper.configure(feature.asInstanceOf[JsonGenerator.Feature], state) // 兜底逻辑, 针对其余的 Feature case feature: MapperFeature =&gt; mapper.configure(feature.asInstanceOf[MapperFeature], state) case feature: Include =&gt; if (state) mapper.setSerializationInclusion(feature.asInstanceOf[Include]) &#125;&#125; (2) 使用位运算符巧妙设置选项其实, 在 jackson 自己的源码中, 就已经蕴含着位运算的设计思路 (以 SerializationFeature 为例):123456789101112/* SerializationFeature */public ObjectMapper configure(SerializationFeature f, boolean state) &#123; _serializationConfig = state ? _serializationConfig.with(f) : _serializationConfig.without(f); return this;&#125;/* SerializationConfig */public SerializationConfig with(SerializationFeature feature) &#123; int newSerFeatures = _serFeatures | feature.getMask(); return (newSerFeatures == _serFeatures) ? this : new SerializationConfig(this, _mapperFeatures, newSerFeatures, _generatorFeatures, _generatorFeaturesToChange, _formatWriteFeatures, _formatWriteFeaturesToChange);&#125; 其中, feature.getMask() 方法便是得到目标 feature 的掩码 _mask, 一个在二进制上与其他 feature 相互错开的整数值:123456private SerializationFeature(boolean defaultState) &#123; _defaultState = defaultState; _mask = (1 &lt;&lt; ordinal());&#125;public int getMask() &#123; return _mask; &#125; 可以发现, 1 &lt;&lt; ordinal() 这个操作会给该枚举中的每个值, 依次对 1 作左移, 从而枚举内所有的值, 其二进制表示都只含有一个 1, 且两两错开 (但由于 _mask 是一个普通整型, 所以该枚举只能容纳不超过 32 个值);那么位或运算 _serFeatures | feature.getMask() 便等于将该目标枚举值追加到掩码中了;在我分享的例子中, 也是借鉴了这样巧妙的设计思想, 不同之处在于, 我的案例中是将所有常用的选项配置放在了一起, 组成了一个新的枚举, 并添加了一个 enableByDefault, 表示是否默认开启; 在这个新枚举中, 使用位操作对所有常用的配置编码, 统一设置:1234567891011121314val defaults: Long = &#123; var flags = 0 for (f &lt;- values if f.enabledByDefault) &#123; flags |= f.getMask &#125; flags&#125;sealed case class JsonFeatureValue (@BeanProperty feature: AnyRef, enabledByDefault: Boolean) extends Val &#123; @BeanProperty val mask = 1 &lt;&lt; id def isEnabled(flags: Long): Boolean = (flags &amp; mask) != 0 def enable(flags: Long): Long = flags | mask def disable(flags: Long): Long = flags &amp; (~mask)&#125; 当不想使用默认设置时, 构建一个新的 ObjectMapper 实例也十分简洁, 只需传入一个掩码映射的数值即可:1234567private def buildMapperInternal(features: Long): ObjectMapper = &#123; val mapper = new ObjectMapper for (jf &lt;- JsonFeature.values) &#123; configure(mapper, jf.getFeature, jf.isEnabled(features)) &#125; mapper&#125; &nbsp;以上便是该案例中两个值得学习的设计要点: 基于 jackson 原生代码, 利用方法重载, 位运算符, 整合分散的配置项, 聚集为一个便捷的工具类; 站内相关文章 便捷设置 jackson 配置选项的案例 参考链接 How to avoid null values serialization in HashMap Java program terminating after ObjectMapper.writeValue(System.out, responseData) - Jackson Library","categories":[{"name":"ser/deser","slug":"ser-deser","permalink":"http://zshell.cc/categories/ser-deser/"},{"name":"jackson","slug":"ser-deser/jackson","permalink":"http://zshell.cc/categories/ser-deser/jackson/"}],"tags":[{"name":"jackson","slug":"jackson","permalink":"http://zshell.cc/tags/jackson/"},{"name":"json","slug":"json","permalink":"http://zshell.cc/tags/json/"}]},{"title":"lsof 札记","slug":"linux-other--lsof札记","date":"2017-01-06T07:17:04.000Z","updated":"2018-01-20T13:26:42.069Z","comments":true,"path":"2017/01/06/linux-other--lsof札记/","link":"","permalink":"http://zshell.cc/2017/01/06/linux-other--lsof札记/","excerpt":"第一次接触到 lsof 命令, 是因为偶然间发现 netstat 命令已经落伍了(与此同时, 还发现了 ss 命令, 详见另一篇文章: netstat/ss 使用对比 );使用之后, 发现 lsof 被人称为 神器, 还是有一定道理的; 在任何资源都被抽象为 文件 的 linux 中, 一个面向 文件 的管理工具, 自然辖域辽阔, 神通广大, 再加上与其他命令的巧妙组合, 更如虎添翼, 在工作实践中独当一面;本文参考了一些实用资料, 结合自己的经验, 对 lsof 命令的使用略作整理;","text":"第一次接触到 lsof 命令, 是因为偶然间发现 netstat 命令已经落伍了(与此同时, 还发现了 ss 命令, 详见另一篇文章: netstat/ss 使用对比 );使用之后, 发现 lsof 被人称为 神器, 还是有一定道理的; 在任何资源都被抽象为 文件 的 linux 中, 一个面向 文件 的管理工具, 自然辖域辽阔, 神通广大, 再加上与其他命令的巧妙组合, 更如虎添翼, 在工作实践中独当一面;本文参考了一些实用资料, 结合自己的经验, 对 lsof 命令的使用略作整理; lsof 命令的输出结构12345678910111213# COMMAND 启动进程的命令# PID 进程号# TID 线程号# USER 用户# FD 文件描述符# TYPE 文件类型# DEVICE 磁盘名称# SIZE 文件大小# NODE inode 号# NAME 文件资源的名称&gt; sudo lsof | head -n 2COMMAND PID TID USER FD TYPE DEVICE SIZE/OFF NODE NAMEsystemd 1 root cwd DIR 253,1 4096 128 / 各字段的不同输出含义FD: 文件描述符 file description12345678910111213141516# 任何进程都必须有的0: 标准输入流1: 标准输出流2: 标准错误流# 几种特殊的保留 fdcwd: current work directory, 应用程序启动的目录txt: 二进制可执行文件或共享库rtd: root directory, 根目录mem: memory mapped file, 内存映射文件mmap: memory-mapped device, 内存映射设备# 整数后面跟着的字母u: 可读可写模式r: 只读模式w: 只写模式 TYPE: 文件类型123456DIR: 目录文件REG: 普通文件CHR: char, 字符设备文件BLK: block, 块设备文件IPV4: ipv4 socket 套接字文件IPV6: ipv6 socket 套接字文件 DEVICE:1todo SIZE: 文件大小12# 套接字文件的文件大小比较特殊, 其没有大小, 用特殊字符占位, 其余则正常显示 size0t0: 套接字文件的默认占位 &nbsp; lsof 的日常应用lsof 网络 相关的应用12345678910# 显示所有网络连接sudo lsof -i# 只显示 ipv6 的连接sudo lsof -i 6# 只显示 tcp 协议的连接sudo lsof -i TCP# 指定端口号sudo lsof -i:port# 指定主机(与端口)sudo lsof -i@l-tracer15.tc.cn2.xx.com:9999 lsof 用户 相关的应用123# 显示某用户所打开的文件sudo lsof -u zshell.zhangsudo lsof -u ^zshell.zhang (排除此用户) lsof 命令/进程 相关的应用123456# 只显示 pidsudo lsof -t# 只显示指定的命令打开的文件sudo lsof -c nginx# 只显示指定 pid 的进程打开的文件sudo lsof -p pid lsof 文件/目录 相关的应用12345# 搜索与指定路径相关的一切资源(user, process 等)sudo lsof /target_path# +d: 搜索与指定的一级目录下所有的文件相关的一切资源; +D: 递归操作(往下所有层级目录)sudo lsof +d /target_pathsudo lsof +D /target_path lsof 的选项组合及实践技巧上述的 lsof 操作, 对于多种选项的组合, 其默认是 或(or) 的关系, 即满足其中之一便会打印出来;lsof 与(and) 的逻辑运算关系如下:123456# 使用 -a 达到 与(and) 的效果# 必须同时满足三个条件: # 1. 是用户 zshell.zhang 启动的进程;# 2. 是套接字文件, 且连接的主机是 10.64.4.11;# 3. 该进程命令是 java;sudo lsof -a -u zshell.zhang -i@10.64.4.11 -c java lsof 常用的组合及实践:12345678910# 寻找已删除但未释放文件句柄的幽灵文件sudo lsof | grep deleted# 杀死所有匹配一定文件打开条件的进程sudo kill `sudo lsof -t -c java` # 杀死所有 java 进程sudo kill `sudo lsof -t -u zshell.zhang` # 杀死所有 zshell.zhang 的用户进程# 恢复删除的文件# 找到误删文件被什么进程持有, 获得 pid 和 fd1. sudo lsof /target_deleted_file# /proc/&#123;pid&#125;/fd/&#123;fd_num&#125; 的内容即为误删内容, 重定向到误删文件中即可2. cat /proc/&#123;pid&#125;/fd/&#123;fd_num&#125; &gt; /target_deleted_file 另外, lsof 还可以被运用于找出系统中的幽灵文件, 详见: du / df 使用及其区别; 站内相关文章 netstat/ss 使用对比 du / df 使用及其区别 参考链接 linux lsof详解 每天一个Linux命令（45）lsof命令 Linux 命令神器: lsof 入门 what-does-the-fd-column-of-pipes-listed-by-lsof-mean","categories":[{"name":"linux","slug":"linux","permalink":"http://zshell.cc/categories/linux/"},{"name":"other","slug":"linux/other","permalink":"http://zshell.cc/categories/linux/other/"}],"tags":[{"name":"linux:disk","slug":"linux-disk","permalink":"http://zshell.cc/tags/linux-disk/"},{"name":"linux:net","slug":"linux-net","permalink":"http://zshell.cc/tags/linux-net/"}]},{"title":"maven-assembly-plugin 使用总结","slug":"tools-maven--assembly_plugin","date":"2016-11-19T15:42:40.000Z","updated":"2018-01-20T13:20:30.547Z","comments":true,"path":"2016/11/19/tools-maven--assembly_plugin/","link":"","permalink":"http://zshell.cc/2016/11/19/tools-maven--assembly_plugin/","excerpt":"本文在 Apache Maven 的官方文档上, 结合自己的一些项目经历: 在 Apache Spark 中使用 springframework 的一次实践, 总结了一些 assembly 插件的使用方式和一些注意事项, 以作备忘;另外, 由于 assembly 的 核心配置文件中可配置项种类繁多, 为了体现直观性, 文本直接在一段 ‘丰富而典型’ 的配置文件 case 上, 以注释的形式作为每个配置项的释义;","text":"本文在 Apache Maven 的官方文档上, 结合自己的一些项目经历: 在 Apache Spark 中使用 springframework 的一次实践, 总结了一些 assembly 插件的使用方式和一些注意事项, 以作备忘;另外, 由于 assembly 的 核心配置文件中可配置项种类繁多, 为了体现直观性, 文本直接在一段 ‘丰富而典型’ 的配置文件 case 上, 以注释的形式作为每个配置项的释义; pom.xml 中的配置项一段典型的 assembly 插件的 mvn 配置:123456789101112131415161718192021222324252627&lt;plugin&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;assembly.plugin.version&#125;&lt;/version&gt; &lt;configuration&gt; &lt;!-- 打包后的包名是否需要追加 assembly 配置文件的 id --&gt; &lt;appendAssemblyId&gt;false&lt;/appendAssemblyId&gt; &lt;!-- 最终生成的打包文件输出的路径 --&gt; &lt;outputDirectory&gt;$&#123;project.build.directory&#125;/target&lt;/outputDirectory&gt; &lt;!-- 定义核心配置文件的访问路径 --&gt; &lt;descriptors&gt; &lt;descriptor&gt;$&#123;basedir&#125;/src/main/assembly/client.xml&lt;/descriptor&gt; &lt;descriptor&gt;$&#123;basedir&#125;/src/main/assembly/server.xml&lt;/descriptor&gt; &lt;/descriptors&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;!-- 一般运行在 package phase --&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;!-- assembly 插件中唯一的核心 goal, 另外一个 goal 是 assembly:help --&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; &nbsp; 核心配置文件以下 assembly 核心配置文件包含了最常用的几种配置项, 该文件习惯上放置在 ${basedir}/src/main/assembly/ 目录里, 并如上一节所示, 在 configuration -&gt; descriptors 路径下定义加载:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081&lt;assembly xmlns=\"http://maven.apache.org/ASSEMBLY/2.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/ASSEMBLY/2.0.0 http://maven.apache.org/xsd/assembly-2.0.0.xsd\"&gt; &lt;!-- assembly 配置文件id --&gt; &lt;id&gt;deploy&lt;/id&gt; &lt;!-- 目标打包文件的格式, 支持格式如下: jar, war, zip, tar, tar.gz, tar.bz2 等 --&gt; &lt;formats&gt; &lt;format&gt;jar&lt;/format&gt; &lt;/formats&gt; &lt;!-- 是否以 $&#123;project.build.finalName&#125;, 作为所有被打包文件的基目录, 默认 true --&gt; &lt;includeBaseDirectory&gt;false&lt;/includeBaseDirectory&gt; &lt;!-- 显式定义 所有被打包文件的基目录 --&gt; &lt;baseDirectory&gt;$&#123;project.build.finalName&#125;&lt;/baseDirectory&gt; &lt;!-- 独立文件的收集 --&gt; &lt;files&gt; &lt;file&gt; &lt;!-- 待收集的文件名 --&gt; &lt;source&gt;LICENSE.txt&lt;/source&gt; &lt;!-- 收集到目标文件的相对路径 --&gt; &lt;outputDirectory&gt;/&lt;/outputDirectory&gt; &lt;/file&gt; &lt;file&gt; &lt;source&gt;NOTICE.txt&lt;/source&gt; &lt;outputDirectory&gt;/&lt;/outputDirectory&gt; &lt;!-- 将 $&#123;...&#125; 占位符 替换为实际的内容, 默认 false --&gt; &lt;filtered&gt;true&lt;/filtered&gt; &lt;/file&gt; &lt;/files&gt; &lt;!-- 目录的收集 --&gt; &lt;fileSets&gt; &lt;fileSet&gt; &lt;!-- 目录名 --&gt; &lt;directory&gt;$&#123;project.basedir&#125;/src/main/resources&lt;/directory&gt; &lt;outputDirectory&gt;/&lt;/outputDirectory&gt; &lt;/fileSet&gt; &lt;fileSet&gt; &lt;directory&gt;$&#123;project.basedir&#125;/src/doc&lt;/directory&gt; &lt;!-- 是否使用默认的排除项, 排除范围包括版本控制程序产生的 metadata 等, 默认 true --&gt; &lt;useDefaultExcludes&gt;true&lt;/useDefaultExcludes&gt; &lt;outputDirectory&gt;/doc&lt;/outputDirectory&gt; &lt;/fileSet&gt; &lt;/fileSets&gt; &lt;!-- 依赖的收集 --&gt; &lt;dependencySets&gt; &lt;dependencySet&gt; &lt;outputDirectory&gt;/lib&lt;/outputDirectory&gt; &lt;!-- 是否将本次构建过程中生成的 主构件 加入到依赖的收集中, 默认 true --&gt; &lt;useProjectArtifact&gt;true&lt;/useProjectArtifact&gt; &lt;!-- 是否将本次构建过程中生成的 附加构件 也加入到依赖的收集中, 默认 false --&gt; &lt;useProjectAttachments&gt;false&lt;/useProjectAttachments&gt; &lt;!-- 是否将依赖都解包为普通的目录文件放入 outputDirectory, 默认 false --&gt; &lt;unpack&gt;false&lt;/unpack&gt; &lt;!-- --&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;!-- 是否让该 dependencySets 收集具有传递性, 即递归地将 dependency 间接依赖的 dependencies 都收集到打包文件中, 默认 true --&gt; &lt;useTransitiveDependencies&gt;true&lt;/useTransitiveDependencies&gt; &lt;!-- includes/excludes 的格式: groupId:artifactId:type:classifier groupId:artifactId groupId:artifactId:type:classifier:version 支持使用 * 通配, * 可以完整匹配由多个 ':' 分割的 section; --&gt; &lt;excludes&gt; &lt;exclude&gt;org.apache.commons:commons-logging:jar&lt;/exclude&gt; &lt;exclude&gt;*:war&lt;/exclude&gt; &lt;/excludes&gt; &lt;!-- 是否让 includes/excludes 具有传递性, 即递归地让指定的 dependency 间接依赖的 dependencies 都被 include/exclude, 默认 false --&gt; &lt;useTransitiveFiltering&gt;true&lt;/useTransitiveFiltering&gt; &lt;/dependencySet&gt; &lt;/dependencySets&gt; &lt;/assembly&gt; &nbsp; 使用 assembly 的一些注意事项 使用 assembly 打包成需要独立运行的 jar 时, 若无特殊需要显式定义 CLASSPATH, 则在核心配置文件中不应该定义 baseDirectory, 并将 includeBaseDirectory 置为 false;因为 assembly 生成的 jar 包在 /META-INF/MANIFEST.MF 文件中默认不会定义 Class-Path, 即 CLASSPATH 默认就是 jar 中的基目录; 1234# assembly 生成的 /META-INF/MANIFEST.MFManifest-Version: 1.0Archiver-Version: Plexus ArchiverCreated-By: 25.151-b12 (Oracle Corporation) 核心配置文件中的 outputDirectory 皆是以目标打包文件的根为相对路径的; 无论是否在路径最前面添加 /, 都不会有影响; assembly 2.2 之前的版本, 在涉及到一些复杂第三方依赖, 多个不同的 jar 包中含有同名的文件 (如 org.springframework) 时, 使用 assembly 打包时会遇到一个 bug:assembly 只把第一次遇到的同名文件加入目标打包文件, 其后遇到的同名文件, 则被 skip 掉 ( 详见官方 issue: When using mulitple Spring dependencies, the files from META-INF (from the Spring jars) overwrite each other in an executable jar-with-dependencies );当然, 在这个 issue 当中, 触发此 bug 还有一个必要条件是将 dependencySet 中的 unpack 置为 true, 这样多个 spring artifact META-INF/ 中的 spring.handlers / spring.schemas / spring.tooling 等文件才会同名冲突; &nbsp; 关于 assembly 命令除了上述以 配置文件 + maven core phase 回调的形式使用 assembly 插件之外, assembly 插件的 goals 也可以命令的形式执行:12mvn clean assembly:singlemvn assembly:help 由于使用 assembly 命令的场景不多见, 此处不再详述, 详见 maven 官方介绍: assembly:single &nbsp; 站内相关文章 在 Apache Spark 中使用 springframework 的一次实践 &nbsp; 参考链接 Apache Maven Assembly Plugin: Assembly Filtering Some Distribution Files 8.5. Controlling the Contents of an Assembly Quick Note on All includes and excludes Patterns","categories":[{"name":"tools","slug":"tools","permalink":"http://zshell.cc/categories/tools/"},{"name":"maven","slug":"tools/maven","permalink":"http://zshell.cc/categories/tools/maven/"}],"tags":[{"name":"mvn:plugins","slug":"mvn-plugins","permalink":"http://zshell.cc/tags/mvn-plugins/"}]},{"title":"cli 控制字符","slug":"linux-other--cli控制字符","date":"2016-11-17T13:11:33.000Z","updated":"2018-01-07T13:13:21.679Z","comments":true,"path":"2016/11/17/linux-other--cli控制字符/","link":"","permalink":"http://zshell.cc/2016/11/17/linux-other--cli控制字符/","excerpt":"cli 控制字符是终端操作中非常实用, 也极其频繁使用的快捷键; 使用得好可以加快敲命令的速度, 提升敲命令的准确性, 为工作带来极大便利; 同时, 这也是我们对 linux 爱不释手, 难以回到 windows 的原因之一;另外, 很多 cli 控制字符本质上是向 linux 或进程发送特定的信号, 关于 linux 信号的介绍, 本站有另外一篇文章: linux signals 总体认识;本文总结一些常用的 cli 控制字符的使用及技巧;","text":"cli 控制字符是终端操作中非常实用, 也极其频繁使用的快捷键; 使用得好可以加快敲命令的速度, 提升敲命令的准确性, 为工作带来极大便利; 同时, 这也是我们对 linux 爱不释手, 难以回到 windows 的原因之一;另外, 很多 cli 控制字符本质上是向 linux 或进程发送特定的信号, 关于 linux 信号的介绍, 本站有另外一篇文章: linux signals 总体认识;本文总结一些常用的 cli 控制字符的使用及技巧; 简单的 cli 控制字符123456789101112131415161718192021222324# 发送 SIGINT 中断信号ctrl + c# 清屏ctrl + l# reverse-i-search 搜索历史命令ctrl + r# 从机器上 logoutctrl + d# 暂停控制台标准输出 / 恢复控制台标准输出ctrl + s / ctrl + q# 发送 SIGQUIT 信号给前台进程, 并生成 core dumpctrl + /# 向前删除到第一个空格ctrl + w# 向后删除到第一个空格 alt + d# 向后删除所有的内容ctrl + k# 撤销上一步操作ctrl + ?# 光标快速跃进ctrl + 方向键# 补全命令/文件tab 与其他命令组合的 cli 控制字符 1234# 发送 SIGTSTP 信号, 挂起前台进程ctrl + z# ctrl + z 的输出[1]+ Stopped sudo vim /etc/profile 此时该前台进程被挂起, 操作系统将不会调度任何 cpu time 给此进程;接下来可以有以下配套操作:123456789101112# 查看后台任务&gt; jobs[1]+ Stopped sudo vim /etc/profile# 查看后台任务的 pidjobs -p# 将后台作业 1 恢复到前台fg 1fg %1# 将后台作业 1 恢复到后台bg 1bg %1 要杀死被挂起的后台任务有一些麻烦, 因为该任务处于 suspend 状态, 无法主动响应 SIGTERM, SIGINT 等相对柔和的信号, 但可以被 SIGKILL 这种强力的信号直接杀死:12kill -9 %1kill -9 `jobs -p` 还有一种比较讨巧的方法是结合 fg/bg 等唤醒后台任务的命令:12345# 当任务被唤醒, 将接收到 SIGTERM 信号并终止kill %1 &amp;&amp; fgkill %1 &amp;&amp; bgkill `jobs -p` &amp;&amp; bgkill `jobs -p` &amp;&amp; fg 控制字符的管理与设置12345678# 打印所有控制字符的设置 (--all)&gt; stty -aspeed 38400 baud; rows 60; columns 211; line = 0;intr = ^C; quit = ^\\; erase = ^?; kill = ^U; eof = ^D; eol = &lt;undef&gt;; eol2 = &lt;undef&gt;; swtch = &lt;undef&gt;; start = ^Q; stop = ^S; susp = ^Z; rprnt = ^R; werase = ^W; lnext = ^V; flush = ^O; min = 1; time = 0;-parenb -parodd cs8 -hupcl -cstopb cread -clocal -crtscts -cdtrdsr-ignbrk -brkint -ignpar -parmrk -inpck -istrip -inlcr -igncr icrnl ixon -ixoff -iuclc -ixany -imaxbel -iutf8opost -olcuc -ocrnl onlcr -onocr -onlret -ofill -ofdel nl0 cr0 tab0 bs0 vt0 ff0isig icanon iexten echo echoe echok -echonl -noflsh -xcase -tostop -echoprt echoctl echoke 参考链接 Bg, Fg, &amp;, Ctrl-Z – 5 Examples to Manage Unix Background Jobs Linux中 ctrl-c, ctrl-z, ctrl-d 区别","categories":[{"name":"linux","slug":"linux","permalink":"http://zshell.cc/categories/linux/"},{"name":"other","slug":"linux/other","permalink":"http://zshell.cc/categories/linux/other/"}],"tags":[{"name":"cheat sheet","slug":"cheat-sheet","permalink":"http://zshell.cc/tags/cheat-sheet/"}]},{"title":"sed 命令整理","slug":"linux-text-sed命令整理","date":"2016-11-04T14:56:47.000Z","updated":"2018-01-04T14:58:47.480Z","comments":true,"path":"2016/11/04/linux-text-sed命令整理/","link":"","permalink":"http://zshell.cc/2016/11/04/linux-text-sed命令整理/","excerpt":"stream editor: 流式文本编辑器;sed 命令的侧重点在于对文本的编辑;","text":"stream editor: 流式文本编辑器;sed 命令的侧重点在于对文本的编辑; sed 的基本模式123456# 标准模式: 选项, 目标行范围, 命令sed [-nefri] '[target line]command' $file_path# 正则模式: 选项, 正则匹配式, 命令sed [-nefri] '/regex/command' $file_path# 混合模式: 选项, 目标行与正则式组合范围, 命令sed [-nefri] 'line,/regex/command' $file_path sed 的常用选项123456781. -n: silent 静默模式, 只输出被 sed 处理过的行;2. -e: --expression, 指定命令, 可以使用多个 -e 执行多个命令: sed -e '$d' -e '/regex/p' $file_path3. -f: 执行给定文件里的命令;4. -r: --regexp-extended, 使 sed 支持拓展的正则表达式语法, 拓展的正则表达式较常规的正则表达式增加支持了如下语法: +, ?, |, () 由于这些拓展语法也非常常见, 所以推荐若使用 sed 的 regex 功能时带上 -r 选项;5. -i: 直接在指定的文件里修改编辑, stdout 不输出任何内容; sed 的 command123456789101. i: insert 到 目标行的上一行2. a: append 到 目标行的下一行 3. c: replace, 不能使用正则表达式4. s: replace, 使用正则表达式, 一般需要与 -r 配合使用, 模式为: s/regex/new_str/g, 替换文件中所有的 regex; s/regex/new_str, 只替换每行第一个被匹配上的 regex; s/regex/new_str/p, 如果某行被匹配上了就打印出来, 常与 -n 选项一同使用;5. d: delete6. p: print, 一般需要与 -n 选项一同使用, 否则看不出打印效果7. y: 按每个字符映射, 模式案例: y/1234567890/ABCDEFGHIJ/ 典型示例12345678# 打印最后一行sed -n '$p' $file_path# 指定两种操作, 删除9到最后一行, 以及向1到3行后追加 'append' 字符串sed -i -e '9,$d' -e '1,3a append' $file_path# 正则表达式替换(替换全部 regex)sed -ri 's/^(test|ping)[a-z]+.$/kill/g' $file_path# 打印从第9行开始到以 test 结尾的行之间的每一行sed -n '9,/test$/p' $file_path 1234# 结合变量, 往最后一行添加一行内容# 需使用\"\", 同时表示最后一行的 $ 需要转义cron_str='5 * * * * sh /home/q/tools/bin/log_collect.sh 1&gt;/dev/null'sed \"\\$a $&#123;cron_str&#125;\" /var/spool/cron/root 参考链接 linux之sed用法 linux sed命令详解","categories":[{"name":"linux","slug":"linux","permalink":"http://zshell.cc/categories/linux/"},{"name":"text","slug":"linux/text","permalink":"http://zshell.cc/categories/linux/text/"}],"tags":[{"name":"linux:text","slug":"linux-text","permalink":"http://zshell.cc/tags/linux-text/"}]},{"title":"bash 条件判断全梳理","slug":"linux-shell--bash条件判断全梳理","date":"2016-09-01T09:52:36.000Z","updated":"2018-08-11T10:09:10.657Z","comments":true,"path":"2016/09/01/linux-shell--bash条件判断全梳理/","link":"","permalink":"http://zshell.cc/2016/09/01/linux-shell--bash条件判断全梳理/","excerpt":"本文基于 GNU bash, version 4.1.2(1)-release (x86_64-redhat-linux-gnu)","text":"本文基于 GNU bash, version 4.1.2(1)-release (x86_64-redhat-linux-gnu) bash 条件判断 的类型与逻辑运算符字符串比较 =同==, 相同为真; !=, 不相同为真; -z, 长度为0(空)为真; -n, 长度不为0(非空)为真; &lt;, 按字典序小于为真; &gt;, 按字典序大于为真; 整数比较 -eq, equals, 相等为真; -ne, not equals, 不相等为真; -gt, greater than, 大于为真; -ge, greater equals, 大于等于为真; -lt, less than, 小于为真; -le, less equals, 小于等于为真; &gt;, 大于; &gt;=, 大于等于; &lt;, 小于; &lt;=, 小于等于; ==, 等于; !=, 不等于; 文件比较 -e, exists, 文件存在为真 -r, read, 用户可读为真 -w, write, 用户可写为真 -x, execute, 用户可执行为真 -f, file, 文件为正规文件为真 -d, directory, 文件为目录为真 -L, link, 文件为链接文件为真 -c, char, 文件为字符特殊文件为真 -b, block, 文件为块特殊文件为真 -s, 文件大小非0时为真 -t, 当文件描述符(默认为1)指定的设备为终端时为真 -nt, newer than, 更新时间更晚为真; -ot, older than, 更新时间更早为真; 逻辑比较 -a, and, 逻辑与; -o, or, 逻辑或; !, 逻辑非; &amp;&amp;, 逻辑与( 支持短路 ); ||, 逻辑或( 支持短路 ); &nbsp; bash 条件判断 的命令(关键字)与语法test 与 [ ]test 与 [ 是 shell 的内置命令;test 和 [] 可以用于比较字符串, 整数, 文件, test expr与[ expr ]有等价的效果; 字符串比较test可以使用=, ==, !=比较, bash 4.1版本下也能使用-n, -z比较字符串( 旧版本可能不支持该方式 );[]可以使用上述全部的比较符号;12if !test $str1 == $str2; then ... ; fiif ! [ $str1 == $str2 ]; then ... ; fi test 与 [] 也可以使用 &lt; 和 &gt; 作字符串比较; 但是有一点要注意, test和[是 shell 的内置命令, 使用 &lt; 和 &gt; 需要转义, 否则会被当成重定向; 整数比较test和[]均可以使用-eq, -gt, -ge, -lt, -le, -ne 作整数比较, 但不能使用 &gt;, &gt;=, &lt;, &lt;=,==,!= 等比较运算符;使用&lt;,&gt;,==,!=虽然语法不会报错, 但是会被当成字符串以字典序比较, 不能确保结果的正确性;12if test $1 -le 0; then ... ; fiif [ $1 -le 0 ]; then ... ; fi 文件比较test和[]均可以使用-e, -r, -w, -x等文件比较逻辑;12if test -e /usr/local/localtime; then ... ; fiif [ -e /usr/local/localtime ]; then ... ; fi 逻辑比较test和[]只能使用-a, -o和!运算符, 但-a和-o 不支持逻辑短路;12if !test $str1 == $str2 -a -n $str3; then ... ; fiif [ $str1 == $str2 -a -n $str3 ]; then ... ; fi test的返回值test可以独立于if使用, 其执行结果( 0为真, 1为假 )可以使用$?来接收;1test -z \"$1\"; echo \"$?\" bash关键字 [[ ]] ( 推荐使用 )[[ 是 bash 的关键字, 而不是命令;[[ ]] 比 [] 更通用, 更安全, 功能更强大; 在生产环境中, 推荐使用 [[ ]]; 字符串比较[[ ]] 除了可以使用基本的 =, ==, !=, -n, -z 之外, 其 =,== 和 !=还有通配符模式匹配的功能:12# 模式串不能加双引号, 否则会被当作普通串if [[ \"test\" == t* ]]; then ... ; fi [[ ]] 还可以使用支持正则表达式的 =~ 运算符:12# 模式串不能加双引号, 否则会被当作普通串if [[ \"test\" =~ ^t[a-z].t$ ]]; then ... ; fi [[ ]]也可以使用&lt;和&gt;作字符串比较; 由于[[是bash内置的关键字, &lt;和&gt;并不会被当成重定向, 所以可以不需要转义; 整数比较和test, []一样, [[ ]]可以使用-eq, -gt, -ge, -lt, -le, -ne 作整数比较, 但不能使用 &gt;, &gt;=, &lt;, &lt;=,==,!= 等比较运算符; 不能使用的原因也是一样的(当成字符串来处理了); 算术拓展[[]]支持算术拓展, 但是其对整数比较支持度较差, 算术拓展可能是一个鸡肋功能, 而且运算符与运算数之间不能有空格:1if [[ 1+1 -eq 2 ]]; then ... ; fi 此功能不推荐使用; 文件比较和test, []一样, [[ ]]可以使用-e, -r, -w, -x等文件比较逻辑; 逻辑比较[[ ]]只能使用&amp;&amp;, ||, !运算符, 且&amp;&amp;和||支持逻辑短路; (( ))的使用场景无论是test, []还是[[ ]], 都不能很好地使用&lt;和&gt;处理整数的比较运算;所以通常使用(())来处理整数的比较运算;(())可以使用&gt;, &gt;=, &lt;, &lt;=,==,!=运算符;1if (( 1 + 1 == 2 )); then ... ; fi 使用(())的时候, 如果使用到了变量, 可以不需要加上$符号; &nbsp; 总结 - test 与 [ ] [[ ]] (( )) 字符串比较 =, ==, !=, -n, -z, &lt;, &gt; =, ==, !=, -n, -z, &lt;, &gt; 不支持 整数比较 -eq, -gt, -ge, -lt, -le, -ne -eq, -gt, -ge, -lt, -le, -ne >, &gt;=, &lt;, &lt;=, ==, != 文件比较 -e, -r, -w, -x, -f, -d, -L, -s, -b, -c, -t, -nt, -ot -e, -r, -w, -x, -f, -d, -L, -s, -b, -c, -t, -nt, -ot 不支持 逻辑比较 -a, -o, ! &amp;&amp;, &#124;&#124;, ! &amp;&amp;, &#124;&#124;, ! &nbsp; 参考链接","categories":[{"name":"linux","slug":"linux","permalink":"http://zshell.cc/categories/linux/"},{"name":"shell","slug":"linux/shell","permalink":"http://zshell.cc/categories/linux/shell/"}],"tags":[{"name":"linux:shell","slug":"linux-shell","permalink":"http://zshell.cc/tags/linux-shell/"}]},{"title":"JsonUtil 类 cheat sheet","slug":"ser_deser-jackson--JsonUtil类cheat_sheet","date":"2016-08-11T07:01:17.000Z","updated":"2018-09-09T13:21:39.438Z","comments":true,"path":"2016/08/11/ser_deser-jackson--JsonUtil类cheat_sheet/","link":"","permalink":"http://zshell.cc/2016/08/11/ser_deser-jackson--JsonUtil类cheat_sheet/","excerpt":"在日常工作中, json 的序列化/反序列化 是最频繁使用的动作; 拥有一个封装良好的 json 工具包能极大得提高工作效率;本文的目的是总结日常工作经验, 并将其作为一个 cheat sheet, 在某些项目环境中, 方便快速获取;jackson 是 java 世界里主流的 json 序列化/反序列化 框架, 本文所涉及的 json 工具类正是基于 jackson 实现的;","text":"在日常工作中, json 的序列化/反序列化 是最频繁使用的动作; 拥有一个封装良好的 json 工具包能极大得提高工作效率;本文的目的是总结日常工作经验, 并将其作为一个 cheat sheet, 在某些项目环境中, 方便快速获取;jackson 是 java 世界里主流的 json 序列化/反序列化 框架, 本文所涉及的 json 工具类正是基于 jackson 实现的; 首先要说的是, 本文不作过多关于 jackson 框架的描述, 其性质更偏向于 cheat sheet; 关于 jackson 及其使用方面的问题, 请参见另一篇文章: 对 jackson 浅层次的概念整理; 相关的 maven 配置jackson-databind, jackson-core, jackson-annotations, 这三个构件对大部分人来说, 都是相当熟悉的: 但凡在工程内引 jackson 必定会引它们三个;这里比较特殊的是第四个构件: jackson-datatype-joda; 这是 jackson 官方提供的针对 joda time 各种类 序列化/反序列化 的一个 ‘add-on module’;在 Group: FasterXML Jackson Datatype 中有各种各样 jackson 官方提供的针对各个 organization 的插件, 包括了 guava, hibernate, 以及 joda time; 其他的插件在我日常的工作中很少使用, 而 joda time 由于其极高的使用频率, jackson-datatype-joda 也自然成为了 jackson 拓展模块中的使用常客;1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-annotations&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-core&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- joda time 的拓展模块 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.datatype&lt;/groupId&gt; &lt;artifactId&gt;jackson-datatype-joda&lt;/artifactId&gt;&lt;/dependency&gt; 这里有一点需要注意的是, jackson-datatype-joda 的最低版本是 2.0.0; JsonUtil 类代码本类在 static 代码块中设置了各种常用的 jackson 选项, 包括 JsonParser, SerializationFeature, DeserializationFeature, JsonInclude 等; 所有的选项上方都写明了注释, 以方便在使用时针对不同的场景作定制化的修改;另外有一点需要补充说明的是, 该 static 代码各配置项虽加上了注释, 但并未说明为何需要设置此选项; 相关的详细说明请参见本站另一篇文章: jackson 常用配置选项梳理;123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148import com.fasterxml.jackson.annotation.JsonInclude;import com.fasterxml.jackson.core.JsonParser;import com.fasterxml.jackson.core.type.TypeReference;import com.fasterxml.jackson.databind.*;import com.fasterxml.jackson.datatype.joda.JodaModule;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.io.IOException;import java.util.List;import java.util.Map;/** * 针对 jackson 的工具封装类: * (1) 预设了 Jackson 常用的各种 Feature 选项; * (2) 封装了针对 normal object 的 ser / deser 方法; * (3) 封装了针对 List, Map 的常用 deser 情景; */public class JsonUtil &#123; private final static Logger logger = LoggerFactory.getLogger(JsonUtil.class); private final static ObjectMapper objectMapper = new ObjectMapper(); // 常用的 Feature 设置 static &#123; /* json 解析相关选项 */ // 允许 json 存在形如 // 或 /**/ 的注释 objectMapper.configure(JsonParser.Feature.ALLOW_COMMENTS, true); // 允许 json 存在没用引号括起来的 field objectMapper.configure(JsonParser.Feature.ALLOW_UNQUOTED_FIELD_NAMES, true); // 允许 json 存在使用单引号括起来的 field objectMapper.configure(JsonParser.Feature.ALLOW_SINGLE_QUOTES, true); // 允许 json 存在没用引号括起来的 ascii 控制字符 objectMapper.configure(JsonParser.Feature.ALLOW_UNQUOTED_CONTROL_CHARS, true); // 允许 json number 类型的数存在前导 0 (like: 0001) objectMapper.configure(JsonParser.Feature.ALLOW_NUMERIC_LEADING_ZEROS, true); // 允许 json 存在 NaN, INF, -INF 作为 number 类型 objectMapper.configure(JsonParser.Feature.ALLOW_NON_NUMERIC_NUMBERS, true); /* json 序列化与反序列化的行为设置 */ // 序列化时, 对于没有任何 public methods / properties 的类, 序列化不报错 objectMapper.configure(SerializationFeature.FAIL_ON_EMPTY_BEANS, false); // 序列化时, 禁止自动缩进 (格式化) 输出的 json objectMapper.configure(SerializationFeature.INDENT_OUTPUT, false); // 序列化时, 将各种时间日期类型统一序列化为 timestamp 而不是其字符串表示 objectMapper.configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, true); // 序列化时, map, list 中的 null 值也要参与序列化 objectMapper.configure(SerializationFeature.WRITE_NULL_MAP_VALUES, true); // 反序列化时, 忽略未知的字段 objectMapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false); /* 字段的 include 设置 */ // 所有实例中的空字段都要参与序列化 objectMapper.setSerializationInclusion(JsonInclude.Include.NON_EMPTY); // 所有实例中的 null 字段都要参与序列化 objectMapper.setSerializationInclusion(JsonInclude.Include.NON_NULL); /* jackson 模块拓展 */ // 针对 joda time 定制的 ser/deser 模块 objectMapper.registerModule(new JodaModule()); &#125; /* normal object */ public static String encode(Object object) &#123; try &#123; return objectMapper.writeValueAsString(object); &#125; catch (IOException e) &#123; logger.error(\"jackson encode error, obj = &#123;&#125;\", object, e); return \"jackson encode error\"; &#125; &#125; public static &lt;T&gt; T decode(String json, Class&lt;T&gt; valueType) &#123; try &#123; return objectMapper.readValue(json, valueType); &#125; catch (Exception e) &#123; logger.error(\"jackson decode error, json = &#123;&#125;, class = &#123;&#125;\", json, valueType.getName(), e); return null; &#125; &#125; public static JsonNode readTree(String json) throws IOException &#123; try &#123; return objectMapper.readTree(json); &#125; catch (IOException e) &#123; logger.error(\"jackson readTree error, json = &#123;&#125;\", json, e); return null; &#125; &#125; /* decode list */ // 方法1, 适用于已知泛型类型 T 的情况 public static &lt;T&gt; List&lt;T&gt; decodeList(String json) throws IOException &#123; try &#123; return objectMapper.readValue(json, new TypeReference&lt;List&lt;T&gt;&gt;() &#123; &#125;); &#125; catch (IOException e) &#123; logger.error(\"jackson decodeList(String) error, json = &#123;&#125;\", json, e); return null; &#125; &#125; // 方法2, 适用于泛型类型未知的通用情况 public static &lt;T&gt; List&lt;T&gt; decodeList(String json, Class&lt;T&gt; clazz) throws IOException &#123; try &#123; return objectMapper.readValue(json, objectMapper.getTypeFactory() .constructCollectionType(List.class, clazz)); &#125; catch (IOException e) &#123; logger.error(\"jackson decodeList(String, Class&lt;T&gt;) error, json = &#123;&#125;, class = &#123;&#125;\", json, clazz.getName(), e); return null; &#125; &#125; /* decode map */ // 方法1, 适用于已知泛型类型 &lt;K, V&gt; 的情况 public static &lt;K, V&gt; Map&lt;K, V&gt; decodeMap(String json) throws IOException &#123; try &#123; return objectMapper.readValue(json, new TypeReference&lt;Map&lt;K, V&gt;&gt;() &#123; &#125;); &#125; catch (IOException e) &#123; logger.error(\"jackson decodeMap(String) error, json = &#123;&#125;\", json, e); return null; &#125; &#125; // 方法2, 使用于泛型类型未知的通用情况 public static &lt;K, V&gt; Map&lt;K, V&gt; decodeMap(String json, Class&lt;K&gt; key, Class&lt;V&gt; value) throws IOException &#123; try &#123; return objectMapper.readValue(json, objectMapper.getTypeFactory() .constructMapType(Map.class, key, value)); &#125; catch (IOException e) &#123; logger.error(\"jackson decodeMap(String, Class&lt;K&gt;, Class&lt;V&gt;) error, json = &#123;&#125;, key = &#123;&#125;, \" + \"value = &#123;&#125;\", json, key.getName(), value.getName(), e); return null; &#125; &#125;&#125; 站内相关文章 对 jackson 浅层次的概念整理 jackson 常用配置选项梳理 jackson 注解 cheat sheet 参考链接 How to serialize Joda DateTime with Jackson JSON processer Group: FasterXML Jackson Datatype","categories":[{"name":"ser/deser","slug":"ser-deser","permalink":"http://zshell.cc/categories/ser-deser/"},{"name":"jackson","slug":"ser-deser/jackson","permalink":"http://zshell.cc/categories/ser-deser/jackson/"}],"tags":[{"name":"cheat sheet","slug":"cheat-sheet","permalink":"http://zshell.cc/tags/cheat-sheet/"},{"name":"jackson","slug":"jackson","permalink":"http://zshell.cc/tags/jackson/"},{"name":"json","slug":"json","permalink":"http://zshell.cc/tags/json/"}]},{"title":"git 忽略文件的特殊场景","slug":"tools-git--git忽略文件的特殊场景","date":"2016-07-14T15:17:24.000Z","updated":"2018-02-12T10:51:43.855Z","comments":true,"path":"2016/07/14/tools-git--git忽略文件的特殊场景/","link":"","permalink":"http://zshell.cc/2016/07/14/tools-git--git忽略文件的特殊场景/","excerpt":"git 忽略文件, 其实有两种场景: 永久忽略 与 临时忽略;使用 .gitignore 在最刚开始时永久忽略指定文件是最常见的处理, 但是偶尔也会遇到特殊情况:1.一时疏忽, 将本该忽略的文件提交追踪了;2.需要临时忽略某指定文件, 一段时间后再继续追踪;本文将讨论以上两种情况下的 git 处理;","text":"git 忽略文件, 其实有两种场景: 永久忽略 与 临时忽略;使用 .gitignore 在最刚开始时永久忽略指定文件是最常见的处理, 但是偶尔也会遇到特殊情况:1.一时疏忽, 将本该忽略的文件提交追踪了;2.需要临时忽略某指定文件, 一段时间后再继续追踪;本文将讨论以上两种情况下的 git 处理; 永远忽略已被跟踪的文件适用场景:手误上传了不需要上传的文件, 希望斩草除根, 以后不让 git 追踪该文件;1234# first stepgit rm --cached file_path/# second step更新 .gitignore 文件, exclude 目标文件 临时忽略已被跟踪的文件适用场景:目标文件庞大, 每次修改保存时, git 计算文件的变化并更新 working directory, 触发磁盘IO瓶颈;所以需要临时忽略文件, 待修改完成 commit 时恢复跟踪;123456# first stepgit update-index --assume-unchanged file_path/# second step编辑文件...# third stepgit update-index --no-assume-unchanged file_path/ 参考链接 git忽略已经被提交的文件","categories":[{"name":"tools","slug":"tools","permalink":"http://zshell.cc/categories/tools/"},{"name":"git","slug":"tools/git","permalink":"http://zshell.cc/categories/tools/git/"}],"tags":[{"name":"tools:git","slug":"tools-git","permalink":"http://zshell.cc/tags/tools-git/"}]},{"title":"guava 源码学习: ListeningExecutorService 类族","slug":"guava--guava源码学习_ListeningExecutorService类族","date":"2016-04-21T16:00:57.000Z","updated":"2018-06-19T13:13:47.759Z","comments":true,"path":"2016/04/22/guava--guava源码学习_ListeningExecutorService类族/","link":"","permalink":"http://zshell.cc/2016/04/22/guava--guava源码学习_ListeningExecutorService类族/","excerpt":"带有 listenable 回调功能的 guava 线程池是 com.google.common.util.concurrent 包里十分重要的概念, 它们实现了任务执行完异步回调指定逻辑的功能, 在很大程度上解决了 java 原生组件 Future / FutureTask 阻塞获取结果的尴尬, 在生产实践中有着广泛的应用;","text":"带有 listenable 回调功能的 guava 线程池是 com.google.common.util.concurrent 包里十分重要的概念, 它们实现了任务执行完异步回调指定逻辑的功能, 在很大程度上解决了 java 原生组件 Future / FutureTask 阻塞获取结果的尴尬, 在生产实践中有着广泛的应用; 类族相关成员列举guava 中与 ListeningExecutorService 相关的类都集中在 util.concurrent 包中, 主要分为三类:(1) 包装返回 ListenableFutureTask 的 ExecutorService:123ListeningExecutorService extends ExecutorService;AbstractListeningExecutorService extends AbstractExecutorService implements ListeningExecutorService;MoreExecutors.ListeningDecorator extends AbstractListeningExecutorService; (2) 与 ListenableFutureTask 相关的类, 实现异步回调的关键逻辑:123ListenableFuture extends Future;ListenableFutureTask extends FutureTask implements ListenableFuture;ExecutionList; (3) 便捷工具类, 主要是方便开发者以友好的方式使用 ListeningExecutorService 和 ListenableFutureTask:123MoreExecutors;Futures;FutureCallback; ListenableFutureTask 的异步回调原理java 原生组件的关键支持guava ListenableFuture 得以实现任务完成后异步回调指定逻辑的关键就在于 java.util.concurrent.FutureTask 留白了一个空方法:12345678910/** * Protected method invoked when this task transitions to state * &#123;@code isDone&#125; (whether normally or via cancellation). The * default implementation does nothing. Subclasses may override * this method to invoke completion callbacks or perform * bookkeeping. Note that you can query status inside the * implementation of this method to determine whether this task * has been cancelled. */ protected void done() &#123; &#125; 可以发现, 注释中说明了该方法将留给子类去重写以实现 “invoke completion callbacks”; 下面来看下这个空方法是如何被回调的:(1) FutureTask 的 run 方法, 当任务跑完后会根据结果调用 set / setException 方法更新 state 状态;1234567891011121314151617181920public void run() &#123; ... try &#123; Callable&lt;V&gt; c = callable; if (c != null &amp;&amp; state == NEW) &#123; V result; boolean ran; try &#123; result = c.call(); ran = true; &#125; catch (Throwable ex) &#123; result = null; ran = false; setException(ex); // 任务失败更新 state 为 EXCEPTIONAL &#125; if (ran) set(result); // 任务成功更新 state 为 COMPLETING &#125; &#125; finally &#123;...&#125;&#125; (2) 以 set 方法为例, 更新完状态后会调用 finishCompletion() 方法;1234567protected void set(V v) &#123; if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) &#123; outcome = v; UNSAFE.putOrderedInt(this, stateOffset, NORMAL); finishCompletion(); // 状态更新完, 回调 finish 逻辑 &#125; &#125; 另外除了 set 与 setException 方法之外, 还有 cancel(boolean mayInterruptIfRunning) 方法也回调了 finishCompletion() 方法;(3) 在 finishCompletion() 方法中, 回调了留白的 done() 方法;12345678910111213141516171819202122private void finishCompletion() &#123; // assert state &gt; COMPLETING; for (WaitNode q; (q = waiters) != null;) &#123; if (UNSAFE.compareAndSwapObject(this, waitersOffset, q, null)) &#123; for (;;) &#123; Thread t = q.thread; if (t != null) &#123; q.thread = null; LockSupport.unpark(t); &#125; WaitNode next = q.next; if (next == null) break; q.next = null; q = next; &#125; break; &#125; &#125; done(); // 此处的回调留待实现 callable = null;&#125; ListenableFutureTask 正是继承了 FutureTask 并重写了 done() 方法, 实现了异步回调指定逻辑的功能; ListenableFutureTask 的具体实现在 ListenableFutureTask 中对 done() 方法的实现是这样的:1234567/** * Internal implementation detail used to invoke the listeners. */@Overrideprotected void done() &#123; executionList.execute();&#125; 其中, 类成员 executionList 的 execute() 方法逻辑如下:12345678910111213141516171819202122232425public void execute() &#123; RunnableExecutorPair list; // 因为涉及到链表反转, 所以需要同步工具保证线程安全 synchronized (this) &#123; if (executed) &#123; return; &#125; executed = true; list = runnables; runnables = null; &#125; RunnableExecutorPair reversedList = null; // 反转链表, 调整执行次序 while (list != null) &#123; RunnableExecutorPair tmp = list; list = list.next; tmp.next = reversedList; reversedList = tmp; &#125; // 挨个执行链表上的每个回调任务 while (reversedList != null) &#123; executeListener(reversedList.runnable, reversedList.executor); reversedList = reversedList.next; &#125; &#125; 1234567891011121314/* * 内部类, 表示一个链表的节点 */private static final class RunnableExecutorPair &#123; final Runnable runnable; final Executor executor; @Nullable RunnableExecutorPair next; RunnableExecutorPair(Runnable runnable, Executor executor, RunnableExecutorPair next) &#123; this.runnable = runnable; this.executor = executor; this.next = next; &#125;&#125; 其中, RunnableExecutorPair 是个链表节点, 存储了待执行的回调任务及执行任务的 executor; ExecutionList.execute 方法的内容就是将链表中的每个任务按照 原始入队的顺序 遍历执行;所谓入队, 其实就是指我们得到一个 ListenableFuture 实例后为其添加的回调逻辑, 通常我们会调用 addListener(Runnable listener, Executor executor) 方法以实现异步回调;而这里所说的 “原始入队的顺序”, 便是指 ListenableFuture 调用 addListener 方法添加回调任务的顺序;ListenableFutureTask 实现的 addListener 方法是调用 executionList.add 方法:12345678/* ExecutionList *//* public void add(Runnable runnable, Executor executor) */synchronized (this) &#123; if (!executed) &#123; runnables = new RunnableExecutorPair(runnable, executor, runnables); return; &#125;&#125; 可以发现, add 方法是将新的 RunnableExecutorPair 插在了链表头上, 使得遍历链表的顺序与插入顺序相反, 所以 execute 方法中需要先反转链表才能执行;&nbsp;以上内容便是 ListenableFutureTask 实现异步回调的基本原理; guava 顺手实现的一些便捷工具类虽然上文已描述了 ListenableFutureTask 异步回调的原理, 但这离我们的实际使用仍然相距甚远, 我们并不会主动构造 ListenableFutureTask, 也很少直接调用一个 ListenableFuture 实例的 addListener 方法, 这些都太不方便了;guava 基于 ListenableFuture 又编写了一系列的工具类, 这些工具类简化了我们使用 ListenableFuture 的方式, 在生产环境中被普遍使用; MoreExecutors首先是入口 MoreExecutors, 我们通常使用 listeningDecorator 方法构造一个能够生产 ListenableFutureTask 的 ListeningExecutorService 实例:1234567public static ListeningExecutorService listeningDecorator(ExecutorService delegate) &#123; return (delegate instanceof ListeningExecutorService) ? (ListeningExecutorService) delegate : (delegate instanceof ScheduledExecutorService) ? new ScheduledListeningDecorator((ScheduledExecutorService) delegate) : new ListeningDecorator(delegate);&#125; 重点看最后一行, 这是我们代码里经常走到的一行逻辑: ListeningDecorator 使用了一个装饰器, 修饰了 ExecutorService 中一些重要的方法:1private static class ListeningDecorator extends AbstractListeningExecutorService; ListeningDecorator 本身没有什么特殊的地方, 关键看它的父类 AbstractListeningExecutorService:12345678@Override protected final &lt;T&gt; ListenableFutureTask&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123; return ListenableFutureTask.create(runnable, value);&#125;@Overridepublic &lt;T&gt; ListenableFuture&lt;T&gt; submit(Runnable task, @Nullable T result) &#123; return (ListenableFuture&lt;T&gt;) super.submit(task, result);&#125; 1234/* ListenableFutureTask */public static &lt;V&gt; ListenableFutureTask&lt;V&gt; create(Runnable runnable, @Nullable V result) &#123; return new ListenableFutureTask&lt;V&gt;(runnable, result);&#125; 所以说, 这里就是生产 ListenableFutureTask 的地方了, MoreExecutors.listeningDecorator 返回的实例将被这些方法包装, 以能够构造出合适的 ListenableFutureTask 实例; Futures能够以友好方式构造 ListenableFutureTask 其实是不够的, 如果我们要主动调用其 addListener 方法, 就得自己处理回调任务中的各种异常, 类似下面这种模式:12345678910listenableFuture.addListener(() -&gt; &#123; try &#123; xxx = listenableFuture.get(); ... &#125; catch (ExecutionException e) &#123; ... &#125; catch (RuntimeException e) &#123; ... &#125;&#125;, Executors.newSingleThreadExecutor()); 很明显, 不是非常友好, 这种固化的逻辑完全是可以抽出来的, 于是 guava 提供了 Futures 类, 其中有一个方法 addCallback:123public static &lt;V&gt; void addCallback(ListenableFuture&lt;V&gt; future, FutureCallback&lt;? super V&gt; callback) &#123; addCallback(future, callback, MoreExecutors.sameThreadExecutor());&#125; 123456789101112131415161718192021public static &lt;V&gt; void addCallback(final ListenableFuture&lt;V&gt; future, final FutureCallback&lt;? super V&gt; callback, Executor executor) &#123; Preconditions.checkNotNull(callback); Runnable callbackListener = () -&gt; &#123; final V value; try &#123; value = getUninterruptibly(future); &#125; catch (ExecutionException e) &#123; callback.onFailure(e.getCause()); return; &#125; catch (RuntimeException e) &#123; callback.onFailure(e); return; &#125; catch (Error e) &#123; callback.onFailure(e); return; &#125; callback.onSuccess(value); &#125;; future.addListener(callbackListener, executor);&#125; 这段代码有两点:(1) 使用 MoreExecutors.sameThreadExecutor() 构造执行回调的 executor;MoreExecutors.sameThreadExecutor() 返回了一个自定义的 SameThreadExecutorService 实例, 这个类的特点是单线程, 回调任务都放在 executor.execute 所在线程里处理; 这样做十分得轻量化, 而如果使用 jdk 的 ThreadPoolExecutor, 很多时候都是为一个方法的执行付出创建一个线程池的开销;(2) 抽象出一个 FutureCallback 留给使用者实现回调的特定逻辑, 其余的 future.get(), 异常处理等都封装到 addCallback 方法里了, 对于 addCallback 方法里遇到异常或是执行成功, 都只是回调 FutureCallback 的接口而已:1234public interface FutureCallback&lt;V&gt; &#123; void onSuccess(@Nullable V result); void onFailure(Throwable t);&#125; 如此一来, 我们为 ListenableFutureTask 添加回调的方法就简洁多了:12345678910Futures.addCallback(listenableFuture, new FutureCallback&lt;String&gt;() &#123; @Override public void onSuccess(String result) &#123; ... &#125; @Override public void onFailure(Throwable t) &#123; ... &#125;&#125;);","categories":[{"name":"guava","slug":"guava","permalink":"http://zshell.cc/categories/guava/"}],"tags":[{"name":"guava","slug":"guava","permalink":"http://zshell.cc/tags/guava/"},{"name":"juc","slug":"juc","permalink":"http://zshell.cc/tags/juc/"},{"name":"线程池","slug":"线程池","permalink":"http://zshell.cc/tags/线程池/"}]}]}